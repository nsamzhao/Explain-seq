{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate fa files for deeplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pybedtools\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starr_peak = pd.read_csv('../data/starr_sig_A549_499bp/data/A549_training_499bp_7_windows_100_stride_random_region_value_label_10_labels_sorted.bed', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2489e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    510651\n",
       "0    391830\n",
       "2     94162\n",
       "3     18261\n",
       "4      6242\n",
       "5      2816\n",
       "6      1405\n",
       "9      1204\n",
       "7       862\n",
       "8       520\n",
       "Name: 4, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starr_peak[4].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502147d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>chr1</td>\n",
       "      <td>790202</td>\n",
       "      <td>790701</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1006493</td>\n",
       "      <td>1006992</td>\n",
       "      <td>+</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1264807</td>\n",
       "      <td>1265306</td>\n",
       "      <td>+</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>chr1</td>\n",
       "      <td>2097551</td>\n",
       "      <td>2098050</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>573</td>\n",
       "      <td>chr1</td>\n",
       "      <td>2097651</td>\n",
       "      <td>2098150</td>\n",
       "      <td>+</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1021816</td>\n",
       "      <td>chrY</td>\n",
       "      <td>21151299</td>\n",
       "      <td>21151798</td>\n",
       "      <td>+</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1021817</td>\n",
       "      <td>chrY</td>\n",
       "      <td>21151648</td>\n",
       "      <td>21152147</td>\n",
       "      <td>+</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1021818</td>\n",
       "      <td>chrY</td>\n",
       "      <td>21151997</td>\n",
       "      <td>21152496</td>\n",
       "      <td>+</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1021819</td>\n",
       "      <td>chrY</td>\n",
       "      <td>21152097</td>\n",
       "      <td>21152596</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1027847</td>\n",
       "      <td>chrY</td>\n",
       "      <td>56842476</td>\n",
       "      <td>56842975</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13049 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2  3  4\n",
       "144      chr1    790202    790701  +  4\n",
       "201      chr1   1006493   1006992  +  6\n",
       "284      chr1   1264807   1265306  +  6\n",
       "572      chr1   2097551   2098050  +  4\n",
       "573      chr1   2097651   2098150  +  7\n",
       "...       ...       ...       ... .. ..\n",
       "1021816  chrY  21151299  21151798  +  8\n",
       "1021817  chrY  21151648  21152147  +  9\n",
       "1021818  chrY  21151997  21152496  +  6\n",
       "1021819  chrY  21152097  21152596  +  4\n",
       "1027847  chrY  56842476  56842975  +  4\n",
       "\n",
       "[13049 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starr_peak = starr_peak.loc[(starr_peak[4] >= 4), :]\n",
    "starr_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf6373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/tmp/pybedtools.ka56ty9l.tmp)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = pybedtools.BedTool.from_dataframe(starr_peak[[0, 1, 2]]).sequence(fi='../genomes/hg38.fa')\n",
    "seq.save_seqs(f'../data/output_data/starr_sig_valueLabel_499bp.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df43b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "starr_peak = pd.read_csv('../data/starr_sig_A549_499bp/data/A549_replicate1_2_499bp_7_windows_100_stride_random_region_value_label_10_labels_sorted.bed', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3746b34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    473687\n",
       "0    395596\n",
       "2     89314\n",
       "3     18344\n",
       "4      6278\n",
       "5      2822\n",
       "6      1428\n",
       "9      1231\n",
       "7       862\n",
       "8       514\n",
       "Name: 4, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starr_peak[4].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284c767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1006437</td>\n",
       "      <td>1006936</td>\n",
       "      <td>+</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1053783</td>\n",
       "      <td>1054282</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1264811</td>\n",
       "      <td>1265310</td>\n",
       "      <td>+</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>chr1</td>\n",
       "      <td>2097551</td>\n",
       "      <td>2098050</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>chr1</td>\n",
       "      <td>2097651</td>\n",
       "      <td>2098150</td>\n",
       "      <td>+</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>983953</td>\n",
       "      <td>chrY</td>\n",
       "      <td>21151301</td>\n",
       "      <td>21151800</td>\n",
       "      <td>+</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>983954</td>\n",
       "      <td>chrY</td>\n",
       "      <td>21151650</td>\n",
       "      <td>21152149</td>\n",
       "      <td>+</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>983955</td>\n",
       "      <td>chrY</td>\n",
       "      <td>21151999</td>\n",
       "      <td>21152498</td>\n",
       "      <td>+</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>983956</td>\n",
       "      <td>chrY</td>\n",
       "      <td>21152099</td>\n",
       "      <td>21152598</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>989977</td>\n",
       "      <td>chrY</td>\n",
       "      <td>56842474</td>\n",
       "      <td>56842973</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13135 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2  3  4\n",
       "201     chr1   1006437   1006936  +  6\n",
       "223     chr1   1053783   1054282  +  4\n",
       "284     chr1   1264811   1265310  +  6\n",
       "523     chr1   2097551   2098050  +  4\n",
       "524     chr1   2097651   2098150  +  7\n",
       "...      ...       ...       ... .. ..\n",
       "983953  chrY  21151301  21151800  +  7\n",
       "983954  chrY  21151650  21152149  +  9\n",
       "983955  chrY  21151999  21152498  +  6\n",
       "983956  chrY  21152099  21152598  +  4\n",
       "989977  chrY  56842474  56842973  +  4\n",
       "\n",
       "[13135 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starr_peak = starr_peak.loc[(starr_peak[4] >= 4), :]\n",
    "starr_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7951db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/tmp/pybedtools._foy5ndc.tmp)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = pybedtools.BedTool.from_dataframe(starr_peak[[0, 1, 2]]).sequence(fi='../genomes/hg38.fa')\n",
    "seq.save_seqs(f'../data/output_data/starr_sig_valueLabel_499bp_rep1rep2.fa')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert trained model to deeplift required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from scipy.stats import gmean\n",
    "import pprint\n",
    "import pybedtools\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from pytorch2keras import pytorch_to_keras\n",
    "from Bio import SeqIO\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 499bp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Read in trained pytorch model without reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaBase(nn.Sequential):\n",
    "    def __init__(self, fn, *args):\n",
    "        super(LambdaBase, self).__init__(*args)\n",
    "        self.lambda_func = fn\n",
    "\n",
    "    def forward_prepare(self, input):\n",
    "        output = []\n",
    "        for module in self._modules.values():\n",
    "            output.append(module(input))\n",
    "        return output if output else input\n",
    "\n",
    "    \n",
    "class Lambda(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return self.lambda_func(self.forward_prepare(input))\n",
    "\n",
    "\n",
    "class Beluga(nn.Module):\n",
    "    def __init__(self, sequence_length, n_targets):\n",
    "        super(Beluga, self).__init__()\n",
    "        conv_kernel_size = 8\n",
    "        pool_kernel_size = 4\n",
    "        self.model = nn.Sequential(\n",
    "            #Lambda(lambda x: x.reshape(-1,4,1,sequence_length)), #added, and changed from view to reshape\n",
    "            nn.Conv2d(4,320,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(320,320,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d((1, pool_kernel_size),(1, pool_kernel_size)),\n",
    "            nn.Conv2d(320,480,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(480,480,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d((1, pool_kernel_size),(1, pool_kernel_size)),\n",
    "            nn.Conv2d(480,640,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(640,640,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            Flatten(),\n",
    "            nn.Linear(7680,2003), #500: 7680, 1000:28160, 2000:67840\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2003,n_targets),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "#                 Lambda(lambda x: x.reshape(x.size(0),-1)),\n",
    "#                 nn.Sequential(Lambda(lambda x: x.reshape(1,-1) if 1==len(x.size()) else x ),nn.Linear(67840,2003)),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Sequential(Lambda(lambda x: x.reshape(1,-1) if 1==len(x.size()) else x ),nn.Linear(2003,n_targets)),\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Beluga(sequence_length=499, n_targets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8fadee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_starr_state_dict = torch.load('../data/starr_sig_A549_499bp/training_outputs/transfer_trained_rep1rep2/best_model.pth.tar')['state_dict']\n",
    "all_starr_state_dict_new = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8350f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_key, trained_model_key in zip(model.state_dict().keys(), all_starr_state_dict.keys()):\n",
    "    all_starr_state_dict_new[model_key] = all_starr_state_dict[trained_model_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78041800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(all_starr_state_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_starr_state_dict, all_starr_state_dict_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbfc8630",
   "metadata": {},
   "source": [
    "### 2.1.2 Convert to keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a46ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np = np.random.uniform(0, 1, (1, 4, 1, 499))\n",
    "input_var = Variable(torch.FloatTensor(input_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model = pytorch_to_keras(model, input_var, verbose=True, change_ordering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model.save('../models/converted_models/keras_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6a01645",
   "metadata": {},
   "source": [
    "### 2.1.3 Convert to keras sequential model with conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fc5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "k_model_1d = keras.models.Sequential()\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=320, kernel_size=8, input_shape=(499,4))) #17\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #18\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=320, kernel_size=8)) #19\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #20\n",
    "k_model_1d.add(keras.layers.MaxPooling1D(pool_size=4))#21\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=480, kernel_size=8)) #22\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #23\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=480, kernel_size=8)) #24\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #25\n",
    "k_model_1d.add(keras.layers.MaxPooling1D(pool_size=4))#26\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=640, kernel_size=8)) #27\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #28\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=640, kernel_size=8)) #29\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #30\n",
    "# k_model_1d.add(keras.layers.Permute((2, 1))) #31_CHW\n",
    "k_model_1d.add(keras.layers.Flatten(data_format='channels_first')) #31\n",
    "k_model_1d.add(keras.layers.Dense(units=2003)) #32\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #33\n",
    "k_model_1d.add(keras.layers.Dense(units=1)) #34\n",
    "k_model_1d.add(keras.layers.Activation(\"softmax\")) #sigmoid\n",
    "k_model_1d.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9844973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 19:49:43.124046: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-12-04 19:49:43.165921: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194965000 Hz\n",
      "2021-12-04 19:49:43.173932: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55828bf71a60 executing computations on platform Host. Devices:\n",
      "2021-12-04 19:49:43.173994: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2021-12-04 19:49:43.175915: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-04 19:49:43.218216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: TITAN V major: 7 minor: 0 memoryClockRate(GHz): 1.455\n",
      "pciBusID: 0000:02:00.0\n",
      "2021-12-04 19:49:43.218273: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-04 19:49:43.220480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-04 19:49:43.222522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-04 19:49:43.222872: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-04 19:49:43.225168: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-04 19:49:43.226538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-04 19:49:43.231532: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-04 19:49:43.233753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2021-12-04 19:49:46.859246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-04 19:49:46.859290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2021-12-04 19:49:46.859297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2021-12-04 19:49:46.862347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10400 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:02:00.0, compute capability: 7.0)\n",
      "2021-12-04 19:49:46.864190: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55831ffdf570 executing computations on platform CUDA. Devices:\n",
      "2021-12-04 19:49:46.864207: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN V, Compute Capability 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "k_model = keras.models.load_model('../models/converted_models/keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_layer_index_k_model_1d = [0, 2, 5, 7, 10, 12, 15, 17]\n",
    "trans_layer_index_k_model = [1, 3, 6, 8, 11, 13, 17, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_k_model_1d, index_k_model in zip(trans_layer_index_k_model_1d, trans_layer_index_k_model):\n",
    "    try:\n",
    "        k_model_1d.layers[index_k_model_1d].set_weights(\n",
    "            [np.squeeze(k_model.layers[index_k_model].get_weights()[0]), \n",
    "             k_model.layers[index_k_model].get_weights()[1]])\n",
    "    except ValueError:\n",
    "        k_model_1d.layers[index_k_model_1d].set_weights(\n",
    "            [k_model.layers[index_k_model].get_weights()[0], \n",
    "             k_model.layers[index_k_model].get_weights()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd493b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model_1d.save('../models/converted_models/starr_sig_A549_499bp_rep1rep2.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bcb94946",
   "metadata": {},
   "source": [
    "## 2.2 499bp regression "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Read in trained pytorch model without reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2a788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaBase(nn.Sequential):\n",
    "    def __init__(self, fn, *args):\n",
    "        super(LambdaBase, self).__init__(*args)\n",
    "        self.lambda_func = fn\n",
    "\n",
    "    def forward_prepare(self, input):\n",
    "        output = []\n",
    "        for module in self._modules.values():\n",
    "            output.append(module(input))\n",
    "        return output if output else input\n",
    "\n",
    "    \n",
    "class Lambda(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return self.lambda_func(self.forward_prepare(input))\n",
    "\n",
    "\n",
    "class Beluga(nn.Module):\n",
    "    def __init__(self, sequence_length, n_targets):\n",
    "        super(Beluga, self).__init__()\n",
    "        conv_kernel_size = 8\n",
    "        pool_kernel_size = 4\n",
    "        self.model = nn.Sequential(\n",
    "            #Lambda(lambda x: x.reshape(-1,4,1,sequence_length)), #added, and changed from view to reshape\n",
    "            nn.Conv2d(4,320,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(320,320,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d((1, pool_kernel_size),(1, pool_kernel_size)),\n",
    "            nn.Conv2d(320,480,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(480,480,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool2d((1, pool_kernel_size),(1, pool_kernel_size)),\n",
    "            nn.Conv2d(480,640,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(640,640,(1, conv_kernel_size)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            Flatten(),\n",
    "            nn.Linear(7680,2003), #500: 7680, 1000:28160, 2000:67840\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2003,n_targets),\n",
    "            #nn.Softmax(),#nn.Sigmoid()\n",
    "            )\n",
    "#                 Lambda(lambda x: x.reshape(x.size(0),-1)),\n",
    "#                 nn.Sequential(Lambda(lambda x: x.reshape(1,-1) if 1==len(x.size()) else x ),nn.Linear(67840,2003)),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Sequential(Lambda(lambda x: x.reshape(1,-1) if 1==len(x.size()) else x ),nn.Linear(2003,n_targets)),\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Beluga(sequence_length=499, n_targets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8fadee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_starr_state_dict = torch.load('../data/starr_sig_A549_499bp_regression/training_outputs/transfer_trained_rep1rep2/best_model.pth.tar')['state_dict']\n",
    "all_starr_state_dict_new = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8350f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_key, trained_model_key in zip(model.state_dict().keys(), all_starr_state_dict.keys()):\n",
    "    all_starr_state_dict_new[model_key] = all_starr_state_dict[trained_model_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f8e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.0.weight',\n",
       "              tensor([[[[-0.0129,  0.1245, -0.0186,  ...,  0.0815,  0.1174, -0.1663]],\n",
       "              \n",
       "                       [[ 0.1011, -0.1691,  0.1431,  ...,  0.0809,  0.0417, -0.0384]],\n",
       "              \n",
       "                       [[ 0.0777,  0.0072, -0.1290,  ...,  0.0088, -0.1462,  0.0324]],\n",
       "              \n",
       "                       [[ 0.1284, -0.1667, -0.0276,  ...,  0.1104, -0.0075,  0.0639]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0854,  0.1462,  0.0444,  ..., -0.1547,  0.0120, -0.1536]],\n",
       "              \n",
       "                       [[-0.0359,  0.0775, -0.1079,  ...,  0.0069, -0.0884, -0.1137]],\n",
       "              \n",
       "                       [[ 0.1046, -0.0147, -0.0422,  ...,  0.1220,  0.0317, -0.0919]],\n",
       "              \n",
       "                       [[-0.0524,  0.0262,  0.1078,  ...,  0.0783, -0.1059, -0.1555]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1700, -0.0174, -0.1754,  ..., -0.0269, -0.0415, -0.0130]],\n",
       "              \n",
       "                       [[ 0.0900, -0.0574, -0.0460,  ...,  0.1191,  0.1229,  0.0539]],\n",
       "              \n",
       "                       [[ 0.0944, -0.0665, -0.0906,  ..., -0.0279, -0.0013,  0.0578]],\n",
       "              \n",
       "                       [[ 0.0692, -0.1201, -0.0288,  ..., -0.0477, -0.0987,  0.0152]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0118, -0.1156, -0.1674,  ...,  0.0729, -0.1373,  0.1543]],\n",
       "              \n",
       "                       [[ 0.1413,  0.0026,  0.0161,  ..., -0.0887,  0.1377,  0.0973]],\n",
       "              \n",
       "                       [[-0.0664, -0.0578,  0.0344,  ..., -0.0834,  0.0559, -0.0491]],\n",
       "              \n",
       "                       [[ 0.0892,  0.0208,  0.1007,  ..., -0.1112,  0.1256,  0.0310]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1182, -0.1062,  0.0172,  ..., -0.1407, -0.0896, -0.1547]],\n",
       "              \n",
       "                       [[ 0.1440,  0.0501,  0.0430,  ...,  0.0958, -0.0407, -0.1677]],\n",
       "              \n",
       "                       [[ 0.1567,  0.0142,  0.1316,  ...,  0.1199,  0.0026,  0.0765]],\n",
       "              \n",
       "                       [[-0.0588, -0.0897,  0.0468,  ..., -0.1528, -0.1698,  0.1626]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0989,  0.0231, -0.0564,  ..., -0.1654,  0.0097,  0.1709]],\n",
       "              \n",
       "                       [[-0.1606, -0.1628, -0.1693,  ...,  0.0394, -0.0963,  0.0320]],\n",
       "              \n",
       "                       [[ 0.0825,  0.0495,  0.1056,  ..., -0.1701, -0.0370,  0.0498]],\n",
       "              \n",
       "                       [[-0.0096,  0.1340,  0.0931,  ...,  0.0314, -0.0650, -0.0498]]]])),\n",
       "             ('model.0.bias',\n",
       "              tensor([ 0.0235, -0.0739,  0.1653, -0.0741, -0.1516, -0.0605,  0.0867,  0.1578,\n",
       "                       0.0008, -0.1244, -0.1136, -0.0740,  0.0911, -0.0781,  0.1397,  0.0954,\n",
       "                      -0.0930, -0.1310, -0.1055,  0.0050, -0.1241, -0.0820,  0.0997,  0.1279,\n",
       "                       0.1505, -0.0721, -0.1487, -0.0272,  0.1195, -0.1181,  0.0150, -0.0017,\n",
       "                       0.0806,  0.0608,  0.0220,  0.0523,  0.0744,  0.0507,  0.1558,  0.0374,\n",
       "                       0.1341, -0.0626,  0.1590, -0.1407, -0.0216, -0.0269, -0.0467,  0.0266,\n",
       "                       0.0878, -0.1342,  0.1062,  0.0114, -0.0170, -0.1417, -0.1181,  0.0975,\n",
       "                      -0.1694, -0.1378,  0.1470, -0.1273,  0.0032, -0.1666, -0.0343, -0.0257,\n",
       "                      -0.0660,  0.1187, -0.1581,  0.0506, -0.1366,  0.0634,  0.1338,  0.1107,\n",
       "                       0.1676,  0.0051,  0.0768,  0.0361,  0.1564, -0.0380, -0.0024, -0.1753,\n",
       "                       0.0062,  0.0252,  0.1227,  0.1061,  0.1521, -0.1170,  0.1726, -0.1351,\n",
       "                      -0.0123, -0.1305,  0.0126,  0.1093, -0.0122, -0.1310,  0.0353, -0.0826,\n",
       "                      -0.1764,  0.0191,  0.1457,  0.0470, -0.1054, -0.1625, -0.0935, -0.0814,\n",
       "                      -0.0173,  0.1236,  0.0596, -0.0931,  0.1253,  0.1350, -0.0042,  0.1563,\n",
       "                       0.0960,  0.1097,  0.0046,  0.0542, -0.1448, -0.1199, -0.0971, -0.1570,\n",
       "                       0.1746, -0.1340, -0.1149, -0.1009, -0.1025, -0.1512, -0.1405,  0.1243,\n",
       "                       0.0194, -0.0802, -0.0733,  0.0188, -0.1450,  0.0747, -0.0880,  0.1654,\n",
       "                       0.1380,  0.1743, -0.0250, -0.0982,  0.0996, -0.0923, -0.0025, -0.1357,\n",
       "                      -0.1582, -0.0887,  0.0688,  0.1352, -0.0502, -0.0108,  0.0936, -0.1207,\n",
       "                       0.0274, -0.0253, -0.0529,  0.0268,  0.0458, -0.1537, -0.0207,  0.0077,\n",
       "                      -0.0304,  0.1270, -0.0236,  0.0824,  0.1550, -0.0146, -0.0700, -0.1590,\n",
       "                      -0.1634, -0.1700,  0.0059, -0.1453, -0.0018,  0.1535,  0.0008, -0.1273,\n",
       "                       0.1638, -0.0008,  0.0946,  0.1709,  0.1182, -0.0516,  0.0805,  0.0993,\n",
       "                       0.0933, -0.0553,  0.0381,  0.0489, -0.1271,  0.1454, -0.1245,  0.1065,\n",
       "                       0.0308,  0.1291, -0.1135, -0.1310,  0.0809,  0.0226,  0.1015, -0.1473,\n",
       "                      -0.1558, -0.0005,  0.0630, -0.0535, -0.1155, -0.1460,  0.0360,  0.1730,\n",
       "                       0.0278, -0.0780, -0.1147, -0.0575, -0.1321, -0.1572, -0.1129,  0.1110,\n",
       "                       0.0509, -0.0437,  0.0878,  0.1427,  0.0340, -0.0697, -0.0626,  0.1242,\n",
       "                       0.0763,  0.0433,  0.1098, -0.1337,  0.1691,  0.0993,  0.1070, -0.1367,\n",
       "                       0.1170,  0.0405,  0.0105,  0.0400,  0.1416, -0.0451,  0.1501, -0.0335,\n",
       "                       0.0685, -0.1073,  0.1748, -0.0221, -0.0166, -0.0713, -0.0859,  0.1194,\n",
       "                      -0.1076, -0.0212, -0.1309,  0.0650,  0.1329,  0.0538, -0.1079, -0.0879,\n",
       "                      -0.0918, -0.1065, -0.0177, -0.0335,  0.0322,  0.0895, -0.1433,  0.0689,\n",
       "                      -0.0786,  0.0475,  0.0697,  0.0230,  0.0042, -0.0216, -0.1584,  0.1429,\n",
       "                       0.1737,  0.0653, -0.0746, -0.1573, -0.0647,  0.0448,  0.0380,  0.0095,\n",
       "                      -0.0749,  0.0495,  0.1229, -0.0266, -0.0601,  0.1478,  0.0294,  0.0182,\n",
       "                       0.0779, -0.1526,  0.1320, -0.1736,  0.0635, -0.0818, -0.0861, -0.1326,\n",
       "                      -0.1565,  0.0096,  0.1128, -0.1343,  0.1188,  0.1377, -0.1321,  0.1282,\n",
       "                       0.0370,  0.1361,  0.0840, -0.0006, -0.1042, -0.1308,  0.1679,  0.0663,\n",
       "                       0.0197,  0.1004,  0.1061,  0.0093,  0.0498, -0.0114,  0.1398, -0.1750])),\n",
       "             ('model.2.weight',\n",
       "              tensor([[[[ 1.2550e-02, -5.9838e-04,  9.9034e-03,  ..., -6.0007e-03,\n",
       "                         -9.2332e-03,  1.1722e-02]],\n",
       "              \n",
       "                       [[ 8.3137e-03, -5.5778e-03, -1.2214e-03,  ...,  1.8507e-02,\n",
       "                         -1.4655e-02, -3.3127e-03]],\n",
       "              \n",
       "                       [[-3.9808e-03, -1.1163e-02, -1.8099e-02,  ..., -5.0514e-03,\n",
       "                         -9.9818e-03, -1.6388e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2799e-02,  3.2926e-03,  9.7393e-03,  ..., -6.3410e-03,\n",
       "                          9.2586e-03,  4.9044e-03]],\n",
       "              \n",
       "                       [[ 1.2988e-02,  1.3112e-02, -7.2202e-03,  ...,  7.8375e-03,\n",
       "                         -1.8649e-02, -1.8044e-02]],\n",
       "              \n",
       "                       [[ 1.2318e-02,  1.2540e-02,  1.7123e-02,  ..., -1.9768e-03,\n",
       "                          4.5103e-03,  7.3049e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2768e-02, -6.7392e-03, -3.8875e-03,  ...,  8.2867e-03,\n",
       "                          1.8230e-02, -1.0362e-02]],\n",
       "              \n",
       "                       [[ 1.3557e-02,  3.5678e-03,  1.2907e-02,  ..., -7.7877e-03,\n",
       "                          1.9744e-03,  1.0003e-02]],\n",
       "              \n",
       "                       [[ 8.6246e-03,  1.8393e-02, -1.7515e-02,  ..., -3.5029e-03,\n",
       "                          1.2190e-02,  3.2008e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.9172e-03, -3.1335e-03, -7.9112e-03,  ..., -6.6791e-04,\n",
       "                          1.1838e-02, -1.7643e-02]],\n",
       "              \n",
       "                       [[-1.9466e-02,  2.6839e-03, -1.4933e-02,  ..., -7.1457e-03,\n",
       "                          7.2314e-03,  1.4143e-02]],\n",
       "              \n",
       "                       [[ 1.2049e-02, -1.3598e-02,  1.2479e-02,  ...,  6.0289e-03,\n",
       "                         -1.5724e-02, -1.9096e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.7047e-02,  1.9451e-02,  1.4716e-02,  ...,  4.7447e-03,\n",
       "                          9.0437e-03,  5.9704e-03]],\n",
       "              \n",
       "                       [[ 1.7375e-03, -1.1367e-02, -1.1607e-02,  ..., -6.4582e-03,\n",
       "                         -9.6913e-03,  2.5203e-03]],\n",
       "              \n",
       "                       [[ 1.3198e-02, -1.8942e-04, -1.9197e-02,  ...,  8.1980e-03,\n",
       "                         -1.6639e-02, -8.3463e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9958e-03,  1.1453e-02, -1.7021e-02,  ..., -1.9745e-02,\n",
       "                         -1.0053e-03,  3.8669e-03]],\n",
       "              \n",
       "                       [[ 1.1390e-02, -8.0463e-03,  1.3964e-02,  ...,  1.4985e-02,\n",
       "                         -8.2352e-03, -1.3881e-02]],\n",
       "              \n",
       "                       [[-1.3503e-02,  1.6867e-02,  1.3872e-02,  ...,  1.3400e-02,\n",
       "                         -1.8020e-02,  3.1666e-04]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-1.4275e-02, -4.2597e-03,  2.2668e-03,  ..., -1.2686e-03,\n",
       "                          1.6180e-02, -1.0053e-02]],\n",
       "              \n",
       "                       [[-1.1782e-02, -1.0807e-03,  1.8770e-02,  ..., -1.9317e-03,\n",
       "                         -1.6097e-02, -5.3981e-03]],\n",
       "              \n",
       "                       [[ 3.6392e-03, -1.6597e-02,  4.2220e-03,  ..., -6.4447e-03,\n",
       "                         -9.1702e-03,  5.8875e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0186e-02, -1.9752e-03, -8.7989e-03,  ...,  3.5746e-03,\n",
       "                          8.1752e-03,  9.5132e-03]],\n",
       "              \n",
       "                       [[-9.9774e-03, -1.5985e-02,  9.5521e-04,  ...,  1.8147e-02,\n",
       "                         -1.0397e-02,  7.3964e-03]],\n",
       "              \n",
       "                       [[-4.5440e-04,  1.9567e-02,  1.7617e-02,  ...,  1.2939e-02,\n",
       "                          4.5446e-03, -1.4393e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.2175e-03, -1.0820e-02, -1.3212e-02,  ...,  4.1944e-03,\n",
       "                          8.5528e-03, -9.0003e-03]],\n",
       "              \n",
       "                       [[-1.9319e-03, -1.8281e-02,  4.0747e-03,  ..., -5.7719e-03,\n",
       "                         -1.9279e-03,  3.8449e-03]],\n",
       "              \n",
       "                       [[-9.4464e-03,  4.5797e-03,  1.5458e-02,  ...,  1.5509e-02,\n",
       "                         -1.9203e-02,  1.1392e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 8.0440e-03,  5.7495e-04, -1.4641e-02,  ...,  1.9174e-02,\n",
       "                          7.1514e-04,  1.0234e-03]],\n",
       "              \n",
       "                       [[ 8.9254e-03,  2.7948e-03,  1.5740e-02,  ..., -1.4994e-02,\n",
       "                         -1.2728e-02, -1.3896e-02]],\n",
       "              \n",
       "                       [[ 1.6792e-02, -1.1370e-02,  8.5838e-03,  ...,  1.0450e-02,\n",
       "                         -6.6648e-03, -3.5513e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.9402e-03,  1.6132e-02,  1.6340e-02,  ..., -3.0254e-03,\n",
       "                         -6.1891e-03,  1.7914e-02]],\n",
       "              \n",
       "                       [[ 7.1197e-03, -5.8429e-03,  9.0410e-04,  ...,  8.7321e-03,\n",
       "                         -1.1029e-02,  1.1438e-02]],\n",
       "              \n",
       "                       [[-1.6730e-02,  1.3669e-03,  1.0671e-02,  ..., -1.4621e-02,\n",
       "                          6.2971e-03, -9.9210e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.6964e-03, -1.4068e-03, -4.5991e-03,  ...,  1.1652e-02,\n",
       "                         -1.1770e-02,  9.9665e-03]],\n",
       "              \n",
       "                       [[ 1.6831e-03, -9.6443e-03,  3.1063e-04,  ...,  2.0615e-04,\n",
       "                          8.4473e-04, -1.9258e-02]],\n",
       "              \n",
       "                       [[-3.3748e-03,  1.6460e-02,  1.3954e-02,  ...,  6.8568e-03,\n",
       "                         -2.9227e-05, -1.6483e-02]]]])),\n",
       "             ('model.2.bias',\n",
       "              tensor([ 1.9663e-02,  5.2012e-03,  2.9889e-03,  5.8058e-04,  6.4140e-03,\n",
       "                       6.6332e-03,  1.1817e-02,  1.5700e-02,  3.1364e-03,  1.4620e-02,\n",
       "                       1.5779e-02, -6.8276e-03, -1.1900e-02,  3.6435e-03, -1.4201e-02,\n",
       "                       2.3734e-03, -1.4985e-02, -6.8622e-03, -1.3540e-02, -1.0940e-02,\n",
       "                      -9.3039e-03,  1.4406e-02,  1.1901e-02, -1.9451e-02,  2.8305e-03,\n",
       "                       5.6662e-03, -5.4347e-03,  7.2185e-03,  5.9031e-03,  1.0594e-02,\n",
       "                       1.5387e-02, -8.3608e-03, -6.1919e-03,  1.0017e-02,  5.4367e-03,\n",
       "                       1.2280e-02, -1.5301e-02, -1.7078e-02, -1.1865e-02,  1.3518e-02,\n",
       "                      -6.6373e-03, -1.6635e-03, -7.3664e-03, -1.3806e-02, -1.6246e-02,\n",
       "                      -1.2126e-03,  1.0540e-02,  1.8604e-02,  1.8822e-02, -1.3584e-02,\n",
       "                      -5.2878e-04,  7.4661e-03, -1.6176e-02,  8.9776e-03,  1.6807e-02,\n",
       "                       1.3687e-02, -1.1205e-02,  6.2188e-03, -1.4609e-02, -1.7423e-02,\n",
       "                       1.0324e-02, -9.1557e-03,  1.5422e-02, -6.0772e-03, -8.2676e-03,\n",
       "                       6.3172e-03, -1.2286e-02, -6.1303e-03, -1.5524e-02,  5.4852e-04,\n",
       "                      -1.2031e-02,  7.2599e-03,  4.4918e-04, -1.5347e-02,  6.7101e-03,\n",
       "                       1.3307e-03, -3.8117e-03,  1.2975e-03,  2.1620e-03, -1.2212e-02,\n",
       "                       1.2946e-02,  1.3421e-02,  6.2285e-03,  9.9386e-03, -5.1338e-03,\n",
       "                       1.5693e-02,  8.3683e-03, -6.3711e-03,  1.3858e-02, -3.6639e-03,\n",
       "                       1.5095e-02, -1.2741e-02, -1.6686e-02, -6.0612e-03,  4.5759e-03,\n",
       "                       1.3704e-02, -8.0029e-03, -8.1955e-04,  1.4635e-02, -1.8784e-02,\n",
       "                      -6.4041e-03, -1.4708e-03,  1.5925e-02,  1.3457e-02, -1.1622e-03,\n",
       "                      -1.2866e-02, -1.9718e-03,  4.0439e-03, -6.6058e-03,  8.9549e-03,\n",
       "                      -1.4338e-02,  2.2871e-03, -1.5156e-02,  5.6519e-04,  1.1341e-02,\n",
       "                       3.0000e-03, -4.1556e-03,  1.0098e-02,  1.3999e-02,  1.7043e-02,\n",
       "                      -1.6065e-02,  1.6970e-02, -6.3825e-03,  5.9999e-03, -1.5055e-02,\n",
       "                       9.5856e-03, -8.7628e-03,  1.3789e-03,  1.2966e-02,  1.2884e-02,\n",
       "                       1.5738e-02, -2.8655e-03, -1.7775e-02,  1.5310e-03,  1.5970e-02,\n",
       "                       1.8955e-02, -1.8840e-02,  1.4493e-02, -1.7665e-03, -3.7751e-03,\n",
       "                      -5.6565e-03, -2.4846e-03,  9.5471e-03,  1.4944e-02, -1.9247e-03,\n",
       "                       1.4433e-02, -8.5083e-03, -1.5241e-02, -7.3288e-03, -1.2625e-02,\n",
       "                      -1.2132e-02,  2.5601e-03,  1.1507e-02,  4.4514e-03, -8.9428e-04,\n",
       "                       1.8217e-02, -5.4862e-03, -7.3175e-03, -5.2710e-03,  1.2885e-02,\n",
       "                       1.4417e-02, -6.8102e-03, -1.7870e-02,  1.4864e-02, -1.3165e-02,\n",
       "                       1.8610e-02,  4.9146e-03,  1.7225e-02,  7.0010e-03,  1.0582e-02,\n",
       "                      -2.4658e-04,  1.5135e-02, -7.0968e-03, -4.1712e-03, -1.2227e-03,\n",
       "                       9.2327e-03, -5.0410e-03,  6.3287e-03,  1.9501e-02, -9.8918e-03,\n",
       "                      -3.3330e-03,  1.0981e-02,  1.2108e-02,  8.0663e-03, -5.0003e-03,\n",
       "                       4.2621e-03,  1.6814e-02,  1.6628e-02,  5.2555e-03,  1.8275e-02,\n",
       "                       1.4813e-02, -1.8405e-02, -6.7293e-03,  1.8460e-02, -1.2158e-02,\n",
       "                       1.2124e-02, -1.2449e-02, -1.7241e-02, -3.0162e-03,  1.9437e-02,\n",
       "                       3.0502e-03,  1.1191e-02, -1.4115e-02,  5.2507e-03, -6.2491e-03,\n",
       "                      -8.1695e-03, -1.8222e-02,  1.8442e-02, -7.0383e-03, -5.8528e-03,\n",
       "                       1.8812e-02, -1.9242e-02, -4.7576e-03,  9.3570e-03, -1.0763e-02,\n",
       "                       1.1866e-02,  5.6623e-03,  1.0931e-02,  8.7112e-03,  1.5690e-02,\n",
       "                       6.9707e-03,  6.4198e-03,  7.7976e-03, -4.1907e-03,  9.4065e-03,\n",
       "                       1.2942e-02,  5.1293e-03,  7.7289e-03, -8.2623e-03,  1.6504e-02,\n",
       "                      -1.5608e-02,  8.6414e-03, -2.9308e-03,  1.1594e-02, -1.8413e-02,\n",
       "                       1.1097e-02, -1.4138e-02, -3.9880e-03, -8.4595e-03, -9.6988e-03,\n",
       "                       3.7637e-03, -1.3293e-04,  1.8458e-02,  1.6335e-02, -1.8342e-03,\n",
       "                       2.7942e-03,  5.1096e-03,  1.9353e-02,  1.4535e-02,  5.3529e-03,\n",
       "                       7.9359e-03,  4.1954e-03, -8.5654e-03,  7.0700e-03, -1.1058e-02,\n",
       "                       2.9226e-03, -7.8114e-03,  9.3658e-03, -8.2661e-03, -6.1030e-03,\n",
       "                      -2.9131e-03, -4.5071e-03,  4.0858e-03,  8.5820e-03, -4.8243e-03,\n",
       "                       7.6737e-04, -1.8740e-02,  1.8180e-02,  6.5708e-03,  1.0697e-02,\n",
       "                       9.4583e-03, -1.6417e-02,  2.7557e-04,  2.7143e-03, -1.1747e-02,\n",
       "                      -1.1813e-02, -1.1311e-02, -5.7681e-03,  9.8512e-04,  1.8288e-02,\n",
       "                      -3.5755e-03,  1.3871e-02,  1.7878e-02,  1.1927e-05,  4.6085e-03,\n",
       "                      -9.4701e-03,  2.4901e-03,  1.0299e-02, -1.9071e-02,  1.3092e-02,\n",
       "                      -1.5929e-02,  1.5419e-03,  2.9891e-03, -3.3586e-03,  1.6707e-02,\n",
       "                       1.0881e-03, -8.8260e-03, -1.6248e-02,  2.7518e-03, -5.4312e-03,\n",
       "                       1.1475e-02, -1.4674e-02,  1.0490e-02, -9.9652e-03, -1.5162e-02,\n",
       "                      -1.4306e-02, -3.5743e-03,  1.7016e-02, -1.4103e-02,  8.5792e-03,\n",
       "                       7.7553e-03,  1.3636e-02, -1.7898e-03,  1.3310e-02, -1.5023e-03,\n",
       "                      -9.1245e-03, -5.9908e-03, -1.7235e-02,  6.7765e-03, -2.9131e-03])),\n",
       "             ('model.6.weight',\n",
       "              tensor([[[[ 3.4307e-03,  9.2668e-03,  3.0272e-03,  ...,  1.0970e-02,\n",
       "                         -4.5456e-04, -2.6589e-03]],\n",
       "              \n",
       "                       [[ 1.5744e-02,  1.8960e-02, -3.2418e-03,  ...,  1.2727e-02,\n",
       "                          6.2924e-03, -5.7023e-03]],\n",
       "              \n",
       "                       [[-6.4390e-03,  1.7480e-03,  5.7939e-03,  ..., -1.2320e-02,\n",
       "                         -1.9330e-02, -3.3029e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.7064e-03, -6.0359e-03, -1.7644e-02,  ..., -5.5923e-03,\n",
       "                         -7.1484e-03,  4.1025e-03]],\n",
       "              \n",
       "                       [[-1.5776e-02, -9.8782e-03, -3.8073e-03,  ...,  9.4566e-03,\n",
       "                         -1.1181e-02, -1.1571e-02]],\n",
       "              \n",
       "                       [[ 1.6891e-03, -1.0298e-02, -1.2733e-02,  ..., -1.7963e-02,\n",
       "                         -1.3341e-02,  2.8836e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7042e-03, -9.6428e-03, -1.1088e-02,  ...,  7.0115e-03,\n",
       "                          1.3558e-02, -1.0798e-02]],\n",
       "              \n",
       "                       [[-1.4086e-02,  1.0583e-02, -1.1986e-02,  ..., -1.4292e-02,\n",
       "                          1.5992e-02,  1.8916e-02]],\n",
       "              \n",
       "                       [[ 1.8182e-02,  3.9773e-03,  9.1904e-04,  ..., -1.2143e-02,\n",
       "                         -9.6610e-03, -1.4363e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.4262e-03,  1.4081e-02, -1.0821e-02,  ...,  1.3863e-02,\n",
       "                          1.9246e-02, -1.7537e-02]],\n",
       "              \n",
       "                       [[ 1.1814e-02, -6.9242e-03, -3.3052e-03,  ...,  1.5300e-04,\n",
       "                         -1.2459e-02, -1.0953e-03]],\n",
       "              \n",
       "                       [[-2.4181e-03,  1.9155e-02,  8.8723e-04,  ...,  1.3015e-02,\n",
       "                         -1.5770e-02, -1.1899e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9706e-02, -8.5939e-03, -1.2502e-02,  ..., -1.8752e-02,\n",
       "                          9.9233e-04,  5.4782e-03]],\n",
       "              \n",
       "                       [[ 1.1852e-03,  3.0029e-03, -6.7939e-03,  ...,  1.6903e-02,\n",
       "                         -1.0601e-02, -1.6708e-02]],\n",
       "              \n",
       "                       [[-2.6092e-03, -9.0270e-03, -1.2184e-02,  ...,  9.7431e-03,\n",
       "                          1.2251e-04,  1.0598e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.8885e-03, -1.5744e-03, -1.8176e-02,  ..., -7.5533e-03,\n",
       "                         -1.2146e-02, -1.8795e-02]],\n",
       "              \n",
       "                       [[ 1.0910e-02,  1.3066e-02, -3.9444e-03,  ...,  1.8500e-02,\n",
       "                          2.5138e-03, -1.9231e-02]],\n",
       "              \n",
       "                       [[ 1.6740e-02, -1.5134e-02, -6.1420e-03,  ...,  1.6977e-02,\n",
       "                          3.0404e-03, -3.1756e-04]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.8511e-02,  4.0053e-03, -1.5974e-02,  ...,  1.7300e-02,\n",
       "                         -1.3777e-02,  3.1187e-03]],\n",
       "              \n",
       "                       [[-1.2765e-02,  1.7461e-03,  1.7932e-02,  ...,  1.4159e-02,\n",
       "                         -5.9350e-03, -1.3962e-02]],\n",
       "              \n",
       "                       [[ 5.7680e-03,  8.8930e-03, -5.8271e-03,  ...,  9.5953e-03,\n",
       "                         -3.4992e-03,  1.5124e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.4719e-02,  1.5956e-03,  1.0850e-02,  ..., -3.4280e-03,\n",
       "                          1.4852e-02,  1.3489e-02]],\n",
       "              \n",
       "                       [[-9.7858e-03,  4.3761e-03, -1.2774e-02,  ..., -5.1441e-03,\n",
       "                          1.1093e-02, -1.3707e-02]],\n",
       "              \n",
       "                       [[-1.5334e-02, -2.2409e-03,  1.6898e-02,  ...,  3.5112e-04,\n",
       "                          4.4445e-03, -7.1558e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5815e-02, -9.6619e-03,  1.6212e-02,  ..., -3.8983e-03,\n",
       "                         -1.0962e-02, -1.7984e-02]],\n",
       "              \n",
       "                       [[-4.8223e-03,  9.2871e-03,  1.1372e-02,  ...,  3.0281e-03,\n",
       "                         -1.8897e-02,  1.6774e-02]],\n",
       "              \n",
       "                       [[ 1.2699e-03, -7.6859e-03, -4.0465e-03,  ...,  3.6971e-03,\n",
       "                         -1.3932e-02,  1.0561e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2322e-02,  1.2355e-02,  1.3144e-02,  ..., -9.8295e-03,\n",
       "                         -1.2204e-02, -1.8654e-02]],\n",
       "              \n",
       "                       [[ 6.3518e-03, -4.7095e-03, -1.9602e-02,  ..., -1.8971e-02,\n",
       "                         -1.2619e-02, -1.0682e-03]],\n",
       "              \n",
       "                       [[-1.0349e-02, -1.0888e-03, -1.5293e-02,  ..., -1.6873e-02,\n",
       "                          1.6346e-02,  8.9863e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1300e-02,  9.3444e-03,  7.8077e-04,  ...,  1.6085e-02,\n",
       "                          7.7715e-03, -1.5199e-02]],\n",
       "              \n",
       "                       [[ 1.6264e-03,  1.0550e-02,  3.9901e-04,  ...,  6.3565e-03,\n",
       "                          1.2109e-02, -1.7600e-02]],\n",
       "              \n",
       "                       [[-2.5872e-03,  1.2584e-02,  9.3803e-03,  ...,  1.1942e-02,\n",
       "                          1.1861e-02, -1.9635e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.7520e-05, -1.8393e-02, -6.3293e-03,  ..., -2.6339e-03,\n",
       "                         -1.7359e-02,  1.9628e-03]],\n",
       "              \n",
       "                       [[ 1.8759e-02, -5.4616e-03,  5.0769e-03,  ...,  2.0623e-03,\n",
       "                         -5.4304e-04, -1.0280e-02]],\n",
       "              \n",
       "                       [[ 3.2543e-03, -9.8526e-04, -1.4419e-03,  ...,  9.4418e-03,\n",
       "                         -1.8861e-02,  4.9268e-03]]]])),\n",
       "             ('model.6.bias',\n",
       "              tensor([-1.7035e-02, -1.6889e-02, -1.5487e-02,  2.8015e-03, -1.6491e-02,\n",
       "                      -3.2901e-03, -7.0108e-03, -3.0014e-03,  1.8806e-02, -1.8575e-02,\n",
       "                      -7.6075e-04,  4.7540e-03,  5.7129e-03, -7.8568e-03,  1.8141e-02,\n",
       "                       3.2911e-03,  3.7435e-03, -8.1407e-03, -2.8088e-03, -1.4767e-02,\n",
       "                       7.2051e-03,  1.6833e-02, -5.8990e-03, -3.8605e-03,  1.2497e-02,\n",
       "                       1.8742e-02, -1.9415e-02,  9.3538e-03, -1.5160e-02, -3.9184e-03,\n",
       "                      -5.0896e-03,  3.2118e-03, -4.5570e-03,  1.2101e-02, -1.4213e-02,\n",
       "                       7.7964e-03, -8.2092e-04,  1.8299e-02, -1.3061e-02, -1.0356e-02,\n",
       "                       2.3277e-03, -1.6326e-02, -1.0796e-02, -1.5374e-02,  1.4715e-02,\n",
       "                       7.9577e-03, -1.4283e-02,  8.1682e-03,  3.7538e-03, -8.8643e-03,\n",
       "                       1.7497e-02,  4.4320e-03,  1.0222e-02, -3.6849e-03, -7.6200e-03,\n",
       "                      -1.5919e-02,  4.5697e-03, -1.8628e-02,  9.9565e-03,  3.6368e-03,\n",
       "                       2.6822e-03,  1.1598e-02, -3.1407e-03, -1.4397e-02, -1.3613e-02,\n",
       "                      -1.0223e-02,  1.3645e-02, -2.9441e-03, -6.1362e-04,  2.6237e-03,\n",
       "                      -1.7101e-02,  4.8000e-03, -1.2812e-02, -1.9212e-02,  1.8289e-02,\n",
       "                      -1.9645e-02, -4.1646e-03,  1.6334e-02, -1.9054e-02, -1.4483e-02,\n",
       "                       9.9683e-03, -1.3020e-02, -1.7122e-03, -9.8247e-03, -8.9814e-03,\n",
       "                       8.8561e-03, -1.6455e-02, -1.9740e-02, -1.1623e-02,  3.7098e-03,\n",
       "                       1.0586e-02, -2.3973e-03,  8.2599e-03, -3.8163e-03, -5.7221e-03,\n",
       "                      -4.8253e-03,  1.5632e-02, -3.3098e-04,  1.1998e-02, -1.6040e-02,\n",
       "                      -1.2735e-02,  1.8047e-02, -1.4600e-02,  1.9151e-02,  2.1546e-03,\n",
       "                      -5.2370e-03, -4.4717e-03,  1.9606e-02,  8.3485e-03,  1.2547e-02,\n",
       "                       9.3907e-03,  5.9543e-03, -6.9206e-03, -1.9098e-02, -1.0464e-02,\n",
       "                      -6.4022e-03,  1.3706e-03,  4.4959e-03, -1.7043e-02, -5.3517e-03,\n",
       "                      -1.5618e-03, -1.2617e-02, -4.6000e-03, -5.1396e-03,  1.1999e-02,\n",
       "                      -5.3629e-03,  4.4227e-03,  1.5562e-02,  7.3946e-03, -7.5927e-03,\n",
       "                       1.9382e-02,  2.3284e-03,  2.8492e-03, -4.3644e-04,  1.4004e-02,\n",
       "                       1.1062e-02,  9.1766e-03, -1.5077e-02,  1.0592e-02, -7.9042e-03,\n",
       "                       3.5030e-03,  6.7040e-03, -4.6416e-03, -9.6093e-03,  4.0338e-03,\n",
       "                      -5.6233e-03, -1.5518e-02, -6.9438e-03,  1.3224e-02, -7.0876e-04,\n",
       "                       1.4307e-02, -1.9848e-03, -2.1064e-03, -3.1048e-05,  9.9087e-03,\n",
       "                       7.2862e-03, -1.2563e-02, -2.3557e-04,  1.2712e-03,  1.0474e-02,\n",
       "                      -7.3356e-03,  6.0347e-03,  2.2672e-03,  1.8232e-02, -4.5844e-03,\n",
       "                       5.6914e-03, -1.0679e-02, -1.2483e-03,  2.8008e-03,  1.0879e-02,\n",
       "                      -6.8047e-03, -1.1445e-02,  1.7421e-02, -7.4387e-03,  1.0175e-02,\n",
       "                      -1.2061e-02,  1.7563e-02, -8.8785e-03,  1.6569e-02, -5.0133e-03,\n",
       "                       5.5808e-03,  3.7354e-03,  1.9682e-02, -3.4611e-03,  1.2199e-02,\n",
       "                      -1.2574e-02, -1.6578e-03,  8.7349e-04,  3.0158e-04,  1.4288e-02,\n",
       "                       1.6525e-02, -3.6435e-03,  2.1274e-04,  7.0965e-03,  9.6862e-03,\n",
       "                      -4.8998e-03, -1.3486e-02,  1.4467e-03, -9.5176e-03, -1.1363e-02,\n",
       "                       1.3071e-02, -4.1706e-03,  1.4205e-03, -8.8260e-03, -4.3382e-03,\n",
       "                       1.4385e-02,  9.4111e-03,  6.8291e-03,  8.6717e-04, -1.8467e-02,\n",
       "                      -1.0387e-03, -9.5945e-06, -1.2303e-02,  1.3874e-02, -1.1865e-02,\n",
       "                      -2.7518e-03, -3.8115e-03,  1.2271e-02, -2.6756e-03,  2.5913e-04,\n",
       "                       1.0238e-02, -1.4512e-02, -1.4203e-02,  8.5625e-03,  4.3150e-03,\n",
       "                      -1.0313e-02, -1.1334e-02, -8.2329e-03,  2.0424e-03, -3.5258e-03,\n",
       "                      -1.9657e-02, -1.5838e-02, -3.5201e-03,  1.4432e-02, -7.2251e-03,\n",
       "                       1.9595e-02,  1.7241e-02,  3.6141e-03,  7.5710e-04,  3.1621e-03,\n",
       "                      -1.5093e-02, -6.3869e-03,  1.6719e-02, -1.6667e-02,  1.5521e-02,\n",
       "                      -1.2872e-02,  2.0437e-03, -1.0302e-02, -1.0843e-02, -1.9894e-03,\n",
       "                       2.3685e-03, -8.4041e-04,  1.5929e-02, -1.6659e-02, -1.2459e-02,\n",
       "                      -1.7505e-05, -1.8313e-02, -1.6682e-03, -1.3370e-02, -3.5769e-03,\n",
       "                       1.6426e-02,  1.8360e-02, -1.6141e-03,  1.5229e-02,  1.3194e-02,\n",
       "                       1.5264e-03,  4.3296e-03,  1.2763e-02, -1.6592e-02, -3.9402e-04,\n",
       "                      -3.0448e-03, -1.5285e-03,  6.2912e-03, -3.8588e-03, -1.3224e-03,\n",
       "                       3.2000e-03,  1.2124e-02,  1.9384e-02, -1.6175e-02, -1.8339e-02,\n",
       "                      -3.9606e-03,  2.2627e-03, -1.4936e-02, -1.5246e-03,  1.5653e-02,\n",
       "                       5.5585e-05,  1.5284e-02, -1.4046e-02,  5.9930e-03, -7.8622e-03,\n",
       "                      -5.0584e-03, -9.3692e-04, -1.6516e-02,  1.5445e-02,  3.8465e-03,\n",
       "                      -1.0185e-02,  5.3004e-03, -1.5268e-02, -1.6470e-02,  9.4125e-03,\n",
       "                       1.8445e-03,  8.1453e-03,  7.6519e-03,  1.3551e-02,  3.7735e-03,\n",
       "                       1.0089e-02,  1.3753e-02, -1.8275e-02,  1.1174e-03,  7.8852e-04,\n",
       "                      -6.0630e-03,  1.1104e-02, -1.0449e-02,  2.0121e-04, -1.0593e-02,\n",
       "                       6.2947e-04,  4.5875e-03, -5.8034e-03, -1.7992e-02, -7.1038e-03,\n",
       "                      -4.9469e-03, -1.4653e-02,  1.6600e-02, -6.1924e-03,  1.6930e-02,\n",
       "                      -7.0591e-04, -3.7213e-03, -5.0361e-03, -5.7791e-03,  1.7827e-02,\n",
       "                       7.9468e-03,  6.4741e-03, -1.5594e-02,  1.4202e-02, -8.4997e-03,\n",
       "                       3.7805e-03, -1.7836e-02, -9.3152e-03,  9.4474e-03,  1.0485e-02,\n",
       "                       1.1514e-02,  1.4428e-02,  3.6117e-03,  1.3750e-02, -6.4625e-03,\n",
       "                      -1.6637e-03,  1.3634e-02,  3.1062e-03,  1.5026e-02,  1.7925e-02,\n",
       "                      -2.9675e-03,  1.3198e-02,  2.1142e-03, -1.3459e-02,  1.0075e-02,\n",
       "                       7.2573e-03,  8.6700e-03,  1.6628e-02, -5.0384e-03, -5.9162e-03,\n",
       "                       8.8491e-03,  8.4816e-03, -4.4986e-03, -1.6284e-02, -1.8970e-02,\n",
       "                       1.9656e-02,  8.0758e-03,  1.1912e-02, -9.2847e-03,  4.0970e-03,\n",
       "                       1.6376e-02, -1.2673e-02,  1.3804e-02,  1.2322e-02, -1.7676e-02,\n",
       "                      -5.0017e-03,  6.2310e-03, -9.4914e-03,  9.3988e-03,  1.8892e-02,\n",
       "                       1.7008e-02, -3.0455e-03,  1.4747e-02, -1.3045e-02, -2.1427e-03,\n",
       "                      -1.3453e-02, -8.0365e-03, -1.0979e-02,  1.1902e-02,  5.7795e-03,\n",
       "                      -1.6952e-02, -1.0159e-03, -1.1424e-02, -6.8343e-03,  5.7070e-03,\n",
       "                      -1.2469e-02,  1.3069e-02,  5.9820e-03, -1.8881e-02, -8.1656e-03,\n",
       "                       7.0787e-03,  1.0894e-02,  1.9426e-03, -7.5256e-03,  7.6439e-03,\n",
       "                      -1.6554e-02,  1.8042e-02,  7.7383e-03, -7.4787e-03, -1.9273e-02,\n",
       "                      -1.3207e-02,  1.1119e-02, -1.2931e-03, -3.1048e-03, -6.7562e-03,\n",
       "                      -9.5595e-04,  1.7518e-02,  4.5171e-03,  1.9742e-02,  1.0922e-02,\n",
       "                       1.3494e-02, -1.5190e-02,  1.4377e-02,  9.6063e-03, -9.9104e-03,\n",
       "                      -1.6059e-02,  5.3986e-03, -1.5839e-02, -3.6710e-03,  6.1135e-03,\n",
       "                       1.6214e-02,  6.3483e-03,  1.5297e-02, -1.6418e-02, -3.1362e-03,\n",
       "                      -1.7012e-02,  3.1414e-03,  6.8194e-03,  3.5251e-03, -1.6442e-02,\n",
       "                      -7.7653e-03,  1.8503e-02, -1.8793e-02, -9.1342e-04,  1.1047e-02,\n",
       "                       1.0258e-02,  8.0956e-03, -3.7078e-03,  9.7248e-03, -9.3262e-04,\n",
       "                      -1.8167e-04, -3.1302e-03,  1.6844e-03, -6.8886e-03, -1.3254e-03,\n",
       "                      -1.5706e-02,  1.1137e-02,  1.7266e-02, -4.5982e-03, -6.1801e-03,\n",
       "                       1.3357e-02,  1.2744e-02,  8.2800e-03, -1.1725e-02, -1.4293e-03,\n",
       "                       2.9143e-03, -1.2731e-02, -1.0639e-02,  1.1387e-02, -1.9251e-02,\n",
       "                       2.4889e-03,  1.3594e-02, -1.3892e-03, -1.3302e-02,  1.1860e-02,\n",
       "                       1.9267e-02,  1.8287e-02,  5.5271e-03, -4.9228e-03, -4.3854e-03])),\n",
       "             ('model.8.weight',\n",
       "              tensor([[[[-6.8095e-03,  9.1776e-03, -5.8535e-05,  ...,  1.3286e-02,\n",
       "                          1.2027e-02,  5.9572e-03]],\n",
       "              \n",
       "                       [[-1.4756e-02, -1.2291e-02, -1.5115e-02,  ..., -3.0339e-03,\n",
       "                          6.9178e-03,  1.2980e-02]],\n",
       "              \n",
       "                       [[-1.9633e-03,  3.7151e-03,  7.8003e-03,  ..., -1.6071e-03,\n",
       "                         -1.2139e-02,  1.5146e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.8719e-03, -9.6613e-03, -1.1227e-03,  ..., -9.8432e-03,\n",
       "                         -4.7612e-03,  8.1608e-03]],\n",
       "              \n",
       "                       [[-6.7438e-03, -1.4147e-02, -2.7389e-04,  ..., -1.1858e-02,\n",
       "                         -1.8283e-03, -1.3828e-02]],\n",
       "              \n",
       "                       [[ 9.3675e-03,  7.8658e-03,  1.5138e-02,  ...,  1.0439e-02,\n",
       "                         -1.1425e-02, -1.4617e-04]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.5239e-03,  5.1989e-03,  7.1471e-03,  ...,  1.0984e-02,\n",
       "                         -1.5047e-02, -8.8053e-04]],\n",
       "              \n",
       "                       [[ 3.2058e-03, -1.5854e-02, -3.9729e-03,  ...,  1.4374e-02,\n",
       "                         -3.0369e-03,  7.4214e-03]],\n",
       "              \n",
       "                       [[ 1.0588e-02, -1.4945e-02, -6.8032e-03,  ..., -4.9905e-03,\n",
       "                          1.3537e-02,  1.3447e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.5291e-02, -7.1607e-03,  8.0140e-03,  ...,  3.4704e-03,\n",
       "                          6.2105e-03, -1.2666e-02]],\n",
       "              \n",
       "                       [[-8.8629e-03, -3.0922e-03, -1.5840e-02,  ...,  1.3269e-02,\n",
       "                         -2.0983e-03, -1.0876e-02]],\n",
       "              \n",
       "                       [[ 6.9794e-03, -1.1950e-03, -1.1511e-02,  ..., -1.0682e-02,\n",
       "                          7.9541e-03,  1.5816e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.4886e-02, -4.8780e-03,  5.6539e-03,  ...,  1.6064e-02,\n",
       "                         -1.3115e-02, -5.1414e-04]],\n",
       "              \n",
       "                       [[ 3.8689e-03, -4.1996e-03, -7.0123e-03,  ..., -1.5435e-02,\n",
       "                          6.7790e-03,  1.4335e-02]],\n",
       "              \n",
       "                       [[ 2.6200e-03, -1.3863e-02,  6.4104e-03,  ..., -9.3632e-03,\n",
       "                         -3.2447e-03, -6.7388e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.7295e-03,  8.7179e-03,  1.2850e-02,  ..., -1.0003e-02,\n",
       "                          9.3975e-03, -5.0389e-03]],\n",
       "              \n",
       "                       [[ 1.4714e-02,  9.4095e-03, -8.2553e-03,  ...,  1.0589e-02,\n",
       "                          8.7862e-03,  1.5692e-02]],\n",
       "              \n",
       "                       [[-5.0614e-03,  1.2319e-02,  8.4955e-03,  ...,  1.5011e-02,\n",
       "                         -5.6777e-03, -3.2840e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-4.4218e-03,  1.1504e-02,  9.8905e-03,  ..., -1.4230e-02,\n",
       "                          1.1179e-02, -3.1308e-03]],\n",
       "              \n",
       "                       [[-1.0867e-03, -2.7088e-04,  3.8497e-03,  ...,  2.7949e-03,\n",
       "                         -1.4910e-02, -2.8793e-03]],\n",
       "              \n",
       "                       [[-3.8725e-03, -1.1234e-02, -2.8855e-03,  ..., -1.0700e-02,\n",
       "                         -1.0895e-02, -1.4646e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3522e-03,  3.0346e-03, -4.8395e-03,  ..., -1.3029e-02,\n",
       "                         -1.0581e-02,  1.5944e-02]],\n",
       "              \n",
       "                       [[-1.1718e-02,  2.5982e-03, -1.4129e-02,  ...,  1.2795e-02,\n",
       "                         -3.0253e-03,  1.1087e-02]],\n",
       "              \n",
       "                       [[-2.8998e-03,  1.3248e-02,  2.1214e-03,  ...,  1.7843e-03,\n",
       "                          2.0004e-03,  7.2104e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.0280e-04, -3.8791e-05, -2.7435e-04,  ..., -1.0656e-02,\n",
       "                         -1.3536e-02, -9.6012e-03]],\n",
       "              \n",
       "                       [[-1.2369e-02,  1.1964e-02,  1.2509e-02,  ..., -5.4588e-03,\n",
       "                          2.4974e-03, -1.1885e-02]],\n",
       "              \n",
       "                       [[-5.3226e-03, -6.2066e-03,  1.4050e-02,  ..., -9.6586e-03,\n",
       "                         -2.6824e-03,  1.2862e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-9.7902e-03,  1.3164e-02, -2.9439e-03,  ..., -2.9503e-03,\n",
       "                          6.3778e-03,  2.1858e-03]],\n",
       "              \n",
       "                       [[-1.3193e-02, -9.9205e-03, -5.3289e-03,  ..., -3.8587e-04,\n",
       "                         -9.9191e-03,  1.0373e-02]],\n",
       "              \n",
       "                       [[ 9.7364e-03,  4.0708e-03, -1.5872e-02,  ..., -6.7195e-03,\n",
       "                         -2.1994e-03,  3.3323e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.5423e-02,  1.5871e-02, -1.1074e-02,  ..., -4.8316e-04,\n",
       "                         -9.0586e-03, -1.0553e-02]],\n",
       "              \n",
       "                       [[ 4.7570e-03, -9.9194e-03,  1.4512e-02,  ...,  1.2386e-02,\n",
       "                          1.5623e-02, -4.4690e-03]],\n",
       "              \n",
       "                       [[ 2.1886e-03, -2.7684e-03,  1.5509e-02,  ..., -1.1860e-02,\n",
       "                         -9.7213e-03,  2.2376e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.7522e-04,  1.4866e-02, -1.1193e-02,  ..., -4.7513e-03,\n",
       "                         -1.8464e-03,  9.6448e-03]],\n",
       "              \n",
       "                       [[ 1.5417e-02,  3.0355e-03,  3.2325e-03,  ...,  1.5396e-03,\n",
       "                          1.4984e-02,  3.6521e-03]],\n",
       "              \n",
       "                       [[-7.7141e-03,  2.3247e-03, -8.1672e-03,  ...,  6.4192e-03,\n",
       "                          1.6637e-03, -4.3285e-03]]]])),\n",
       "             ('model.8.bias',\n",
       "              tensor([ 8.5807e-04,  1.0766e-02,  9.6747e-03, -7.5450e-04,  1.4991e-02,\n",
       "                      -1.5145e-02, -1.4603e-02,  7.7453e-03,  1.2763e-02, -1.3110e-02,\n",
       "                      -7.8542e-03, -3.5554e-03,  1.4202e-02,  1.1798e-02,  4.0199e-04,\n",
       "                       1.4233e-02,  9.1248e-03,  9.0698e-03,  1.0357e-02, -4.5863e-03,\n",
       "                       1.2585e-02, -1.4146e-02, -4.7960e-03, -1.5127e-02, -4.1466e-03,\n",
       "                       2.6006e-03, -2.3011e-03, -6.9724e-03,  5.6573e-03,  1.2091e-02,\n",
       "                       1.0289e-02,  9.9432e-03, -4.5128e-03, -1.5355e-02,  1.5985e-02,\n",
       "                      -1.6096e-02, -1.2478e-02, -1.4708e-02,  5.9134e-03,  9.9355e-03,\n",
       "                       1.5255e-02,  1.3639e-03,  1.1644e-02,  1.2502e-04,  1.3779e-02,\n",
       "                       5.5182e-04, -8.5653e-03, -4.2176e-03,  1.3360e-02,  1.3278e-02,\n",
       "                       1.4103e-02,  2.8800e-03,  6.1712e-03,  1.5785e-02,  7.7504e-03,\n",
       "                       5.8863e-03,  1.3234e-02,  8.9752e-03, -1.0646e-02, -5.1714e-03,\n",
       "                       7.6763e-03,  4.8307e-04, -7.6170e-03, -1.3506e-02,  2.6823e-03,\n",
       "                       1.3874e-03, -2.6126e-03, -3.4244e-03, -2.4408e-03, -7.1646e-04,\n",
       "                      -4.7752e-03,  1.2936e-02,  1.4318e-02, -3.2198e-03,  8.7138e-03,\n",
       "                      -9.4885e-03,  2.6696e-03,  3.6798e-05,  1.3885e-02,  6.8194e-03,\n",
       "                      -4.9739e-03, -1.2776e-02, -1.4281e-02, -1.0547e-02,  4.5504e-03,\n",
       "                      -1.4459e-02, -9.5616e-03, -1.3539e-02, -1.8706e-03, -1.9994e-03,\n",
       "                      -3.5880e-03, -8.0146e-03, -8.7227e-03,  4.0679e-03,  8.4267e-03,\n",
       "                      -1.7195e-03,  6.0296e-03, -6.8049e-03,  1.1875e-03,  3.3328e-03,\n",
       "                      -1.2064e-02,  7.8455e-03, -1.5601e-02,  2.7151e-03,  9.2755e-03,\n",
       "                      -9.3586e-03,  7.6447e-04, -4.5131e-03, -1.0218e-02, -1.0726e-02,\n",
       "                       9.7780e-04,  6.1426e-03,  1.4124e-02, -7.3502e-03,  1.0934e-02,\n",
       "                       3.7765e-03,  8.4807e-03, -5.6123e-04,  4.6892e-03,  1.3447e-02,\n",
       "                      -1.0626e-02,  1.5066e-02, -1.5616e-02,  5.9671e-03,  7.0736e-03,\n",
       "                      -1.2979e-02, -1.4993e-02,  1.6108e-02,  9.5635e-03, -7.5999e-03,\n",
       "                      -3.4711e-03, -2.5796e-04,  2.2661e-03, -4.2722e-03, -6.2255e-03,\n",
       "                      -1.4723e-02,  3.8410e-03,  1.4738e-02, -1.5649e-02,  1.9698e-03,\n",
       "                       7.5251e-03,  8.7674e-03, -7.3884e-03, -1.4078e-02,  1.8323e-03,\n",
       "                      -1.6003e-02, -5.4394e-03, -1.1831e-02, -1.1563e-02,  6.2672e-03,\n",
       "                       8.3690e-03,  8.9571e-03, -7.2344e-03,  2.9429e-03,  3.5321e-03,\n",
       "                       6.9843e-04, -5.0936e-03, -7.3030e-03, -1.0686e-02,  1.1723e-02,\n",
       "                       3.8881e-03, -1.3364e-02,  3.6449e-03, -4.0962e-03,  1.0585e-02,\n",
       "                      -5.0717e-03,  1.4887e-03,  8.9399e-03, -1.6097e-03, -1.4180e-02,\n",
       "                      -7.7427e-03,  1.3718e-03, -9.0859e-03, -3.0262e-03,  6.4641e-03,\n",
       "                       6.2998e-04,  7.3301e-03,  1.3938e-02,  1.4709e-02,  1.6596e-03,\n",
       "                       1.3279e-02, -3.4236e-03, -1.4586e-02, -1.0162e-02,  8.9526e-03,\n",
       "                       1.4117e-02, -1.9198e-03,  9.0623e-03,  7.0462e-03,  6.7266e-03,\n",
       "                       1.4466e-03, -1.2251e-02, -1.2460e-02, -3.4640e-03,  6.4027e-03,\n",
       "                      -1.1603e-03, -1.8816e-03, -1.2997e-02, -1.5725e-02, -1.3330e-02,\n",
       "                      -7.4662e-03,  8.7787e-03,  4.1705e-03,  2.4287e-03, -1.0602e-02,\n",
       "                      -1.4305e-03, -1.1801e-02, -6.0869e-03, -7.9434e-04,  1.2788e-02,\n",
       "                      -8.8589e-03,  1.4491e-02,  8.7944e-03,  3.2788e-03, -6.4411e-03,\n",
       "                       1.4028e-02, -8.5492e-03, -1.4915e-02, -8.7681e-03,  2.6704e-03,\n",
       "                       7.4450e-03, -7.7545e-03,  4.6592e-03, -9.4809e-07,  7.1602e-03,\n",
       "                      -5.9589e-03,  3.3216e-03, -7.9056e-03,  1.2734e-02, -1.3629e-02,\n",
       "                      -7.4996e-03, -6.2439e-03, -1.3131e-02,  3.6610e-03,  9.4122e-03,\n",
       "                      -1.5924e-02,  1.4664e-03,  3.5796e-03, -8.0140e-03,  2.4567e-04,\n",
       "                      -1.2469e-02, -1.1657e-02,  1.6041e-02, -2.3907e-04, -6.9656e-03,\n",
       "                      -2.2211e-03, -1.2450e-02,  8.1282e-03,  1.5633e-02,  1.4521e-02,\n",
       "                       1.1653e-02, -1.5370e-02, -7.3355e-03,  7.7222e-03,  9.3137e-03,\n",
       "                      -1.0950e-02, -7.8706e-03,  1.3987e-02, -1.1332e-02,  7.8006e-03,\n",
       "                      -1.5495e-02,  1.1010e-02, -1.4267e-02, -1.0348e-02, -1.1402e-02,\n",
       "                      -8.1045e-03,  7.2495e-03,  2.0811e-03, -1.4601e-02, -1.0437e-02,\n",
       "                      -6.4818e-03, -5.3107e-03,  1.0152e-02, -1.3098e-02,  1.4389e-02,\n",
       "                      -3.7349e-03,  8.9681e-03, -1.3428e-02,  9.3353e-03,  1.5187e-02,\n",
       "                       1.3632e-02,  2.8179e-03, -4.2298e-03,  6.8443e-04, -1.0094e-02,\n",
       "                      -8.2465e-03,  7.1471e-04,  6.8664e-03,  1.5556e-02,  7.7975e-03,\n",
       "                      -8.2033e-03, -9.4653e-03,  7.5023e-03, -1.2125e-03, -1.1863e-02,\n",
       "                       6.1074e-03, -2.0329e-03,  1.4121e-02,  1.3024e-02,  4.1703e-03,\n",
       "                      -1.0262e-02,  8.1992e-03,  5.2009e-03, -4.9856e-03, -9.9926e-03,\n",
       "                       1.0258e-02, -1.4385e-02, -1.2351e-02, -4.7424e-03, -4.0899e-03,\n",
       "                      -8.3372e-03,  4.0226e-03,  8.6195e-03,  2.4691e-03,  1.2869e-02,\n",
       "                      -1.0995e-02, -1.4487e-03,  1.5147e-02,  1.6013e-02,  1.1336e-02,\n",
       "                       9.5977e-03, -1.4241e-02, -1.1183e-02,  1.1874e-03, -1.0300e-02,\n",
       "                       8.7995e-03,  1.5848e-02, -3.6089e-03, -8.9940e-03,  1.4632e-02,\n",
       "                       6.8932e-03,  9.0831e-03,  1.2140e-02, -8.3987e-03,  1.8652e-04,\n",
       "                      -1.2909e-02,  6.8730e-03,  3.7025e-03, -9.7603e-04,  1.2309e-02,\n",
       "                      -7.8707e-03,  4.5126e-03,  1.2730e-02,  1.0518e-02, -8.4622e-03,\n",
       "                      -1.5289e-02,  3.2919e-03,  1.1950e-02, -6.6454e-03,  1.5449e-02,\n",
       "                       8.5674e-03,  9.1106e-03, -1.4729e-02, -8.5939e-03, -1.1244e-02,\n",
       "                      -1.5961e-02, -9.3076e-03,  7.4670e-03,  1.3610e-02,  1.4116e-02,\n",
       "                      -8.3163e-03, -1.1873e-02, -2.5335e-03,  1.5320e-02,  1.3715e-02,\n",
       "                      -3.8301e-03, -1.0322e-02, -1.5036e-02,  1.9817e-03,  6.8487e-03,\n",
       "                      -1.3136e-02,  1.3422e-02,  8.0836e-03, -1.3274e-03,  1.3064e-02,\n",
       "                      -7.4130e-03,  1.3226e-02,  9.9272e-03,  1.2418e-02, -1.0415e-02,\n",
       "                      -4.2041e-03,  6.9110e-03, -1.2898e-02, -1.0285e-02, -1.5799e-02,\n",
       "                       2.2372e-03, -1.5565e-02,  3.1864e-03,  6.6222e-03,  1.2544e-02,\n",
       "                       1.3865e-02, -1.1684e-02,  1.1147e-02,  1.4132e-02, -6.6233e-03,\n",
       "                      -2.9752e-04, -1.7943e-04,  1.5048e-03,  9.3034e-03, -1.4629e-02,\n",
       "                       1.2824e-02, -1.9146e-03, -4.8192e-04,  4.4750e-03,  1.2475e-02,\n",
       "                      -1.4914e-02,  1.0159e-02,  1.5487e-02,  1.9473e-03,  6.6845e-03,\n",
       "                      -9.2406e-03, -1.3999e-03, -9.1820e-03, -1.1005e-04, -1.1535e-02,\n",
       "                      -1.3077e-03,  5.6873e-03, -2.6887e-03,  7.7314e-03,  1.0559e-02,\n",
       "                       1.1731e-02, -1.3440e-02,  2.3454e-03, -4.6378e-03, -1.4688e-04,\n",
       "                       1.9403e-03,  1.0154e-02, -8.1548e-03,  5.4738e-03,  1.4893e-02,\n",
       "                       1.2400e-02,  2.9272e-03,  4.3580e-05, -7.5898e-03, -1.5752e-02,\n",
       "                       8.4647e-03, -1.5794e-02, -5.0581e-03, -1.4427e-02,  1.2099e-02,\n",
       "                       2.1706e-03,  5.9864e-03, -3.5744e-03, -2.9431e-03, -5.9688e-05,\n",
       "                       1.0552e-02, -1.3064e-02, -1.1499e-02,  4.4749e-04,  1.3567e-02,\n",
       "                      -1.1085e-02, -1.5411e-02,  6.0408e-03, -9.3985e-03, -1.5775e-02,\n",
       "                      -1.4053e-04,  5.4010e-03, -1.1595e-02,  4.4405e-03,  1.2304e-02,\n",
       "                       7.1097e-03, -3.1397e-03,  1.3632e-02, -4.7405e-03,  7.8421e-04,\n",
       "                      -1.5037e-02,  3.7696e-04, -1.5590e-02, -1.5025e-02,  7.6076e-03,\n",
       "                       1.1114e-02, -1.2704e-02, -3.8486e-03, -4.3329e-03,  1.1783e-02,\n",
       "                       1.3898e-02,  1.9252e-03,  9.5870e-03, -1.0218e-03,  1.2653e-03])),\n",
       "             ('model.12.weight',\n",
       "              tensor([[[[ 1.4668e-02,  1.4124e-02, -6.2371e-03,  ...,  7.2782e-03,\n",
       "                          9.2661e-03,  1.5931e-02]],\n",
       "              \n",
       "                       [[-4.5711e-03, -1.3397e-02,  1.3596e-02,  ...,  1.4815e-02,\n",
       "                          6.6301e-03, -9.2633e-03]],\n",
       "              \n",
       "                       [[-9.2989e-03,  1.2295e-02, -8.7987e-03,  ..., -3.8763e-03,\n",
       "                          1.1511e-02, -8.6580e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.2722e-03, -3.3630e-03, -5.3451e-03,  ...,  1.5617e-02,\n",
       "                         -6.7204e-03,  1.3566e-02]],\n",
       "              \n",
       "                       [[-9.4109e-03, -3.2115e-03, -1.0082e-02,  ..., -2.4376e-03,\n",
       "                         -9.4265e-03,  1.2027e-02]],\n",
       "              \n",
       "                       [[-3.1795e-03,  1.2937e-02,  7.5962e-03,  ..., -1.2091e-02,\n",
       "                         -9.1082e-03, -2.8762e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.2289e-03,  1.1508e-02, -6.7944e-03,  ..., -1.0808e-02,\n",
       "                         -1.1492e-03,  1.0141e-02]],\n",
       "              \n",
       "                       [[ 1.3877e-02,  1.3846e-02, -1.5510e-02,  ..., -4.7868e-03,\n",
       "                          1.1000e-02,  1.5485e-02]],\n",
       "              \n",
       "                       [[-2.8028e-03, -5.2345e-03, -1.3172e-02,  ...,  1.1970e-02,\n",
       "                         -8.9228e-03,  6.0959e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.0480e-02,  4.5889e-03,  4.4883e-04,  ...,  1.1731e-02,\n",
       "                          9.7356e-03, -1.4665e-02]],\n",
       "              \n",
       "                       [[ 1.4123e-02, -9.3018e-03, -5.6033e-03,  ...,  1.4861e-02,\n",
       "                          8.2786e-03,  6.7013e-03]],\n",
       "              \n",
       "                       [[-3.1508e-03,  1.5851e-02, -9.4071e-04,  ...,  1.5774e-03,\n",
       "                          1.3243e-02, -1.2739e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.3809e-02,  1.9169e-03, -7.5649e-03,  ...,  6.3580e-04,\n",
       "                          1.4205e-02, -5.9985e-03]],\n",
       "              \n",
       "                       [[-9.6684e-03, -1.4788e-03,  9.9660e-03,  ..., -9.0388e-03,\n",
       "                          3.4272e-03, -1.0716e-02]],\n",
       "              \n",
       "                       [[-1.2121e-02, -6.8836e-03,  4.8222e-03,  ..., -1.2922e-02,\n",
       "                         -8.6240e-03, -1.9573e-05]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.5211e-03, -4.3684e-03,  4.3437e-03,  ...,  2.2622e-03,\n",
       "                         -1.1193e-02,  5.7465e-03]],\n",
       "              \n",
       "                       [[ 1.6680e-03,  2.9645e-03,  1.1743e-02,  ..., -6.1649e-03,\n",
       "                          1.5605e-02, -7.8615e-03]],\n",
       "              \n",
       "                       [[-5.3122e-03, -1.4113e-03,  1.3503e-02,  ..., -3.6838e-03,\n",
       "                         -1.0719e-02, -6.4593e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-5.5537e-03, -2.8508e-03, -4.4952e-03,  ...,  6.5345e-03,\n",
       "                          1.5707e-02,  1.4120e-02]],\n",
       "              \n",
       "                       [[ 7.1098e-03,  1.3741e-02,  1.4463e-02,  ...,  1.3313e-02,\n",
       "                          1.3673e-02, -1.4700e-02]],\n",
       "              \n",
       "                       [[-1.3381e-02, -5.6165e-03,  1.1931e-02,  ...,  1.3074e-02,\n",
       "                          1.1788e-02, -1.0393e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3884e-02,  1.0466e-02,  1.0439e-02,  ..., -1.1912e-02,\n",
       "                          1.4529e-02,  7.7544e-03]],\n",
       "              \n",
       "                       [[-1.4719e-03,  1.1420e-02,  1.4517e-02,  ..., -5.3345e-03,\n",
       "                         -1.4461e-03,  2.7608e-03]],\n",
       "              \n",
       "                       [[ 6.0300e-03, -6.9958e-03, -8.9108e-03,  ...,  1.4986e-02,\n",
       "                         -1.0353e-02, -1.3405e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.3353e-04, -8.2267e-03,  1.1009e-02,  ..., -6.8184e-03,\n",
       "                         -3.3520e-03, -8.9714e-03]],\n",
       "              \n",
       "                       [[ 2.4644e-03, -1.0703e-02, -7.8425e-03,  ...,  1.1286e-02,\n",
       "                          6.6185e-03, -1.5587e-02]],\n",
       "              \n",
       "                       [[-9.2849e-03,  5.2480e-03,  1.2654e-02,  ...,  2.0258e-03,\n",
       "                          2.7699e-04,  1.1975e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.9316e-03,  1.1683e-03, -8.8556e-03,  ..., -4.5840e-03,\n",
       "                         -9.0285e-04, -8.5047e-04]],\n",
       "              \n",
       "                       [[ 1.2002e-02, -1.2998e-02, -2.6964e-03,  ..., -2.7538e-04,\n",
       "                         -1.2254e-02, -5.5048e-03]],\n",
       "              \n",
       "                       [[-1.2229e-02,  1.7429e-03,  1.1677e-02,  ..., -1.4564e-02,\n",
       "                          1.5455e-02, -1.4944e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.9128e-04,  9.5853e-03,  4.0990e-03,  ..., -1.2547e-03,\n",
       "                         -1.4985e-03, -6.4896e-03]],\n",
       "              \n",
       "                       [[-1.3160e-02,  1.5508e-02,  4.9763e-03,  ..., -1.0733e-02,\n",
       "                         -1.2594e-02, -5.3261e-03]],\n",
       "              \n",
       "                       [[-1.4774e-02, -1.2956e-02,  1.5025e-02,  ..., -1.4534e-02,\n",
       "                          8.8255e-03,  1.0605e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.0739e-02,  4.3012e-04,  8.0171e-04,  ..., -7.1045e-04,\n",
       "                         -1.3081e-02,  1.0035e-02]],\n",
       "              \n",
       "                       [[-4.8482e-03,  1.4214e-02,  1.1054e-02,  ...,  4.5943e-03,\n",
       "                          1.1139e-02,  1.0190e-02]],\n",
       "              \n",
       "                       [[-2.0640e-03, -1.3940e-02, -5.4725e-03,  ..., -1.4586e-02,\n",
       "                          1.1138e-02,  6.5811e-03]]]])),\n",
       "             ('model.12.bias',\n",
       "              tensor([ 6.8466e-03,  2.4579e-05, -5.5898e-03,  4.8378e-03,  4.4534e-03,\n",
       "                       1.5673e-02, -1.3598e-02,  3.8855e-03, -1.5442e-02, -1.3562e-02,\n",
       "                       1.4150e-02, -1.5976e-02,  4.2729e-03, -2.1573e-03, -1.0164e-02,\n",
       "                      -5.8423e-03,  9.5259e-03, -5.4861e-03,  3.2799e-03, -1.0421e-02,\n",
       "                       1.3923e-02,  1.3387e-02, -1.4080e-02,  4.1733e-03,  1.4084e-02,\n",
       "                       8.8982e-03, -4.8839e-03,  1.0100e-02,  4.9279e-03, -3.4052e-03,\n",
       "                       2.5816e-03, -4.7001e-04,  6.9833e-03,  3.5390e-03,  9.0345e-03,\n",
       "                      -4.2449e-03,  9.2505e-04,  1.5356e-02, -4.3515e-03, -7.2379e-03,\n",
       "                       1.3773e-02, -9.0125e-03, -6.6920e-03,  6.0373e-03,  6.6300e-03,\n",
       "                       9.7893e-03,  5.4483e-04,  1.2656e-02,  8.8817e-03,  1.2641e-02,\n",
       "                      -6.1756e-03,  1.4192e-02, -1.2756e-02, -1.1983e-02, -2.7143e-03,\n",
       "                       2.2755e-03, -8.1369e-03, -4.7979e-03, -1.0581e-02, -1.3921e-02,\n",
       "                      -6.7340e-03, -1.5411e-02, -1.2138e-02, -4.7488e-03, -8.7910e-03,\n",
       "                      -6.0708e-03, -1.5871e-02, -9.8179e-04,  7.0986e-03, -6.9800e-03,\n",
       "                       1.3190e-02, -4.1158e-03,  8.8101e-04, -9.6572e-03, -2.9843e-03,\n",
       "                      -7.0734e-03,  1.1117e-02,  1.8067e-03,  1.0530e-02, -5.1043e-03,\n",
       "                      -4.3886e-03,  1.4449e-02, -7.1757e-03, -1.2732e-03, -1.3151e-02,\n",
       "                       4.4523e-03,  1.1391e-02, -1.2921e-02,  2.0225e-03,  7.9012e-03,\n",
       "                      -6.0546e-03,  1.1738e-02, -1.1726e-02,  6.5101e-03, -8.2524e-03,\n",
       "                      -1.5150e-02, -4.7456e-03,  1.0404e-02,  1.1193e-02, -1.7191e-03,\n",
       "                       1.5809e-02,  2.8772e-04, -1.0830e-02,  1.4722e-02, -7.7455e-03,\n",
       "                      -1.1867e-02, -6.6871e-03,  8.8404e-03,  2.3801e-04,  1.3608e-02,\n",
       "                       1.4319e-03,  1.5034e-02,  7.4411e-03,  1.5797e-02, -4.2332e-03,\n",
       "                       1.2172e-02,  4.4842e-03, -7.7550e-03,  5.7152e-03,  5.7774e-03,\n",
       "                      -3.6047e-03, -1.9758e-03, -8.4321e-03,  1.8308e-03,  1.4166e-02,\n",
       "                      -1.2457e-02, -1.3780e-05, -1.7556e-03, -1.3344e-02, -1.1780e-02,\n",
       "                      -1.5079e-02,  1.3608e-02,  6.8145e-03, -1.6648e-03, -1.0064e-02,\n",
       "                       1.0179e-02,  9.3492e-05,  2.1474e-03,  1.2905e-02, -1.4116e-02,\n",
       "                       1.1910e-02,  6.5679e-03, -8.2671e-03,  8.4870e-03, -1.3664e-02,\n",
       "                      -1.1028e-02,  1.5799e-02,  9.8245e-03, -9.8160e-03,  1.2218e-02,\n",
       "                       8.6996e-03,  3.6391e-03,  7.8591e-04, -1.1073e-02,  8.9695e-03,\n",
       "                      -1.4590e-02,  3.7536e-03, -2.5382e-03,  1.4836e-03, -3.5500e-03,\n",
       "                       1.0398e-02, -2.2649e-03, -3.4454e-03, -1.5680e-03, -8.3541e-03,\n",
       "                       3.4521e-03, -1.2966e-02, -1.0543e-03,  1.4175e-02,  7.1577e-03,\n",
       "                       8.5531e-03,  1.5754e-03,  8.0245e-03, -6.2984e-03,  1.3714e-03,\n",
       "                       1.4408e-02, -1.0492e-02,  1.1375e-02, -5.2991e-03,  7.8443e-03,\n",
       "                       8.1673e-03, -5.0489e-03, -3.3062e-03,  3.3823e-03, -1.3178e-03,\n",
       "                       7.8951e-04, -8.0922e-03, -2.2255e-03, -1.2269e-02,  1.1262e-02,\n",
       "                       1.2521e-02,  9.6731e-03,  1.6091e-02, -6.9516e-03,  1.5016e-02,\n",
       "                       6.0324e-03,  1.3831e-02, -1.9722e-03, -1.3400e-02,  6.7559e-03,\n",
       "                      -5.2775e-03, -8.9283e-03,  1.0914e-02,  5.1313e-04, -1.2490e-02,\n",
       "                       3.5918e-04,  1.3103e-02,  6.8329e-04,  7.8763e-03, -3.8808e-03,\n",
       "                       1.5056e-02, -1.5894e-02, -3.9358e-03,  6.6066e-03, -8.2861e-04,\n",
       "                      -1.5924e-02, -1.0504e-02,  3.8455e-03,  2.2857e-03, -7.1087e-03,\n",
       "                      -1.2999e-02, -6.5057e-03, -3.7114e-03,  2.8706e-03, -5.3189e-03,\n",
       "                      -4.5667e-03,  1.0326e-02,  1.0477e-02, -1.0483e-02,  4.7575e-03,\n",
       "                       1.8227e-03,  4.4855e-03,  1.1264e-02,  6.4248e-03, -1.5580e-02,\n",
       "                       5.9759e-03, -1.3058e-02, -1.4924e-02,  1.3697e-02, -1.4557e-02,\n",
       "                       1.1964e-02,  5.0363e-03,  5.0420e-03, -5.1876e-03, -6.6308e-03,\n",
       "                       1.7651e-03,  2.2113e-04,  4.8524e-03, -2.2943e-03, -9.0528e-03,\n",
       "                      -1.2458e-03,  1.5927e-02,  5.3269e-03,  1.6883e-03, -1.2414e-03,\n",
       "                       2.5929e-03, -1.2832e-02,  1.0726e-02, -1.1122e-02,  1.2335e-02,\n",
       "                      -8.0264e-03, -1.2171e-02, -7.2483e-03,  9.2475e-03, -1.0839e-02,\n",
       "                       3.8341e-03, -4.1281e-03,  2.0848e-03, -1.5689e-02,  1.3141e-03,\n",
       "                      -5.4168e-03, -1.5022e-02, -1.5998e-02, -7.0580e-03,  1.0019e-02,\n",
       "                      -8.0990e-03, -9.3400e-03,  1.2100e-02,  1.6019e-02,  1.5819e-02,\n",
       "                      -1.1740e-02,  1.0698e-02,  8.3253e-03, -1.3316e-02,  5.5635e-03,\n",
       "                      -7.7427e-03, -1.2649e-02, -1.0667e-03, -4.4150e-04,  6.8702e-03,\n",
       "                       9.0294e-03,  1.1121e-02, -6.5832e-03,  1.6132e-02,  1.0142e-02,\n",
       "                       1.1764e-02,  1.3285e-02,  1.5130e-02,  1.2882e-02,  1.2668e-02,\n",
       "                       3.2123e-03, -9.4110e-03,  9.6402e-03, -6.4559e-03,  2.4187e-03,\n",
       "                      -1.5663e-02, -6.0482e-03, -1.2554e-02,  3.4839e-03, -1.9548e-03,\n",
       "                       4.7318e-03,  8.1906e-03, -6.3627e-03,  1.3284e-02,  3.5925e-03,\n",
       "                       2.6569e-04, -2.5071e-03, -3.1411e-04, -8.6973e-03, -7.7086e-03,\n",
       "                       1.0396e-02,  1.3409e-02, -2.4880e-03,  7.1733e-03,  1.5159e-02,\n",
       "                      -6.5324e-03,  9.8703e-04, -2.1662e-03, -1.6123e-02,  4.1913e-03,\n",
       "                       9.5851e-03, -1.2098e-02, -5.0771e-03,  4.9092e-03, -1.3527e-03,\n",
       "                       1.4733e-02, -2.7941e-03,  1.3109e-02, -1.3916e-02,  1.0124e-02,\n",
       "                       1.2133e-02, -2.4594e-03, -1.1313e-02,  8.2953e-03,  7.0067e-03,\n",
       "                      -9.2181e-03, -2.7926e-03,  1.5249e-02, -4.2428e-03, -1.1884e-02,\n",
       "                       1.2834e-02,  4.1792e-03, -1.1738e-02,  2.6200e-03, -7.0363e-03,\n",
       "                       1.5258e-02, -1.1700e-02,  9.6676e-03,  1.3257e-02,  7.8375e-04,\n",
       "                       3.6523e-03, -1.5073e-02, -8.4727e-03,  4.7112e-03, -4.9440e-03,\n",
       "                       9.7311e-04,  5.6617e-03, -1.5158e-02,  6.0362e-03,  4.6414e-03,\n",
       "                      -1.6867e-03,  1.5964e-02, -7.4648e-03,  6.3925e-03, -1.3706e-02,\n",
       "                      -5.2570e-03, -6.9232e-04, -6.3306e-03, -3.1259e-03,  1.0831e-02,\n",
       "                       1.3913e-02, -4.5285e-03,  8.5440e-03, -2.6585e-03, -1.5991e-02,\n",
       "                      -1.0310e-02,  6.9409e-03, -2.1087e-03,  1.8721e-03, -9.8485e-03,\n",
       "                       7.0339e-03,  1.2553e-02, -1.5957e-02, -9.1716e-03,  2.2496e-03,\n",
       "                       1.7074e-03,  1.4550e-02,  1.5028e-02,  5.4091e-04,  1.5131e-02,\n",
       "                       1.4573e-02, -1.3274e-02, -1.5026e-02,  3.6390e-03, -9.4891e-03,\n",
       "                       7.8947e-03,  9.3027e-03, -6.4082e-03, -6.7930e-04,  4.9609e-03,\n",
       "                      -5.8215e-03,  1.3912e-02,  3.3205e-03, -1.3426e-02, -1.0187e-02,\n",
       "                      -4.5937e-03,  6.6176e-03,  1.2679e-02, -1.4134e-02, -1.5041e-02,\n",
       "                       3.0317e-03,  7.6875e-03,  2.5829e-03, -1.1173e-02,  3.9672e-03,\n",
       "                      -5.0286e-03,  1.3519e-02,  4.0055e-03, -1.2416e-02,  1.4296e-02,\n",
       "                      -1.4963e-02, -1.3188e-03,  4.3330e-03, -3.0639e-03, -5.1735e-03,\n",
       "                       1.4092e-02,  1.2704e-02,  3.7756e-04, -5.6651e-03,  8.5733e-03,\n",
       "                       4.8404e-03, -1.0718e-02,  2.1464e-03,  1.6785e-03,  7.4975e-03,\n",
       "                      -6.6034e-03, -1.8245e-03,  1.1375e-02,  7.0348e-03, -4.4275e-03,\n",
       "                      -1.0987e-03, -5.3597e-03,  2.2803e-03, -1.1717e-02,  1.2473e-02,\n",
       "                       1.2977e-02,  1.2947e-02, -8.6159e-03,  1.5760e-02, -9.9063e-05,\n",
       "                       1.2684e-03, -6.3950e-03,  7.7061e-03, -3.5076e-03,  1.2139e-02,\n",
       "                      -1.1737e-02, -4.5691e-03,  8.1845e-03, -6.3345e-03, -1.3647e-02,\n",
       "                      -8.9752e-04,  2.8304e-03, -1.5276e-02,  1.0834e-02, -7.4467e-03,\n",
       "                       8.7847e-03, -1.3023e-02,  1.4270e-02, -1.3787e-02, -5.2539e-03,\n",
       "                      -1.1910e-02, -9.1774e-03, -1.1335e-02, -1.1714e-02, -6.9884e-03,\n",
       "                       2.4377e-03, -4.6847e-03, -3.0112e-03, -7.0529e-03, -1.6044e-02,\n",
       "                      -1.8551e-03,  1.3093e-02, -2.7501e-03, -1.0874e-02, -7.9117e-03,\n",
       "                       9.4753e-03, -9.7077e-03,  1.2277e-02, -8.7698e-03,  5.6953e-03,\n",
       "                       9.5266e-03, -1.2021e-03, -1.2401e-02,  1.5437e-02, -1.1717e-02,\n",
       "                       1.4275e-02, -1.3602e-02, -1.4929e-02,  5.8052e-03, -2.7755e-03,\n",
       "                       1.2864e-02, -1.4312e-02,  1.5350e-02,  3.9707e-03, -1.0620e-02,\n",
       "                      -1.1969e-02,  3.0972e-03,  9.3666e-03,  1.3648e-02, -1.2916e-02,\n",
       "                      -1.4373e-03, -8.6112e-03, -9.1892e-03, -1.1061e-02, -1.2866e-02,\n",
       "                       1.8098e-03, -8.0113e-03, -9.6054e-03, -4.5567e-03,  1.0618e-02,\n",
       "                       5.9733e-03, -2.9577e-03, -8.2856e-03, -1.0076e-02, -1.1377e-02,\n",
       "                      -5.1781e-03,  4.4888e-03,  9.4560e-03, -2.0381e-03, -1.5786e-02,\n",
       "                       8.0698e-03, -1.3316e-02, -1.1965e-02, -3.8366e-03, -9.8293e-03,\n",
       "                       1.3256e-02,  1.7716e-03,  1.0008e-03,  3.6648e-03, -1.3149e-02,\n",
       "                       7.2993e-03,  6.9300e-03, -7.6145e-03, -4.3278e-03,  1.1858e-02,\n",
       "                       2.6206e-03,  7.6280e-03, -1.9661e-03, -4.4747e-03,  5.4092e-03,\n",
       "                       4.0851e-03,  1.2487e-02, -8.1821e-03,  9.0880e-03, -8.1185e-03,\n",
       "                       1.5447e-02, -2.4383e-03, -6.7257e-03,  9.9350e-03, -1.5541e-02,\n",
       "                       1.4810e-03, -1.2622e-02,  9.1516e-03, -1.0168e-02,  1.4469e-02,\n",
       "                      -1.3876e-02,  1.0145e-02, -8.6413e-03,  5.4324e-03,  7.1281e-03,\n",
       "                      -4.9247e-03,  6.6460e-03, -8.6791e-03,  7.9322e-03,  1.5411e-02,\n",
       "                       4.5246e-03, -1.1427e-02,  8.0106e-03,  1.7628e-03,  9.5107e-03,\n",
       "                       6.9956e-03, -7.0854e-03, -7.9773e-03, -4.0034e-03, -1.3435e-02,\n",
       "                       1.3341e-03, -3.4430e-03,  9.8552e-04,  4.8167e-03, -1.2678e-02,\n",
       "                      -7.6735e-03, -7.8941e-03, -1.1218e-02,  1.3583e-02,  6.6193e-03,\n",
       "                       5.7838e-03, -1.4395e-02, -6.0223e-03, -2.6397e-03, -1.3120e-02,\n",
       "                       7.1556e-03,  1.3640e-02,  1.4114e-02,  1.1200e-02,  6.0688e-03,\n",
       "                       4.5289e-03, -1.0635e-02,  1.2860e-03,  6.2661e-03,  7.6935e-04,\n",
       "                      -8.0094e-04,  1.0295e-02,  8.0359e-03,  1.3345e-02,  6.1199e-03,\n",
       "                       2.7315e-03,  5.7084e-03,  3.2219e-04, -3.1328e-03,  1.0197e-02,\n",
       "                      -1.6276e-03,  7.4591e-03,  1.0792e-03,  1.3513e-02,  4.3520e-03,\n",
       "                      -1.7916e-03,  1.5612e-02,  1.3072e-02,  2.0354e-03,  9.7360e-03])),\n",
       "             ('model.14.weight',\n",
       "              tensor([[[[ 0.0091, -0.0014, -0.0115,  ..., -0.0076,  0.0091, -0.0025]],\n",
       "              \n",
       "                       [[ 0.0091,  0.0054, -0.0076,  ...,  0.0093,  0.0057,  0.0133]],\n",
       "              \n",
       "                       [[ 0.0112,  0.0089,  0.0043,  ..., -0.0054,  0.0095,  0.0126]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0035, -0.0010,  0.0031,  ...,  0.0071,  0.0060, -0.0061]],\n",
       "              \n",
       "                       [[-0.0057, -0.0134, -0.0050,  ...,  0.0061, -0.0051, -0.0070]],\n",
       "              \n",
       "                       [[ 0.0034,  0.0067,  0.0030,  ..., -0.0136,  0.0070,  0.0050]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0090, -0.0139, -0.0123,  ..., -0.0097,  0.0008, -0.0056]],\n",
       "              \n",
       "                       [[-0.0124,  0.0128,  0.0056,  ...,  0.0101, -0.0054, -0.0131]],\n",
       "              \n",
       "                       [[ 0.0033,  0.0018,  0.0121,  ..., -0.0025, -0.0089, -0.0127]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0075,  0.0094,  0.0002,  ..., -0.0065, -0.0070,  0.0066]],\n",
       "              \n",
       "                       [[-0.0051,  0.0103, -0.0001,  ...,  0.0050,  0.0134, -0.0106]],\n",
       "              \n",
       "                       [[ 0.0015, -0.0038, -0.0055,  ..., -0.0094,  0.0069,  0.0111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0125, -0.0124,  0.0019,  ..., -0.0074, -0.0055,  0.0139]],\n",
       "              \n",
       "                       [[ 0.0010, -0.0041, -0.0029,  ..., -0.0070, -0.0096,  0.0050]],\n",
       "              \n",
       "                       [[-0.0087,  0.0101,  0.0038,  ...,  0.0026, -0.0071, -0.0111]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0106,  0.0064, -0.0102,  ...,  0.0106, -0.0018,  0.0016]],\n",
       "              \n",
       "                       [[-0.0038,  0.0126,  0.0084,  ...,  0.0084, -0.0057,  0.0123]],\n",
       "              \n",
       "                       [[-0.0013, -0.0113, -0.0081,  ...,  0.0057, -0.0039, -0.0099]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0132, -0.0036, -0.0081,  ..., -0.0008,  0.0056, -0.0039]],\n",
       "              \n",
       "                       [[-0.0047, -0.0032,  0.0137,  ..., -0.0128, -0.0053,  0.0095]],\n",
       "              \n",
       "                       [[-0.0134, -0.0033, -0.0028,  ..., -0.0062,  0.0136,  0.0052]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0102,  0.0041, -0.0042,  ...,  0.0112,  0.0041, -0.0132]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0132,  0.0105,  ...,  0.0052, -0.0058, -0.0065]],\n",
       "              \n",
       "                       [[-0.0139,  0.0062,  0.0068,  ...,  0.0094, -0.0058, -0.0118]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0074,  0.0025, -0.0027,  ...,  0.0107, -0.0089,  0.0095]],\n",
       "              \n",
       "                       [[-0.0003,  0.0118, -0.0066,  ..., -0.0136, -0.0059, -0.0070]],\n",
       "              \n",
       "                       [[ 0.0057,  0.0125, -0.0072,  ...,  0.0094, -0.0080,  0.0082]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0104,  0.0039,  0.0131,  ...,  0.0041,  0.0026,  0.0024]],\n",
       "              \n",
       "                       [[ 0.0124,  0.0075, -0.0053,  ...,  0.0036,  0.0126,  0.0072]],\n",
       "              \n",
       "                       [[ 0.0074,  0.0076, -0.0039,  ..., -0.0074, -0.0134, -0.0035]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0097,  0.0132,  0.0064,  ...,  0.0056,  0.0059, -0.0108]],\n",
       "              \n",
       "                       [[-0.0060, -0.0095, -0.0113,  ...,  0.0043, -0.0039,  0.0082]],\n",
       "              \n",
       "                       [[ 0.0082,  0.0071,  0.0120,  ..., -0.0027,  0.0049, -0.0076]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0050, -0.0025, -0.0110,  ..., -0.0004, -0.0083, -0.0100]],\n",
       "              \n",
       "                       [[ 0.0086,  0.0100, -0.0077,  ..., -0.0016,  0.0005, -0.0095]],\n",
       "              \n",
       "                       [[-0.0124, -0.0044,  0.0048,  ..., -0.0112, -0.0037, -0.0131]]]])),\n",
       "             ('model.14.bias',\n",
       "              tensor([-7.0501e-04,  1.3702e-02,  6.7369e-03,  4.6810e-04,  4.8549e-03,\n",
       "                      -9.2899e-03,  1.1963e-02, -1.3373e-03,  7.5271e-03,  9.4622e-03,\n",
       "                      -8.4471e-03, -1.1061e-02, -6.5934e-03,  7.9681e-05,  5.2849e-03,\n",
       "                      -1.3448e-02,  1.3223e-02, -1.3509e-02, -5.9831e-03,  5.9870e-03,\n",
       "                      -1.3845e-02,  6.8650e-03,  1.2185e-02,  1.1189e-02, -4.1633e-03,\n",
       "                       6.6254e-03, -7.5582e-03,  2.0885e-03,  6.5117e-03,  4.3112e-03,\n",
       "                      -1.1671e-03, -1.0286e-02, -8.0022e-03,  1.0358e-02,  1.1630e-02,\n",
       "                      -1.1165e-02,  2.5330e-03,  1.0939e-02,  2.9158e-03,  1.2681e-02,\n",
       "                      -1.3632e-02,  5.9444e-03, -5.5170e-03, -7.4006e-03,  3.7311e-03,\n",
       "                      -1.1738e-02, -7.0540e-04,  3.9018e-03, -7.2923e-03, -8.9807e-03,\n",
       "                       8.0732e-03, -1.3728e-02,  5.2136e-03,  1.0997e-02, -3.1683e-04,\n",
       "                      -7.7523e-03,  4.7156e-03,  4.6214e-03, -4.5116e-04,  9.3099e-03,\n",
       "                      -6.6395e-03, -1.2354e-02, -1.1587e-02, -5.0836e-03, -1.1610e-03,\n",
       "                       9.4198e-03, -7.7923e-04, -6.1204e-04, -9.8387e-03,  1.0693e-02,\n",
       "                       1.4071e-03, -1.7386e-03, -2.8062e-03,  5.3582e-03, -1.6776e-03,\n",
       "                       4.2785e-03, -7.7083e-03, -1.1536e-02, -1.0503e-02,  1.5341e-03,\n",
       "                      -5.2072e-03, -3.2047e-03,  8.7860e-03, -9.0252e-03,  6.6679e-03,\n",
       "                      -5.4201e-04,  1.3829e-02, -8.8666e-03, -1.3871e-02,  1.6653e-04,\n",
       "                      -9.2048e-03, -1.1517e-02,  9.9224e-03, -1.0885e-02,  1.3676e-02,\n",
       "                      -5.5534e-03, -2.3467e-03, -8.6934e-03,  1.0177e-02,  1.3579e-03,\n",
       "                      -7.0232e-03,  6.3380e-03, -9.9612e-03, -2.2167e-03, -9.5230e-03,\n",
       "                       2.5504e-03, -1.3648e-02,  9.6695e-03,  5.2139e-03, -2.3971e-03,\n",
       "                       9.4481e-04, -1.1383e-02,  1.4653e-03, -5.7771e-03,  2.2669e-03,\n",
       "                      -1.3607e-02, -1.3136e-03, -9.9896e-03, -2.4065e-03, -5.1030e-03,\n",
       "                      -9.2281e-04, -1.1394e-02, -3.1298e-03, -8.1244e-03,  3.3503e-04,\n",
       "                      -9.4374e-03, -8.1259e-03,  1.8665e-03,  7.4959e-03,  7.2578e-03,\n",
       "                       3.3020e-03,  6.1722e-03,  2.8585e-03, -7.2276e-03,  1.0104e-02,\n",
       "                       4.0784e-03,  7.0423e-03,  1.3599e-03,  8.8112e-03,  3.1693e-03,\n",
       "                      -8.4979e-03,  6.4747e-04,  2.1590e-03, -7.1017e-03, -4.1706e-03,\n",
       "                      -5.4723e-03,  8.8295e-03, -4.8737e-03,  1.2926e-02,  2.8092e-03,\n",
       "                      -5.4215e-03,  7.2910e-03, -3.7018e-04, -4.1263e-03, -7.9665e-04,\n",
       "                       2.5578e-04,  1.5643e-03, -1.3182e-02, -7.5580e-03, -2.2687e-03,\n",
       "                      -7.6779e-03,  1.3443e-02,  1.1722e-02,  4.3046e-03,  8.2807e-03,\n",
       "                      -1.6793e-03,  1.3163e-02,  1.2070e-03, -8.8558e-03, -4.8890e-03,\n",
       "                      -5.4540e-03, -1.3943e-02,  1.6778e-03,  7.4310e-03,  8.9221e-03,\n",
       "                      -3.3975e-03, -7.4144e-04,  6.5281e-03,  1.1499e-02,  8.7054e-03,\n",
       "                       1.2351e-02, -1.9276e-03,  6.8945e-03, -5.5073e-03,  4.1297e-03,\n",
       "                       5.5925e-03,  1.8942e-03, -1.3274e-02,  7.1173e-03, -7.7002e-03,\n",
       "                       9.8460e-03, -6.4749e-03,  5.0971e-03,  6.2838e-03, -1.0757e-02,\n",
       "                      -6.1495e-03,  1.1920e-02, -5.4656e-03, -1.9775e-03,  7.1501e-03,\n",
       "                      -1.0342e-05,  2.7256e-03, -1.0395e-02,  3.4073e-03, -1.6711e-04,\n",
       "                      -2.5579e-03, -5.6556e-03,  5.6816e-03,  3.1052e-03, -9.7308e-03,\n",
       "                       2.2935e-03, -1.3527e-02, -4.0219e-04, -8.7177e-03,  6.8295e-04,\n",
       "                      -4.2420e-03,  4.6693e-03, -8.2361e-03,  4.1860e-03, -4.6663e-03,\n",
       "                      -4.5900e-03, -4.7516e-03,  3.8891e-03, -1.0957e-02, -3.4808e-03,\n",
       "                      -9.5145e-03,  1.1782e-02, -2.8539e-03, -1.2017e-02,  2.9825e-03,\n",
       "                       4.9406e-03, -4.2072e-04,  2.4746e-03, -1.0406e-02,  9.6886e-03,\n",
       "                       1.0670e-02,  1.0264e-02, -1.1287e-02,  6.4361e-03,  1.7473e-03,\n",
       "                      -3.1905e-03, -2.0411e-03, -1.3660e-03,  7.8325e-03,  5.7071e-04,\n",
       "                       7.2004e-03,  6.5169e-03,  7.6962e-03,  4.5485e-03, -6.1443e-03,\n",
       "                       1.1149e-02, -6.0689e-03, -7.2218e-03, -4.9172e-03, -3.1232e-03,\n",
       "                      -6.8753e-03, -5.1664e-03, -7.5151e-04,  3.9768e-03,  5.9852e-03,\n",
       "                       9.1528e-03,  7.0302e-03,  4.5453e-03,  3.8658e-03,  3.3932e-03,\n",
       "                      -2.9160e-03,  1.7575e-04, -3.9877e-04, -3.7985e-03,  2.6437e-03,\n",
       "                       1.0307e-02, -8.6033e-03, -7.1736e-03,  9.5457e-03, -1.1556e-02,\n",
       "                      -2.2628e-03,  8.7342e-03, -9.2865e-03, -7.1111e-03,  1.1806e-02,\n",
       "                       7.6776e-03,  1.2422e-02,  2.1138e-03,  1.6413e-03,  1.3214e-02,\n",
       "                       1.0066e-02,  1.6753e-03,  2.3520e-03, -1.3950e-03,  2.1253e-03,\n",
       "                      -1.0170e-02, -4.8650e-03,  7.9733e-03,  4.5557e-03,  1.3008e-02,\n",
       "                       1.2429e-02, -7.2413e-03,  5.4621e-03,  1.2374e-02,  8.7454e-03,\n",
       "                      -1.0026e-02,  6.2286e-04,  9.4911e-03, -1.3984e-03, -6.1759e-03,\n",
       "                      -1.2355e-02, -8.2521e-03, -5.0945e-03,  1.1345e-02, -2.7292e-03,\n",
       "                      -8.3735e-03,  3.1650e-03, -1.1546e-02, -1.1979e-02, -9.9263e-04,\n",
       "                      -1.0437e-02, -7.0914e-03,  1.8012e-03, -8.9723e-03,  1.1623e-02,\n",
       "                      -1.0040e-02, -5.5397e-04, -3.7023e-03, -2.5062e-03,  1.3283e-02,\n",
       "                      -1.1854e-02,  8.1203e-03, -1.2191e-02,  1.0609e-02, -1.2483e-02,\n",
       "                       3.8850e-03,  6.0814e-03,  7.4149e-03, -1.3085e-02, -3.2748e-03,\n",
       "                       1.2592e-02, -1.1278e-02,  3.6608e-04, -1.1698e-03,  1.1525e-02,\n",
       "                      -9.4514e-03,  2.2771e-03, -1.0378e-02,  9.5987e-03, -1.9303e-03,\n",
       "                       1.1223e-02,  1.2580e-02,  8.3708e-03,  1.7058e-03, -3.6159e-03,\n",
       "                      -5.3014e-04, -1.1225e-03,  7.9850e-03, -3.9797e-03, -1.1984e-02,\n",
       "                       9.8494e-03, -6.2330e-03, -1.3652e-02,  1.3414e-02, -1.9251e-03,\n",
       "                      -1.3910e-02, -2.3657e-03, -2.5995e-03,  8.9478e-03, -4.5172e-03,\n",
       "                       1.3518e-02, -3.6694e-03, -1.3876e-02,  3.6187e-03, -8.5003e-03,\n",
       "                      -1.3405e-03,  8.8750e-03,  5.0153e-03,  1.3709e-02,  9.0098e-03,\n",
       "                      -4.5147e-03,  6.0740e-03,  5.2500e-03,  2.9810e-03,  6.4732e-03,\n",
       "                      -2.9208e-03,  4.7300e-03, -4.8372e-03,  2.3501e-03,  6.0306e-03,\n",
       "                       1.0369e-02, -7.6717e-04,  1.0697e-02, -1.1153e-02, -9.8311e-03,\n",
       "                      -1.3696e-02, -1.1375e-02,  3.5654e-03, -1.1841e-02, -9.6113e-03,\n",
       "                       1.8661e-03, -9.4872e-03,  1.3943e-02,  1.0420e-02, -1.3471e-03,\n",
       "                       5.2472e-03,  2.4512e-04, -2.0319e-03,  1.2141e-02,  1.6371e-04,\n",
       "                       9.9285e-03, -1.2382e-02, -7.5736e-03,  2.2590e-03, -1.2720e-02,\n",
       "                      -7.1141e-03, -1.1385e-02,  1.2966e-02,  1.6613e-03, -8.2087e-06,\n",
       "                       8.0964e-03, -5.3488e-03, -1.3308e-02,  1.0107e-02, -1.1047e-02,\n",
       "                      -1.1140e-02,  1.0769e-02, -2.6088e-04, -2.6907e-03, -1.2442e-02,\n",
       "                       9.7845e-03,  4.0369e-04,  1.0948e-02,  1.0182e-03, -1.0752e-02,\n",
       "                      -1.6629e-03,  2.3424e-03,  9.3989e-03,  4.1859e-03,  6.3985e-03,\n",
       "                      -1.3710e-02, -5.7822e-03,  8.8767e-03, -3.7100e-03, -1.1687e-02,\n",
       "                      -1.1528e-02,  7.9811e-03, -6.8686e-04,  1.1973e-02, -4.0295e-03,\n",
       "                       3.5349e-03, -1.0978e-02,  8.1352e-03,  9.3075e-04, -6.7538e-03,\n",
       "                      -8.3656e-03,  4.7724e-03, -2.9711e-04, -3.6263e-03, -4.7495e-03,\n",
       "                      -8.6566e-03, -9.1464e-03, -9.7559e-03, -2.8198e-03,  5.6199e-03,\n",
       "                       1.8895e-03, -2.4404e-04, -3.9696e-03, -1.7500e-03,  1.9618e-03,\n",
       "                       5.2768e-03, -7.3024e-03,  2.8871e-03, -6.9873e-03, -1.3540e-02,\n",
       "                      -1.1256e-02,  2.8093e-03, -5.2807e-03,  5.1118e-03, -1.3814e-02,\n",
       "                       1.1727e-02,  1.8686e-03, -8.4786e-03,  9.1927e-03,  9.4688e-05,\n",
       "                       5.2429e-03, -1.3532e-02,  8.0385e-03,  3.7331e-03, -2.7792e-03,\n",
       "                       5.8280e-03,  1.2374e-02, -7.9468e-03, -9.0348e-03,  6.7661e-03,\n",
       "                      -1.2007e-02, -1.6203e-03, -9.6076e-03, -1.5714e-03, -2.7733e-03,\n",
       "                       1.1209e-02,  1.0108e-02,  1.1674e-02, -3.1099e-03, -4.1186e-03,\n",
       "                      -2.3357e-03, -5.5373e-03,  3.4577e-04,  4.3954e-03, -1.1177e-02,\n",
       "                      -8.9200e-03,  8.7202e-03,  5.4767e-03, -1.8530e-03,  3.9399e-03,\n",
       "                       4.0613e-03, -1.0664e-02, -1.3673e-02, -7.3448e-03,  9.6964e-03,\n",
       "                       4.7710e-03,  5.4296e-03, -1.3940e-02,  1.1211e-02,  5.9134e-03,\n",
       "                       9.3684e-03, -1.3352e-02, -8.9679e-03, -5.8487e-03, -5.2446e-03,\n",
       "                       2.6992e-03, -1.0820e-02, -3.3443e-03, -2.4626e-03, -2.3513e-03,\n",
       "                       6.2068e-03, -4.5427e-03, -1.0783e-02,  1.3765e-02, -8.3824e-03,\n",
       "                      -4.7976e-03, -2.2344e-03,  1.3681e-02,  1.2389e-02, -1.6974e-04,\n",
       "                      -9.4093e-03, -4.5004e-03, -4.7950e-03, -4.2760e-03,  3.7467e-06,\n",
       "                      -1.1229e-02,  1.1410e-02,  9.8917e-03,  2.7963e-03, -8.9602e-03,\n",
       "                      -1.9116e-03,  5.9197e-03,  1.0446e-02,  1.2554e-02, -2.4387e-03,\n",
       "                       9.0280e-04,  8.8544e-03,  1.3976e-03,  4.4970e-03, -5.7156e-03,\n",
       "                       4.3230e-03,  8.4302e-03,  3.9847e-03,  4.4153e-04, -4.5101e-03,\n",
       "                      -1.2942e-02,  8.9507e-03,  8.3814e-03,  1.0969e-02,  9.8280e-03,\n",
       "                       7.2840e-03,  1.2020e-02, -1.2634e-02,  9.1668e-03,  1.1402e-02,\n",
       "                       3.0574e-03,  2.3987e-03, -1.2781e-02, -1.2883e-02, -5.3937e-03,\n",
       "                      -5.5722e-03,  1.2775e-02,  9.3818e-03,  5.8138e-03,  7.8696e-03,\n",
       "                      -1.3758e-02, -7.0285e-03, -1.0885e-02,  3.2088e-03, -8.6593e-03,\n",
       "                       4.7429e-03, -8.2898e-03, -1.0370e-02, -9.2631e-03,  7.0485e-04,\n",
       "                      -1.4524e-03, -1.1529e-02,  7.8701e-03,  8.3230e-03,  5.8369e-03,\n",
       "                      -3.8471e-03, -7.1712e-03,  1.1254e-02,  9.0218e-03, -9.7268e-03,\n",
       "                       3.6878e-03,  1.1616e-02,  1.3260e-02, -4.8904e-03,  6.5077e-03,\n",
       "                       6.5349e-03,  6.0173e-03,  1.1786e-02, -1.0943e-02, -1.3375e-05,\n",
       "                      -3.8759e-03, -1.3479e-02, -4.4799e-03,  7.2571e-03, -9.3526e-03,\n",
       "                       5.6878e-03,  4.4037e-03, -5.2359e-06, -7.7237e-03,  1.1403e-02,\n",
       "                       1.2796e-02, -1.2304e-02,  1.1755e-02, -1.9121e-03,  1.2557e-02,\n",
       "                      -1.1839e-02,  5.1111e-04,  1.0839e-02,  1.2450e-03, -1.0946e-02,\n",
       "                      -1.2250e-02,  1.3504e-02,  7.4991e-03, -1.2767e-02, -8.1171e-03])),\n",
       "             ('model.18.weight',\n",
       "              tensor([[ 5.7569e-03, -5.4044e-03,  1.0644e-02,  ..., -7.2736e-03,\n",
       "                        4.1270e-03,  9.2203e-04],\n",
       "                      [ 6.1262e-03, -4.8252e-03,  8.1451e-04,  ..., -6.8582e-03,\n",
       "                       -6.8728e-04,  7.1738e-04],\n",
       "                      [-6.7597e-03, -1.0403e-02,  1.0973e-02,  ...,  3.6397e-03,\n",
       "                       -7.1142e-03,  3.6532e-04],\n",
       "                      ...,\n",
       "                      [ 1.6152e-03, -5.2341e-03,  7.0286e-03,  ..., -1.5867e-03,\n",
       "                        6.1046e-03,  2.9921e-03],\n",
       "                      [-3.9429e-05,  1.0469e-03, -1.1045e-02,  ..., -6.5644e-04,\n",
       "                       -4.2350e-03, -2.8742e-03],\n",
       "                      [ 6.8078e-03, -8.3039e-03,  1.0711e-02,  ..., -3.3252e-04,\n",
       "                       -4.1624e-03, -1.5092e-03]])),\n",
       "             ('model.18.bias',\n",
       "              tensor([ 0.0104, -0.0109,  0.0058,  ...,  0.0008, -0.0105,  0.0037])),\n",
       "             ('model.20.weight',\n",
       "              tensor([[ 0.0108, -0.0193, -0.0031,  ..., -0.0028, -0.0013,  0.0014]])),\n",
       "             ('model.20.bias', tensor([0.0050]))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78041800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(all_starr_state_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fe338c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.0.weight',\n",
       "              tensor([[[[ 1.6613e-01,  3.1092e-01, -1.0372e-01,  ..., -1.9600e-01,\n",
       "                         -7.4552e-02,  5.0334e-02]],\n",
       "              \n",
       "                       [[-1.1445e-01, -4.7423e-02,  1.4395e-01,  ...,  3.0431e-01,\n",
       "                          1.5359e-01, -2.3749e-01]],\n",
       "              \n",
       "                       [[-2.5124e-01, -2.4415e-01, -2.5052e-01,  ..., -2.1614e-01,\n",
       "                         -3.1528e-01,  1.5794e-01]],\n",
       "              \n",
       "                       [[-3.6601e-02, -1.4999e-01, -2.3390e-01,  ..., -1.0493e-01,\n",
       "                          2.3972e-04, -1.4323e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1824e-02,  9.0586e-02,  4.6133e-01,  ..., -2.4137e-01,\n",
       "                          3.1201e-01, -1.8993e-01]],\n",
       "              \n",
       "                       [[ 1.7946e-03, -4.2285e-01, -2.6302e-01,  ...,  1.9758e-01,\n",
       "                         -2.6901e-01, -2.6468e-01]],\n",
       "              \n",
       "                       [[-1.7176e-01,  2.3972e-01, -2.0065e-01,  ..., -1.7563e-01,\n",
       "                         -1.8126e-01,  2.1261e-01]],\n",
       "              \n",
       "                       [[ 1.6274e-01, -8.7259e-02, -2.6847e-01,  ...,  1.6300e-01,\n",
       "                          7.8101e-03,  1.9941e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.3599e-01, -2.0656e-01,  1.0156e-01,  ..., -2.4407e-01,\n",
       "                         -7.9640e-02, -1.5367e-01]],\n",
       "              \n",
       "                       [[-1.7816e-01, -3.3466e-01, -1.0816e-01,  ..., -1.6074e-01,\n",
       "                         -4.6894e-01, -8.0263e-02]],\n",
       "              \n",
       "                       [[-2.9894e-01,  5.1157e-01,  5.3476e-02,  ..., -4.9415e-02,\n",
       "                          2.1799e-01, -4.8995e-02]],\n",
       "              \n",
       "                       [[ 3.8278e-01, -2.3386e-01, -2.4643e-01,  ...,  8.7866e-02,\n",
       "                          1.6316e-01,  9.7396e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 8.7187e-02,  5.9615e-02, -1.3476e-01,  ..., -3.4466e-01,\n",
       "                          3.4444e-01, -5.1620e-01]],\n",
       "              \n",
       "                       [[ 2.7823e-02, -1.3591e-01, -2.8329e-01,  ...,  8.3141e-02,\n",
       "                         -2.5411e-01,  4.1530e-01]],\n",
       "              \n",
       "                       [[ 7.5335e-02, -1.5517e-01, -5.3561e-02,  ...,  1.6850e-01,\n",
       "                         -3.6869e-01,  7.1592e-02]],\n",
       "              \n",
       "                       [[-1.9967e-01,  1.0062e-01,  3.2938e-01,  ...,  1.4282e-01,\n",
       "                          1.2441e-01, -2.2743e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.3728e-02, -2.8646e-01, -7.9093e-02,  ..., -1.3065e-01,\n",
       "                          1.7027e-01, -3.6435e-01]],\n",
       "              \n",
       "                       [[-1.1697e-01, -1.7257e-01,  1.8700e-01,  ..., -3.8868e-01,\n",
       "                         -1.9518e-01, -3.4020e-01]],\n",
       "              \n",
       "                       [[ 8.9661e-02,  2.8241e-01, -1.3828e-01,  ...,  3.2921e-01,\n",
       "                          1.4948e-01,  4.9978e-01]],\n",
       "              \n",
       "                       [[-2.9450e-01, -3.2840e-02, -2.0408e-01,  ..., -7.4273e-02,\n",
       "                         -2.5140e-01, -2.1800e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.8974e-02, -3.0459e-01, -3.1650e-01,  ..., -7.8628e-02,\n",
       "                         -3.2879e-01,  2.7736e-01]],\n",
       "              \n",
       "                       [[-2.6735e-01, -7.7371e-02, -9.3566e-02,  ..., -8.3310e-02,\n",
       "                          2.4056e-01, -4.7438e-01]],\n",
       "              \n",
       "                       [[ 3.3158e-01,  2.6991e-01,  3.3840e-02,  ..., -4.4868e-01,\n",
       "                         -3.8560e-01, -1.5872e-01]],\n",
       "              \n",
       "                       [[-1.7694e-01,  5.9308e-03,  3.0985e-02,  ...,  3.3839e-01,\n",
       "                          3.9732e-01,  1.6757e-01]]]])),\n",
       "             ('model.0.bias',\n",
       "              tensor([-0.2994, -0.3579, -0.2577, -0.2879, -0.3742, -0.3301, -0.3225, -0.3383,\n",
       "                      -0.3546, -0.2303, -0.3249, -0.2542, -0.2256, -0.4658, -0.3230, -0.2535,\n",
       "                      -0.0795, -0.4408, -0.2127, -0.1815, -0.4987, -0.1810, -0.2970, -0.3491,\n",
       "                      -0.4014, -0.3319, -0.3927, -0.3276, -0.3950, -0.2720, -0.3045, -0.5104,\n",
       "                      -0.3163, -0.4609, -0.3691, -0.0972, -0.3009, -0.1849, -0.5512, -0.4184,\n",
       "                      -0.3331, -0.0594, -0.2315, -0.2648, -0.2331, -0.1178, -0.2803, -0.2265,\n",
       "                      -0.2845, -0.3271, -0.2240, -0.3989, -0.2728, -0.3493, -0.1954, -0.3674,\n",
       "                      -0.1301, -0.3892, -0.1543, -0.4431, -0.3137, -0.2214, -0.1714, -0.2201,\n",
       "                      -0.3111, -0.3767, -0.1449, -0.3173, -0.4390, -0.3240, -0.1569, -0.2767,\n",
       "                      -0.2708, -0.5304, -0.2238, -0.2777, -0.2591, -0.4932, -0.2346, -0.4383,\n",
       "                      -0.3032, -0.3800, -0.3846, -0.3087, -0.2565, -0.2165, -0.2187, -0.2653,\n",
       "                      -0.1399, -0.3556, -0.3985, -0.2714, -0.5628, -0.2494, -0.2930, -0.4167,\n",
       "                      -0.4224, -0.2857, -0.2686, -0.2361, -0.3349, -0.4068, -0.3474, -0.1555,\n",
       "                      -0.4233, -0.2308, -0.4235, -0.4961, -0.1547, -0.4181, -0.3117, -0.3055,\n",
       "                      -0.2304, -0.1952, -0.3425, -0.3526, -0.3850, -0.3568, -0.3516, -0.2343,\n",
       "                      -0.2388, -0.1913, -0.3019, -0.4194, -0.2632, -0.1217, -0.3901, -0.2827,\n",
       "                      -0.3476, -0.1700, -0.2121, -0.4495, -0.2991, -0.3763, -0.3015, -0.2630,\n",
       "                      -0.2928, -0.2982, -0.4862, -0.2221, -0.2244, -0.1896, -0.2378, -0.2444,\n",
       "                      -0.4228, -0.2662, -0.2876, -0.1881, -0.6642, -0.2485, -0.4407, -0.3546,\n",
       "                      -0.6018, -0.4346, -0.3039, -0.1626, -0.2236, -0.2119, -0.3903, -0.3506,\n",
       "                      -0.2904, -0.3436, -0.2627, -0.1807, -0.3555, -0.4026, -0.4307, -0.3845,\n",
       "                      -0.2719, -0.3094, -0.4602, -0.1230, -0.4016, -0.3616, -0.2335, -0.2222,\n",
       "                      -0.4162, -0.4939, -0.2474, -0.2352, -0.4008, -0.5358, -0.1254, -0.3554,\n",
       "                      -0.3361, -0.4000, -0.2362, -0.0863, -0.2295, -0.4939, -0.2399, -0.1166,\n",
       "                      -0.2386, -0.3620, -0.3872, -0.3669, -0.2641, -0.4412, -0.2537, -0.3498,\n",
       "                      -0.2161, -0.2914, -0.4308, -0.3468, -0.4081, -0.4570, -0.3557, -0.3924,\n",
       "                      -0.1851, -0.2531, -0.2494, -0.2544, -0.3195, -0.3542, -0.2282, -0.4153,\n",
       "                      -0.2420, -0.3745, -0.4055, -0.2392, -0.3524, -0.1489, -0.1167, -0.1772,\n",
       "                      -0.0874, -0.2695, -0.1894, -0.4217, -0.2778, -0.3693, -0.2354, -0.2084,\n",
       "                      -0.4117, -0.3542, -0.3780, -0.4110, -0.3264, -0.3513, -0.1909, -0.2340,\n",
       "                      -0.2575, -0.3866, -0.2212, -0.2356, -0.2299, -0.2048, -0.4384, -0.4438,\n",
       "                      -0.3306, -0.3672, -0.4957, -0.2726, -0.3239, -0.3332, -0.4184, -0.2264,\n",
       "                      -0.4841, -0.1649, -0.2893, -0.2837, -0.2209, -0.4870, -0.3394, -0.2589,\n",
       "                      -0.3657, -0.4980, -0.3595, -0.3294, -0.4789, -0.4339, -0.3873, -0.1690,\n",
       "                      -0.3433, -0.2686, -0.3482, -0.3655, -0.4224, -0.3464, -0.2531, -0.3165,\n",
       "                      -0.2685,  0.0979, -0.3329, -0.2309, -0.1134, -0.2812, -0.2757, -0.4614,\n",
       "                      -0.3378, -0.2436, -0.2503, -0.2726, -0.0980, -0.4287, -0.2398, -0.3495,\n",
       "                      -0.3329, -0.1688, -0.3845, -0.2130, -0.3060, -0.3967, -0.1734, -0.3446,\n",
       "                      -0.3820, -0.3608, -0.2757, -0.2821, -0.1518, -0.1746, -0.4140, -0.2825,\n",
       "                      -0.3866, -0.2334, -0.2458, -0.1591, -0.3053, -0.3881, -0.3860, -0.2056])),\n",
       "             ('model.2.weight',\n",
       "              tensor([[[[-0.0102,  0.0543,  0.0279,  ...,  0.0114, -0.0146,  0.0178]],\n",
       "              \n",
       "                       [[ 0.0218, -0.0104,  0.0009,  ...,  0.0728,  0.0218,  0.0666]],\n",
       "              \n",
       "                       [[-0.0461, -0.0580, -0.0397,  ..., -0.0133, -0.0602, -0.0431]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0216, -0.0043,  0.0379,  ...,  0.0508,  0.0081,  0.0003]],\n",
       "              \n",
       "                       [[-0.0260, -0.0642, -0.1319,  ..., -0.0050, -0.0257,  0.0154]],\n",
       "              \n",
       "                       [[ 0.0268,  0.0345,  0.0283,  ..., -0.0283, -0.0118,  0.0165]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0245,  0.0077, -0.0195,  ..., -0.0007, -0.0280,  0.0112]],\n",
       "              \n",
       "                       [[ 0.0246, -0.0080, -0.1006,  ..., -0.0092,  0.0298, -0.0355]],\n",
       "              \n",
       "                       [[-0.0061,  0.0100,  0.0028,  ...,  0.0163, -0.0011,  0.0680]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0034, -0.0105, -0.0152,  ..., -0.0085, -0.0084, -0.0587]],\n",
       "              \n",
       "                       [[-0.0043, -0.0530,  0.0003,  ...,  0.0111, -0.0266, -0.0068]],\n",
       "              \n",
       "                       [[ 0.0226, -0.0324,  0.0042,  ...,  0.0262, -0.0060,  0.0016]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0156,  0.0206,  0.0155,  ...,  0.0030, -0.0061, -0.0027]],\n",
       "              \n",
       "                       [[ 0.0505, -0.0323, -0.0162,  ..., -0.0067, -0.0122, -0.0326]],\n",
       "              \n",
       "                       [[ 0.0568, -0.0071,  0.0865,  ...,  0.1053,  0.0553,  0.0428]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0436,  0.0312, -0.0214,  ...,  0.0017, -0.0066, -0.0326]],\n",
       "              \n",
       "                       [[-0.0652,  0.0115, -0.0163,  ...,  0.0061, -0.0367,  0.0147]],\n",
       "              \n",
       "                       [[ 0.0307,  0.0146, -0.0191,  ...,  0.0395, -0.0058,  0.0032]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0157, -0.0118, -0.0174,  ...,  0.0130, -0.0270,  0.0068]],\n",
       "              \n",
       "                       [[ 0.0377, -0.0120, -0.0286,  ..., -0.0022,  0.0245, -0.0347]],\n",
       "              \n",
       "                       [[ 0.0213, -0.0029, -0.0674,  ..., -0.0036, -0.0039,  0.0080]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0505, -0.0521,  0.0065,  ...,  0.0339, -0.0222, -0.0164]],\n",
       "              \n",
       "                       [[-0.0095, -0.0240, -0.0472,  ..., -0.0293,  0.0509, -0.0258]],\n",
       "              \n",
       "                       [[-0.0227, -0.0164,  0.0220,  ...,  0.0098,  0.0425, -0.0687]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0070, -0.0453, -0.0356,  ...,  0.0293,  0.0122,  0.0476]],\n",
       "              \n",
       "                       [[-0.0236, -0.0030, -0.0136,  ...,  0.0344, -0.0375,  0.0796]],\n",
       "              \n",
       "                       [[-0.0391, -0.0075,  0.0011,  ...,  0.0578, -0.0419, -0.0344]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0327, -0.0361, -0.0144,  ...,  0.0097,  0.0039, -0.0075]],\n",
       "              \n",
       "                       [[-0.0297,  0.0714, -0.0335,  ..., -0.0001, -0.0633,  0.0047]],\n",
       "              \n",
       "                       [[ 0.0429,  0.0113,  0.0043,  ...,  0.0526,  0.0049, -0.0198]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0211, -0.0384, -0.0139,  ..., -0.0256,  0.0057, -0.0134]],\n",
       "              \n",
       "                       [[ 0.0484, -0.0124, -0.0004,  ...,  0.0327,  0.0324, -0.0314]],\n",
       "              \n",
       "                       [[ 0.0098,  0.0066, -0.0144,  ...,  0.0252, -0.0084,  0.0246]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0344, -0.0309, -0.0404,  ...,  0.0077,  0.0186, -0.0144]],\n",
       "              \n",
       "                       [[-0.0043,  0.0618,  0.0213,  ..., -0.0078, -0.0245, -0.0119]],\n",
       "              \n",
       "                       [[ 0.0023,  0.0073, -0.0154,  ..., -0.0074, -0.0532,  0.1047]]]])),\n",
       "             ('model.2.bias',\n",
       "              tensor([-0.3070, -0.2049, -0.1749, -0.1034, -0.2136, -0.1886, -0.2189, -0.1961,\n",
       "                      -0.2091, -0.1460, -0.3121, -0.1813, -0.2737, -0.2659, -0.2203, -0.2142,\n",
       "                      -0.3882, -0.2394, -0.4225, -0.2064, -0.0493, -0.1743, -0.1727, -0.5528,\n",
       "                      -0.3295, -0.1968, -0.3072, -0.1890, -0.2297, -0.2932, -0.2511, -0.2416,\n",
       "                      -0.2738, -0.1488, -0.2131, -0.3081, -0.1776,  0.2927, -0.3877, -0.2133,\n",
       "                      -0.2077, -0.2918, -0.1248, -0.2240, -0.3467, -0.3030, -0.1991, -0.3496,\n",
       "                      -0.2826, -0.1420, -0.2674, -0.3833, -0.2320, -0.3638, -0.1960, -0.2296,\n",
       "                      -0.3226, -0.3284, -0.2608, -0.3905, -0.3868, -0.2324, -0.3147, -0.1912,\n",
       "                      -0.2518, -0.2587, -0.2337, -0.2670, -0.2126, -0.1740, -0.1765, -0.3863,\n",
       "                      -0.3592, -0.1879, -0.1930, -0.1537, -0.4657, -0.1546, -0.1835, -0.1608,\n",
       "                      -0.2088, -0.2419, -0.2121, -0.1787, -0.2770, -0.2469, -0.2330, -0.2165,\n",
       "                      -0.1974, -0.2689, -0.1553, -0.2046, -0.2860, -0.1917, -0.1889, -0.3858,\n",
       "                      -0.1664, -0.2686, -0.3060, -0.1905, -0.2277, -0.2654, -0.1791, -0.1770,\n",
       "                      -0.1847, -0.3696, -0.2829, -0.3175, -0.2392, -0.2050, -0.2477, -0.2775,\n",
       "                      -0.2910, -0.1507, -0.4608, -0.3749, -0.2549, -0.2773, -0.5039, -0.0495,\n",
       "                      -0.2410, -0.2721, -0.2377, -0.2382, -0.2118, -0.1765, -0.4449, -0.4276,\n",
       "                      -0.4272, -0.1752, -0.2065, -0.2954, -0.2079, -0.1842, -0.2477, -0.1562,\n",
       "                      -0.2242, -0.2921, -0.2446, -0.4296, -0.3109, -0.2211, -0.2119,  0.1191,\n",
       "                      -0.2614, -0.1843, -0.2142, -0.5272, -0.2374, -0.1561, -0.2841, -0.2149,\n",
       "                      -0.2147, -0.2347, -0.2135, -0.2754, -0.1764, -0.4014, -0.1846, -0.2217,\n",
       "                      -0.1849, -0.2419, -0.3381, -0.3123, -0.1660, -0.2194, -1.1171, -0.2333,\n",
       "                      -0.3512, -0.2964, -0.7302, -0.2309, -0.2788, -0.2927, -0.3434, -0.5235,\n",
       "                      -0.1952, -0.3121, -0.2442, -0.4016, -0.1163, -0.1877, -0.2905, -0.2179,\n",
       "                      -0.2951, -0.1574, -0.1841, -0.1356, -0.2437, -0.1741, -0.3082, -0.2769,\n",
       "                      -0.2011, -0.1502, -0.5389, -0.2125, -0.2197, -0.2349, -0.3401, -0.1137,\n",
       "                      -0.3880, -0.2865, -0.1557, -0.4294, -0.2881, -0.1822, -0.3793, -0.1627,\n",
       "                      -0.2007, -0.2706, -0.1876, -0.3321, -0.2653, -0.1834, -0.2078, -0.4356,\n",
       "                      -0.5146, -0.1612, -0.2213, -0.2611, -0.2742, -0.4431, -0.1831, -0.2933,\n",
       "                      -0.2797, -0.2832, -0.3848, -0.3069, -0.2235,  0.0882, -0.2397, -0.2890,\n",
       "                      -0.1608, -0.2810, -0.2637, -0.5766, -0.1995, -0.1343, -0.1739, -0.1362,\n",
       "                      -0.1764, -0.2930, -0.1804, -0.1895, -0.1882, -0.5214, -0.1689, -0.1866,\n",
       "                      -0.5103, -0.1252, -0.2031, -0.2977, -0.3178, -0.3570, -0.2325, -0.2025,\n",
       "                      -0.2038, -0.2510, -0.2738, -0.2614, -0.3436, -0.2424, -0.2509, -0.2503,\n",
       "                      -0.2185, -0.2010, -0.2275, -0.3031, -0.1783, -0.2237, -0.3790, -0.4324,\n",
       "                      -0.3202, -0.1478, -0.1178, -0.3279, -0.2057, -0.1684, -0.2059, -0.1494,\n",
       "                      -0.0902, -0.3706, -0.2651, -0.1785, -0.4814, -0.2548, -0.3771, -0.2112,\n",
       "                      -0.4584, -0.1975, -0.2403, -0.1293, -0.2893, -0.1617, -0.2826, -0.2539,\n",
       "                      -0.2187,  0.0194, -0.2150, -0.4916, -0.2516, -0.5884, -0.4516, -0.1822,\n",
       "                      -0.3100, -0.4009, -0.1940, -0.2987, -0.2127, -0.2499, -0.2921, -0.1793,\n",
       "                      -0.3931, -0.2894, -0.2075, -0.4278, -0.3464, -0.2377, -0.1952, -0.2665])),\n",
       "             ('model.6.weight',\n",
       "              tensor([[[[-6.3860e-03, -2.0649e-02, -3.4437e-02,  ..., -8.3836e-03,\n",
       "                         -1.9336e-02, -6.4807e-03]],\n",
       "              \n",
       "                       [[-7.5977e-02,  2.1828e-02, -7.5901e-03,  ...,  7.4589e-02,\n",
       "                         -3.2889e-03, -2.3974e-02]],\n",
       "              \n",
       "                       [[ 2.0512e-02,  7.2566e-03,  1.1787e-02,  ...,  2.0165e-03,\n",
       "                          3.5524e-02, -1.3971e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1885e-02, -3.9999e-02, -3.7193e-02,  ...,  4.3375e-03,\n",
       "                          3.3359e-02,  1.4622e-02]],\n",
       "              \n",
       "                       [[-1.0938e-02, -4.0728e-02, -3.2495e-02,  ...,  1.5684e-02,\n",
       "                          4.1667e-02, -3.2489e-02]],\n",
       "              \n",
       "                       [[ 1.8143e-02,  1.3858e-02,  3.6095e-02,  ...,  7.2005e-03,\n",
       "                         -8.5559e-05,  1.5513e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1022e-02,  3.5586e-02, -4.4387e-03,  ..., -1.0111e-02,\n",
       "                         -4.9103e-02,  1.9066e-02]],\n",
       "              \n",
       "                       [[-2.1543e-02,  1.3527e-02,  1.6494e-02,  ...,  3.5180e-02,\n",
       "                         -1.2114e-02,  3.6707e-03]],\n",
       "              \n",
       "                       [[ 8.2737e-03, -1.2586e-02,  2.5100e-02,  ...,  3.5529e-02,\n",
       "                          5.3764e-02,  5.4760e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3022e-02, -2.0667e-02, -5.5612e-03,  ..., -9.2194e-03,\n",
       "                         -4.2014e-02, -1.2926e-02]],\n",
       "              \n",
       "                       [[-3.5192e-02, -7.1098e-03,  1.4521e-02,  ...,  9.2707e-03,\n",
       "                         -1.8894e-02, -2.0477e-03]],\n",
       "              \n",
       "                       [[ 5.9477e-03,  1.3896e-02,  4.2025e-03,  ..., -3.7289e-04,\n",
       "                          1.3101e-02, -7.3454e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0465e-03, -3.9984e-02, -4.6748e-02,  ...,  2.6143e-02,\n",
       "                         -2.0781e-02, -4.2965e-03]],\n",
       "              \n",
       "                       [[ 2.9517e-02,  3.5806e-02,  2.9587e-02,  ...,  1.8479e-02,\n",
       "                          6.4728e-02,  7.7624e-02]],\n",
       "              \n",
       "                       [[ 2.7862e-02, -5.2449e-02, -6.7253e-03,  ...,  9.5862e-03,\n",
       "                         -5.7678e-02, -5.3148e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.1719e-02,  1.2670e-02,  2.9868e-02,  ..., -1.0248e-01,\n",
       "                         -3.1302e-02,  4.6353e-02]],\n",
       "              \n",
       "                       [[-4.5075e-02, -7.0313e-02, -3.0399e-02,  ..., -5.3623e-02,\n",
       "                         -5.5859e-02, -1.1293e-02]],\n",
       "              \n",
       "                       [[ 7.0595e-03, -8.5062e-03, -2.2929e-02,  ..., -5.2226e-02,\n",
       "                         -3.0874e-02, -1.9963e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1211e-02, -5.3287e-03, -7.1063e-02,  ..., -2.0013e-02,\n",
       "                          7.6226e-02, -1.1620e-02]],\n",
       "              \n",
       "                       [[ 1.1076e-02, -1.2814e-02, -7.5745e-03,  ..., -1.2194e-02,\n",
       "                         -3.9413e-02, -1.5304e-02]],\n",
       "              \n",
       "                       [[-4.1615e-02,  4.7766e-02,  1.7325e-02,  ..., -6.6661e-02,\n",
       "                         -1.2373e-02,  1.1502e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.2663e-02, -2.1894e-02, -2.5777e-02,  ..., -2.6606e-02,\n",
       "                          1.6117e-02,  3.3026e-02]],\n",
       "              \n",
       "                       [[-3.3075e-02,  2.0002e-02, -1.0673e-02,  ...,  4.9890e-02,\n",
       "                          6.4474e-04,  5.0501e-03]],\n",
       "              \n",
       "                       [[-3.8198e-03, -1.1137e-02,  7.2425e-03,  ...,  9.6221e-03,\n",
       "                          8.5882e-03,  1.0227e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4509e-02,  4.8414e-03,  1.9841e-02,  ...,  4.7595e-02,\n",
       "                         -2.5180e-02,  3.1548e-03]],\n",
       "              \n",
       "                       [[-3.3929e-03,  1.5469e-02,  9.9161e-03,  ...,  4.8767e-03,\n",
       "                          2.2391e-03, -8.1876e-03]],\n",
       "              \n",
       "                       [[ 3.9379e-02, -3.0091e-02, -1.0198e-02,  ...,  4.0931e-03,\n",
       "                         -3.7733e-02,  6.8111e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.0178e-02, -1.3090e-03, -1.6445e-03,  ...,  3.7142e-02,\n",
       "                          4.4174e-02,  1.6274e-02]],\n",
       "              \n",
       "                       [[-8.0250e-03, -2.2052e-02, -1.0916e-02,  ...,  7.7303e-02,\n",
       "                          5.2949e-02,  4.2140e-02]],\n",
       "              \n",
       "                       [[ 1.5027e-03, -2.1039e-02,  1.6361e-03,  ..., -2.1642e-02,\n",
       "                         -1.9232e-02,  1.0150e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8558e-02, -4.1800e-02,  1.0229e-02,  ..., -2.8081e-02,\n",
       "                         -6.8645e-02,  4.5373e-02]],\n",
       "              \n",
       "                       [[-3.8627e-02, -2.4890e-02,  4.7549e-02,  ...,  5.9654e-02,\n",
       "                         -6.8704e-02, -5.8373e-03]],\n",
       "              \n",
       "                       [[ 1.8146e-02,  4.8915e-02,  1.6568e-02,  ..., -8.6509e-02,\n",
       "                         -6.2725e-02, -1.4847e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.1281e-02,  1.9663e-02, -5.6708e-02,  ..., -5.9958e-03,\n",
       "                         -5.4470e-02, -1.8031e-02]],\n",
       "              \n",
       "                       [[ 3.2586e-02, -3.8584e-02, -7.6077e-03,  ...,  1.0676e-02,\n",
       "                         -9.5615e-03, -1.2932e-02]],\n",
       "              \n",
       "                       [[ 3.4606e-02, -1.6738e-02,  2.4425e-03,  ..., -1.0190e-03,\n",
       "                         -1.7829e-02,  7.0473e-03]]]])),\n",
       "             ('model.6.bias',\n",
       "              tensor([-1.5801e-01, -2.1408e-01, -1.8809e-02, -6.9405e-02, -5.1569e-01,\n",
       "                      -4.9691e-02, -1.2964e-01, -2.7389e-01, -8.9018e-02, -5.1594e-02,\n",
       "                      -1.8176e-01, -8.4467e-02, -2.5943e-01, -2.3718e-01, -1.4369e-01,\n",
       "                      -1.2770e-01, -1.9658e-01, -1.4947e-01, -7.9416e-02, -3.1990e-02,\n",
       "                      -8.2620e-03, -2.8952e-01,  1.4475e-01, -9.8917e-02, -1.3916e-01,\n",
       "                      -1.7811e-01,  2.3852e-02, -3.1905e-02,  2.2534e-02, -3.5937e-01,\n",
       "                      -9.5841e-02, -1.1500e-01, -2.1702e-01, -2.7632e-01, -3.0388e-01,\n",
       "                      -3.1006e-01,  1.1687e-01,  2.5863e-01, -4.7741e-02, -2.0220e-01,\n",
       "                      -2.0650e-01, -4.0432e-01, -3.1898e-01, -2.1176e-01,  6.1990e-02,\n",
       "                      -9.6216e-02, -9.3178e-02, -2.4381e-01, -5.5867e-02, -2.6650e-01,\n",
       "                      -3.2214e-02, -3.6044e-01,  3.3786e-02, -8.9942e-02,  1.0985e-01,\n",
       "                      -1.6893e-01, -3.9699e-02, -2.5054e-01, -5.9821e-02,  2.8530e-01,\n",
       "                      -1.4549e-01, -9.6166e-02, -2.1128e-01,  7.4555e-02, -6.6422e-02,\n",
       "                      -8.6268e-04, -8.7238e-02,  1.7393e-01, -4.9991e-02, -1.1957e-01,\n",
       "                      -1.1189e-01, -6.6199e-02, -1.0041e-01, -1.7186e-02, -5.6558e-02,\n",
       "                      -3.9272e-02, -2.1703e-01, -2.1005e-01, -6.5109e-02, -1.9511e-01,\n",
       "                      -1.2508e-01, -5.2067e-03,  1.3873e-01, -3.2871e-01, -8.6509e-02,\n",
       "                      -5.1437e-02,  2.4608e-01, -6.6779e-02, -6.5100e-02, -4.6311e-01,\n",
       "                       1.8941e-02, -1.9535e-01, -9.1772e-02, -7.6775e-02,  2.2287e-01,\n",
       "                      -1.2834e-01,  3.4719e-02, -2.0351e-01, -7.9881e-04, -2.3398e-01,\n",
       "                      -8.9796e-02, -2.7366e-01, -2.9150e-01, -1.6232e-01, -2.2286e-01,\n",
       "                      -3.5016e-01, -2.9003e-02, -3.1491e-02,  2.6862e-02,  1.4699e-02,\n",
       "                      -5.3301e-03, -7.4533e-02, -1.5648e-01, -3.2022e-01, -1.3139e-01,\n",
       "                       2.2650e-01, -2.3212e-01, -1.8905e-01, -3.1029e-02, -2.7579e-01,\n",
       "                      -5.2603e-02,  2.5512e-02,  1.6001e-01, -6.3830e-02, -1.3621e-01,\n",
       "                      -2.7799e-01,  2.8376e-02, -6.5705e-03, -1.2101e-01,  1.4381e-01,\n",
       "                      -4.2539e-02, -1.4821e-01, -7.4409e-02, -1.2445e-01, -1.6032e-01,\n",
       "                      -2.1665e-01, -8.4592e-02, -1.9409e-02, -1.1105e-01, -1.1816e-01,\n",
       "                      -1.5732e-01, -8.5885e-02, -9.2777e-02, -8.3690e-02, -7.5395e-02,\n",
       "                      -2.1547e-01,  2.8719e-01, -6.3781e-02,  3.1798e-01, -3.3935e-01,\n",
       "                      -3.5639e-03, -8.6983e-03,  2.3328e-01, -3.3217e-01, -2.2484e-02,\n",
       "                      -2.3198e-01, -2.5245e-01, -1.6448e-01, -2.6200e-01, -1.6176e-01,\n",
       "                      -2.1630e-01, -2.1121e-01, -4.4306e-02, -6.8427e-02,  7.1563e-02,\n",
       "                      -7.6648e-03, -2.1375e-01, -1.6486e-01,  1.3215e-02, -1.6005e-01,\n",
       "                      -1.4353e-01,  4.9531e-02,  1.7245e-01,  1.0187e-01, -1.3596e-01,\n",
       "                      -4.1976e-01, -1.6387e-01,  7.7736e-02, -5.9268e-02,  1.9460e-01,\n",
       "                      -1.4454e-01,  2.5471e-02, -9.0706e-02, -1.9046e-01, -6.2934e-03,\n",
       "                       4.3598e-03, -9.8127e-02, -3.3633e-02,  6.9146e-02, -3.8491e-02,\n",
       "                      -2.8123e-01, -2.1858e-01, -7.9985e-02, -4.5210e-02, -1.2898e-01,\n",
       "                      -6.2023e-02,  1.4153e-01, -2.0814e-01, -3.4969e-01, -1.8054e-01,\n",
       "                       9.7978e-02,  1.0375e-01, -1.0246e-01,  3.6529e-01, -2.3961e-01,\n",
       "                      -6.6697e-02,  9.6667e-02, -2.2634e-01, -1.0470e-01, -5.5996e-02,\n",
       "                      -8.1362e-02, -3.5025e-02, -2.7213e-01,  1.8369e-02, -7.2202e-02,\n",
       "                      -5.6356e-02, -3.8116e-01, -3.0661e-02, -2.5402e-01,  1.9763e-02,\n",
       "                      -1.4189e-01, -1.2860e-01,  2.6043e-02,  5.7742e-02, -1.1765e-01,\n",
       "                      -2.4661e-01,  7.3207e-02,  8.2062e-01, -1.3674e-01, -3.5115e-02,\n",
       "                      -1.9492e-01, -3.0428e-01, -2.8035e-02, -1.5297e-01, -1.2664e-01,\n",
       "                      -7.4001e-02,  1.9402e-01, -1.4747e-01, -1.3279e-01, -3.5909e-01,\n",
       "                      -2.1510e-01,  4.0073e-02, -1.8535e-01, -5.6950e-02,  4.6213e-01,\n",
       "                      -3.7074e-01, -1.4228e-01, -3.7518e-02, -2.3871e-01, -1.2935e-01,\n",
       "                      -1.8600e-01,  5.2280e-02, -2.3228e-01, -2.1504e-01,  1.7612e-01,\n",
       "                      -1.1289e-01,  8.0715e-03, -1.2074e-01,  5.9813e-02,  7.1307e-02,\n",
       "                       1.6259e-01, -9.4101e-02, -2.1667e-01, -2.1739e-01,  3.1833e-01,\n",
       "                      -1.3811e-01, -6.9370e-02, -4.5833e-02, -1.8036e-01, -1.0144e-01,\n",
       "                       2.6924e-01, -1.8879e-01, -1.4492e-01, -2.6136e-01, -1.4975e-01,\n",
       "                      -1.2841e-01, -1.4477e-01, -1.1685e-01, -2.1546e-01, -2.2891e-01,\n",
       "                      -6.4474e-02, -1.4498e-01, -2.2342e-01, -1.9705e-02, -5.4061e-03,\n",
       "                      -1.3832e-01, -1.3351e-01, -5.7155e-02, -1.4960e-01, -6.1942e-02,\n",
       "                      -3.2825e-02, -9.7206e-02, -1.6372e-01, -3.3421e-01, -3.5018e-01,\n",
       "                       9.7081e-03, -2.9426e-01,  1.5911e-02, -4.5587e-02, -9.1174e-02,\n",
       "                      -1.1068e-01, -2.1531e-01, -2.1219e-02, -2.9967e-02,  8.4418e-02,\n",
       "                       4.4427e-02, -1.6326e-01, -7.7028e-02,  3.0867e-02, -1.6472e-01,\n",
       "                      -1.6731e-01, -1.5303e-01, -2.7012e-01,  8.4254e-02, -1.0634e-01,\n",
       "                      -6.4394e-05, -2.5131e-01, -1.8486e-01, -1.9069e-02, -9.2978e-02,\n",
       "                      -6.5813e-02, -1.4325e-01, -8.5748e-02, -4.8830e-02, -1.0260e-01,\n",
       "                      -9.1111e-02, -4.1802e-01, -9.5565e-02, -9.2140e-02, -7.8270e-02,\n",
       "                      -1.1963e-01,  3.0471e-02, -3.8409e-01,  1.7082e-01, -6.2156e-02,\n",
       "                       5.5666e-01, -2.2011e-01, -5.2036e-02, -2.1596e-01, -2.0653e-02,\n",
       "                       7.2010e-02,  2.4958e-01, -2.1938e-01,  2.0641e-01, -1.1412e-01,\n",
       "                      -1.4939e-01, -2.7949e-01, -9.3936e-04, -5.4941e-02, -4.0983e-01,\n",
       "                      -1.0908e-01, -1.2454e-01, -1.4841e-01, -1.3564e-01, -1.9204e-01,\n",
       "                      -1.2358e-01, -1.0434e-01,  1.0541e-01, -3.1282e-03, -2.1271e-01,\n",
       "                      -2.5481e-01, -2.5174e-02, -8.2138e-02, -1.0808e-01, -1.2987e-01,\n",
       "                      -7.3462e-01, -3.0017e-01,  2.8876e-02, -6.1690e-02, -5.2188e-02,\n",
       "                      -1.2257e-01, -4.0353e-02,  2.0609e-01, -2.7002e-01,  3.1309e-01,\n",
       "                       1.5065e-02, -1.7997e-01,  3.8802e-02,  5.5648e-02,  2.9170e-02,\n",
       "                      -1.5685e-01, -2.1554e-02, -3.2803e-01, -2.7434e-01, -7.9811e-02,\n",
       "                       1.4160e-02, -1.3609e-01, -1.4346e-01, -4.4107e-02,  4.1331e-02,\n",
       "                      -1.2338e-01,  5.7318e-02, -7.7970e-02, -1.6390e-01, -1.4957e-01,\n",
       "                      -3.7444e-02,  6.8990e-01, -1.3899e-01, -7.0046e-02, -4.4126e-02,\n",
       "                      -5.8596e-02, -3.6346e-02, -1.8764e-02, -5.9221e-02, -3.8011e-01,\n",
       "                       2.4588e-01,  3.6417e-02,  8.6191e-02,  4.4413e-01, -1.4532e-01,\n",
       "                      -7.1300e-02, -2.6456e-01,  7.5504e-03, -3.7972e-02, -2.9068e-01,\n",
       "                       7.3766e-03, -2.8647e-02, -5.8983e-02, -2.7911e-01, -1.3765e-01,\n",
       "                      -1.1866e-01, -1.6866e-01, -1.4217e-01, -1.2873e-01, -2.8458e-02,\n",
       "                       1.5538e-01, -6.5919e-02, -1.8664e-01, -1.4798e-01, -4.1156e-02,\n",
       "                       1.4152e-02, -3.8094e-02, -1.4932e-01, -1.7051e-01,  3.1744e-01,\n",
       "                       9.3924e-02, -1.5872e-01, -3.7700e-01,  2.1660e-01, -1.3331e-01,\n",
       "                      -1.5682e-02, -1.3097e-02, -1.1859e-01, -1.7539e-01, -1.1259e-01,\n",
       "                      -2.4118e-01, -5.0280e-03, -1.4784e-01, -1.6575e-01, -1.4018e-01,\n",
       "                      -2.6905e-01, -9.2709e-02,  2.5836e-01, -4.8064e-02,  1.5472e-02,\n",
       "                      -4.0255e-02, -1.8604e-01, -1.2673e-01, -1.9487e-01, -5.5732e-02,\n",
       "                      -2.8451e-01, -1.9104e-01, -3.2314e-01, -2.2480e-01, -1.6435e-01,\n",
       "                      -5.1305e-02, -7.3943e-02, -1.6768e-01,  1.1212e-01, -8.6679e-02,\n",
       "                       1.2749e-01, -2.2574e-01, -1.1112e-01, -1.5992e-01, -2.2199e-02,\n",
       "                       2.4645e-03,  8.9119e-02, -1.3583e-01, -1.7633e-01, -5.0519e-02])),\n",
       "             ('model.8.weight',\n",
       "              tensor([[[[ 1.6279e-03, -3.0804e-03, -7.2335e-03,  ..., -7.9989e-03,\n",
       "                         -2.4748e-03, -1.9936e-02]],\n",
       "              \n",
       "                       [[ 3.4069e-04, -9.8919e-03, -2.4526e-02,  ..., -1.9533e-02,\n",
       "                         -3.3571e-02, -4.4867e-02]],\n",
       "              \n",
       "                       [[ 9.3274e-03,  4.8369e-02,  2.7949e-02,  ..., -2.0513e-02,\n",
       "                         -1.9246e-03, -3.3835e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 4.0187e-02,  4.4073e-02,  3.3703e-02,  ...,  5.9885e-02,\n",
       "                          2.7216e-02,  1.0834e-02]],\n",
       "              \n",
       "                       [[ 2.6864e-02,  1.7594e-02,  4.2306e-03,  ...,  9.3628e-03,\n",
       "                          3.4530e-02,  4.7488e-02]],\n",
       "              \n",
       "                       [[ 1.4209e-02,  6.7550e-03,  1.4943e-02,  ...,  1.0359e-02,\n",
       "                          1.5414e-02,  1.3331e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5474e-03, -1.5090e-02, -2.0333e-03,  ..., -7.6885e-04,\n",
       "                          7.2913e-03,  5.7261e-03]],\n",
       "              \n",
       "                       [[-1.7306e-02, -1.2935e-02,  3.9597e-05,  ...,  2.1155e-02,\n",
       "                         -1.7019e-02,  2.0456e-03]],\n",
       "              \n",
       "                       [[ 1.6957e-03, -2.4807e-02, -3.1083e-02,  ..., -1.4394e-02,\n",
       "                         -1.8194e-02, -3.5965e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4328e-02,  2.8148e-03,  3.0379e-02,  ..., -5.4496e-04,\n",
       "                          7.5331e-03,  2.5400e-02]],\n",
       "              \n",
       "                       [[-5.0598e-03, -3.5318e-03,  1.7204e-02,  ..., -4.5195e-03,\n",
       "                          4.0365e-03,  7.3842e-04]],\n",
       "              \n",
       "                       [[ 2.4737e-02,  1.2699e-02,  1.3551e-02,  ...,  2.8287e-02,\n",
       "                          3.0751e-02,  3.3911e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6430e-02,  2.1295e-02,  7.0178e-03,  ...,  1.6173e-02,\n",
       "                          1.8110e-02,  1.5639e-02]],\n",
       "              \n",
       "                       [[ 2.0627e-03, -2.8472e-03, -1.3879e-03,  ..., -8.0554e-03,\n",
       "                          2.5936e-03,  2.5890e-03]],\n",
       "              \n",
       "                       [[ 1.0020e-02,  3.3837e-03, -1.1675e-02,  ..., -7.4559e-03,\n",
       "                         -2.4335e-03, -6.3343e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3428e-02, -1.3736e-02, -7.2827e-03,  ...,  7.5955e-03,\n",
       "                         -6.6096e-06,  5.7835e-03]],\n",
       "              \n",
       "                       [[-2.2586e-03,  6.8830e-03,  8.1153e-04,  ...,  8.7554e-03,\n",
       "                         -9.6112e-03, -3.1443e-03]],\n",
       "              \n",
       "                       [[ 1.4897e-03,  1.5315e-02,  8.1657e-03,  ...,  7.9935e-04,\n",
       "                          9.2704e-03,  2.2235e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1829e-02,  2.0912e-02,  1.0152e-02,  ..., -9.8767e-04,\n",
       "                          1.5797e-02,  4.3016e-03]],\n",
       "              \n",
       "                       [[ 9.8398e-03,  7.8308e-03, -8.5129e-03,  ...,  1.5261e-04,\n",
       "                         -1.3760e-02, -2.3230e-02]],\n",
       "              \n",
       "                       [[ 2.8289e-02,  1.2265e-02, -2.0933e-03,  ...,  9.2393e-03,\n",
       "                         -1.5887e-03,  2.3829e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.7704e-03,  1.5377e-02, -1.4540e-03,  ...,  1.5777e-02,\n",
       "                          1.2868e-02,  1.3717e-02]],\n",
       "              \n",
       "                       [[-2.1409e-03,  1.1170e-02,  2.2188e-02,  ...,  1.4414e-02,\n",
       "                          6.6493e-03,  3.3091e-02]],\n",
       "              \n",
       "                       [[-1.7889e-03,  4.4351e-03, -2.5649e-03,  ...,  8.5823e-03,\n",
       "                          9.5688e-03, -2.2104e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.5205e-03,  8.4193e-03,  1.6490e-02,  ...,  8.6266e-03,\n",
       "                          1.4690e-02,  1.1948e-02]],\n",
       "              \n",
       "                       [[ 2.1928e-02,  1.4461e-02,  2.1450e-02,  ...,  1.0760e-02,\n",
       "                          1.5532e-02,  9.8676e-03]],\n",
       "              \n",
       "                       [[-1.4104e-02, -9.3616e-04, -1.3864e-02,  ...,  5.5625e-04,\n",
       "                         -1.3856e-02, -2.2857e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.9334e-03, -2.7340e-03, -4.3863e-03,  ..., -1.8056e-02,\n",
       "                         -1.7608e-02, -4.3451e-03]],\n",
       "              \n",
       "                       [[ 1.9857e-03, -3.5394e-03,  8.7038e-03,  ..., -1.1125e-02,\n",
       "                         -1.6131e-03,  9.5420e-03]],\n",
       "              \n",
       "                       [[-1.4821e-03, -8.4088e-03, -1.6107e-02,  ..., -2.6967e-03,\n",
       "                         -3.1573e-03, -5.7612e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7450e-02, -1.2821e-02,  2.4288e-02,  ...,  6.7694e-03,\n",
       "                         -5.7093e-03, -1.4498e-02]],\n",
       "              \n",
       "                       [[ 6.5066e-02,  2.8463e-02,  8.8846e-03,  ...,  4.5402e-03,\n",
       "                          1.0424e-02,  1.1018e-02]],\n",
       "              \n",
       "                       [[-2.8674e-02, -3.5819e-02, -4.4531e-02,  ..., -6.4625e-03,\n",
       "                         -8.7550e-03, -2.8327e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.5874e-02,  1.6615e-02,  6.5086e-03,  ...,  3.5589e-02,\n",
       "                          4.4667e-02,  3.5850e-02]],\n",
       "              \n",
       "                       [[-2.8829e-02,  1.4990e-03,  1.4666e-02,  ...,  6.6275e-06,\n",
       "                          9.7726e-03,  1.5075e-03]],\n",
       "              \n",
       "                       [[ 8.2862e-03,  1.4903e-02,  1.7278e-02,  ..., -2.9450e-03,\n",
       "                         -1.8271e-02,  1.2474e-03]]]])),\n",
       "             ('model.8.bias',\n",
       "              tensor([ 8.5473e-02,  4.4931e-04,  2.3772e-02,  1.7258e-01,  2.2749e-01,\n",
       "                       1.1256e-01, -8.7120e-03,  2.6951e-02, -2.7534e-02,  1.6614e-01,\n",
       "                      -2.6250e-02,  1.5578e-01,  7.9095e-02,  4.0503e-01, -1.3057e-01,\n",
       "                       7.7257e-02, -2.0331e-02,  4.8875e-02,  1.4981e-01,  1.3820e-01,\n",
       "                      -3.3171e-01, -4.4543e-01,  8.8079e-02,  1.4432e-01,  1.2443e-01,\n",
       "                       1.0051e-01, -8.5669e-02,  1.3824e-02, -8.4468e-02,  9.5781e-02,\n",
       "                       6.4557e-02, -1.3137e-01, -1.0255e-01,  8.8086e-02,  9.8818e-02,\n",
       "                       1.2706e-02, -7.9347e-02,  1.6476e-01,  7.4699e-02,  1.1194e-01,\n",
       "                      -1.5309e-02,  1.2531e-01,  1.0791e-01,  9.5325e-02, -2.9206e-02,\n",
       "                       1.1035e-01, -2.1656e-01,  1.1710e-01,  2.2393e-01,  5.9840e-02,\n",
       "                       1.8342e-01,  5.3828e-02,  6.3720e-02,  1.3055e-01,  2.7571e-01,\n",
       "                      -1.5911e-02,  1.5085e-01, -3.1406e-01,  9.5003e-02,  1.1106e-01,\n",
       "                       1.0367e-01,  4.2136e-01,  8.7714e-02, -1.7016e-02,  1.1625e-02,\n",
       "                       1.2654e-01,  2.8754e-01, -1.4182e-04,  1.3680e-01,  1.1610e-02,\n",
       "                       1.0716e-01,  1.5038e-01,  1.6410e-01,  2.0043e-01,  1.1961e-01,\n",
       "                       2.9996e-01, -2.5861e-01, -2.7865e-02,  1.2941e-01,  9.4996e-02,\n",
       "                       8.8443e-03, -7.5901e-02,  2.2194e-02, -3.0004e-02,  9.1298e-02,\n",
       "                       4.1177e-03,  2.2357e-01,  3.2282e-02,  3.9989e-02,  7.2397e-02,\n",
       "                       2.6788e-02,  2.2112e-01,  5.0692e-02,  4.9482e-02, -2.1392e-01,\n",
       "                      -3.6908e-02,  2.8068e-03,  1.5276e-01,  3.1442e-02,  3.5797e-02,\n",
       "                       1.2060e-02, -3.2906e-01,  1.9118e-01,  9.4475e-02, -3.9879e-03,\n",
       "                       8.5630e-02,  2.0884e-01,  1.7170e-01, -4.5620e-02,  5.4027e-02,\n",
       "                      -2.8648e-02,  4.0064e-01,  2.0624e-01, -2.7292e-01,  1.0269e-01,\n",
       "                       3.7231e-02,  2.1052e-01,  9.8899e-02,  1.6061e-02,  1.7243e-01,\n",
       "                       1.0710e-01, -1.9037e-01, -2.5334e-01, -4.4070e-02,  4.0933e-02,\n",
       "                       5.9000e-02,  1.1776e-01,  1.2417e-01,  1.1466e-01,  1.2876e-01,\n",
       "                       2.3192e-01,  5.5387e-02,  6.3153e-02, -4.8968e-02, -9.8100e-03,\n",
       "                       1.1331e-01, -4.5624e-02, -2.6123e-02,  1.5672e-02,  2.7551e-02,\n",
       "                      -1.6077e-01,  4.9699e-02, -1.4984e-01, -1.0611e-01, -1.5794e-02,\n",
       "                       2.2201e-01,  1.8809e-01, -3.8828e-02,  4.8677e-03,  1.1522e-01,\n",
       "                       2.3170e-01, -8.3022e-02,  2.8045e-01,  9.7809e-02,  2.6421e-01,\n",
       "                      -3.5706e-02,  9.4084e-02, -4.5564e-02,  1.5516e-01,  1.9878e-01,\n",
       "                       1.8550e-01,  1.0075e-01,  1.2169e-01,  4.4514e-02, -8.6592e-02,\n",
       "                       9.1044e-02,  7.6899e-03, -1.8107e-02,  1.4443e-01,  1.2196e-01,\n",
       "                       1.1640e-01,  1.1140e-01,  7.6958e-02,  1.3669e-01,  1.5910e-01,\n",
       "                      -1.7456e-02,  1.5650e-02,  1.9797e-01, -4.7483e-02,  2.7773e-02,\n",
       "                       1.8738e-01,  8.9108e-02,  5.7079e-02, -1.1422e-01,  5.5249e-02,\n",
       "                       1.2190e-01,  6.2000e-02,  2.7799e-01,  9.7785e-02,  1.3744e-01,\n",
       "                      -1.8946e-02,  1.8736e-01,  1.2805e-02, -3.2612e-02,  1.1433e-01,\n",
       "                       4.8414e-02,  1.6148e-01, -2.0074e-02,  1.7060e-01,  1.2903e-01,\n",
       "                      -1.9002e-01,  8.6985e-02,  1.3402e-01,  5.8417e-02, -3.1088e-01,\n",
       "                      -6.3737e-02,  1.4753e-01,  9.9059e-02,  1.9380e-02, -2.7031e-01,\n",
       "                      -1.6574e-02,  2.1347e-01,  2.2433e-01, -3.1665e-01,  1.1283e-01,\n",
       "                       1.1930e-01,  2.1952e-01,  1.4959e-01,  5.4475e-02,  7.6411e-02,\n",
       "                      -3.6244e-01,  1.9440e-01,  1.6858e-01,  1.4547e-01, -8.5415e-02,\n",
       "                       1.7171e-01,  7.1932e-03,  2.1227e-01,  1.0654e-01,  1.7375e-01,\n",
       "                      -7.6733e-02, -5.9506e-02, -1.8232e-01, -4.5436e-02,  1.1452e-01,\n",
       "                       6.0962e-02, -4.1509e-01,  3.2518e-02,  1.7377e-01,  1.2607e-02,\n",
       "                      -1.0991e-01,  2.5392e-01,  2.4574e-01,  8.4314e-02,  1.8090e-02,\n",
       "                      -3.6880e-01,  1.2758e-01,  2.2493e-02,  1.3692e-02,  2.0371e-02,\n",
       "                       1.3399e-01, -6.4991e-02,  2.3767e-01,  4.3024e-02, -2.5842e-01,\n",
       "                       1.3373e-01,  2.2153e-01, -7.2765e-01,  5.7401e-02, -7.1316e-02,\n",
       "                       3.8757e-02,  1.5160e-01, -1.1228e-01,  4.4272e-02,  5.2302e-02,\n",
       "                      -2.6358e-05,  2.2983e-01, -1.4980e-01,  1.7349e-01, -5.4240e-02,\n",
       "                       2.1433e-01,  3.9624e-01,  5.6042e-02,  4.0558e-02, -4.7878e-04,\n",
       "                       2.5676e-01,  6.0293e-02,  8.9789e-02, -3.7003e-02, -1.7745e-01,\n",
       "                       6.0646e-02, -2.2189e-02, -1.4510e-02, -3.2148e-01,  1.2423e-01,\n",
       "                       2.0073e-01,  4.6296e-02, -7.4960e-03, -2.5562e-02, -1.5972e-02,\n",
       "                       2.4883e-01,  2.0289e-01,  1.6553e-01, -1.3600e-01, -2.1031e-01,\n",
       "                       7.7053e-02,  1.2939e-01, -6.4363e-02,  6.4346e-02,  2.9505e-01,\n",
       "                       1.3401e-01,  1.0118e-01, -6.6650e-03,  2.9339e-02, -1.9718e-01,\n",
       "                       8.1976e-02,  3.4909e-02,  1.9293e-01,  2.0629e-01,  1.0716e-01,\n",
       "                       6.5487e-02, -4.5985e-02, -1.2985e-01, -5.2211e-02,  5.5190e-05,\n",
       "                      -1.4248e-01, -1.9336e-01,  9.4248e-02, -6.0945e-02, -6.0727e-02,\n",
       "                       1.8423e-01, -6.3674e-03,  1.1396e-01, -1.0118e-01,  1.6457e-01,\n",
       "                       2.1064e-01,  7.2889e-02, -6.0864e-02, -2.3985e-03, -3.6656e-01,\n",
       "                       7.8268e-03, -2.4485e-01, -2.6008e-02,  2.0184e-01,  2.7356e-01,\n",
       "                       1.0578e-01, -1.4602e-02, -9.7075e-02,  1.9272e-01,  4.5821e-02,\n",
       "                       6.6700e-04,  4.5579e-02,  1.2672e-01,  2.2051e-01,  1.6507e-01,\n",
       "                       2.4381e-01, -1.0232e-02, -8.5865e-02,  1.2377e-01,  3.6079e-02,\n",
       "                      -3.1691e-01,  2.8434e-02, -2.3923e-02,  2.5995e-01,  1.7308e-01,\n",
       "                      -2.7495e-02,  2.9100e-02, -5.2367e-02, -7.8834e-03,  5.1546e-03,\n",
       "                       1.0672e-01, -7.7848e-02, -1.0860e-01, -1.4398e-02,  8.6989e-03,\n",
       "                       1.5373e-01, -5.2083e-02,  8.4002e-02,  7.8690e-02,  6.6615e-02,\n",
       "                       3.5618e-02, -4.1205e-02,  2.5209e-01, -1.7815e-02, -9.2429e-02,\n",
       "                       1.5152e-02,  3.3634e-02,  1.7415e-01, -6.4095e-03, -2.3256e-02,\n",
       "                       2.0566e-01,  2.3511e-01,  7.0738e-02,  2.0182e-02, -5.1558e-02,\n",
       "                       3.8612e-02,  1.0271e-01,  1.8696e-01, -4.3674e-01,  1.3128e-02,\n",
       "                      -1.0393e-01,  2.1975e-01,  1.0299e-01, -2.0819e-02,  5.9241e-02,\n",
       "                       5.6086e-02,  1.1960e-01, -7.7897e-03,  1.2196e-02, -1.1631e-01,\n",
       "                      -4.0530e-02, -2.3361e-02,  1.2197e-01,  1.0741e-01, -4.6926e-02,\n",
       "                      -5.9416e-02,  5.5270e-02,  2.2448e-01, -1.2276e-01,  1.8006e-01,\n",
       "                       4.3847e-02,  1.3356e-01,  2.4258e-02, -1.2947e-02,  1.3528e-01,\n",
       "                       1.1817e-02,  1.7175e-03,  4.1705e-02,  1.6278e-01, -1.4433e-03,\n",
       "                       8.4205e-03, -1.2813e-01,  2.0438e-01,  2.3917e-01,  1.6234e-01,\n",
       "                       2.3657e-01,  4.2546e-02, -3.1837e-02,  6.8400e-02,  2.3823e-02,\n",
       "                      -1.3487e-01,  1.9380e-01,  8.6339e-02,  4.1300e-02,  1.3538e-01,\n",
       "                       5.8661e-02, -1.8736e-02,  1.5104e-01,  3.3866e-01,  2.7680e-03,\n",
       "                       2.1108e-02,  8.2468e-02,  4.3376e-02,  9.4398e-02, -7.5061e-02,\n",
       "                      -3.2988e-02, -3.6808e-02,  4.3333e-02, -1.9008e-01,  1.6555e-01,\n",
       "                       3.5829e-01,  1.1540e-01,  3.2033e-01, -7.4897e-02,  4.1545e-02,\n",
       "                      -1.5573e-01,  2.6739e-01, -2.2332e-01, -4.7653e-02,  2.7501e-01,\n",
       "                       3.0452e-01, -7.0655e-03,  4.9669e-02, -1.5495e-01,  1.4089e-01,\n",
       "                       1.8686e-01,  2.8119e-02, -1.7596e-01,  1.4282e-02,  5.8435e-02,\n",
       "                       1.2577e-01, -1.7004e-01,  5.4009e-02, -7.0836e-02, -5.0805e-02,\n",
       "                      -1.0297e-01,  3.2010e-02,  1.0351e-01, -1.8785e-01, -4.2787e-02])),\n",
       "             ('model.12.weight',\n",
       "              tensor([[[[ 0.0050,  0.0005,  0.0058,  ..., -0.0107,  0.0011,  0.0018]],\n",
       "              \n",
       "                       [[-0.0074, -0.0124,  0.0029,  ..., -0.0085, -0.0105,  0.0044]],\n",
       "              \n",
       "                       [[ 0.0104, -0.0049, -0.0014,  ..., -0.0001,  0.0082, -0.0084]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0013,  0.0074,  0.0090,  ..., -0.0072,  0.0061, -0.0090]],\n",
       "              \n",
       "                       [[ 0.0069,  0.0060,  0.0025,  ..., -0.0036,  0.0032,  0.0068]],\n",
       "              \n",
       "                       [[ 0.0214,  0.0240,  0.0090,  ..., -0.0175, -0.0088, -0.0020]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0100, -0.0063, -0.0068,  ..., -0.0105, -0.0160, -0.0048]],\n",
       "              \n",
       "                       [[ 0.0107,  0.0051,  0.0048,  ..., -0.0039,  0.0067,  0.0336]],\n",
       "              \n",
       "                       [[-0.0196, -0.0018,  0.0064,  ...,  0.0136,  0.0078,  0.0021]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0073, -0.0170, -0.0193,  ..., -0.0240, -0.0189, -0.0124]],\n",
       "              \n",
       "                       [[-0.0211, -0.0296, -0.0237,  ..., -0.0123,  0.0006,  0.0057]],\n",
       "              \n",
       "                       [[-0.0350,  0.0037,  0.0224,  ...,  0.0041,  0.0106, -0.0040]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0151, -0.0041,  0.0156,  ...,  0.0159,  0.0115,  0.0100]],\n",
       "              \n",
       "                       [[ 0.0271, -0.0252, -0.0305,  ..., -0.0155, -0.0102,  0.0200]],\n",
       "              \n",
       "                       [[-0.0166, -0.0113, -0.0065,  ...,  0.0108,  0.0050,  0.0169]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0061,  0.0137,  0.0023,  ...,  0.0068,  0.0109, -0.0100]],\n",
       "              \n",
       "                       [[-0.0020, -0.0040,  0.0052,  ...,  0.0067,  0.0138,  0.0282]],\n",
       "              \n",
       "                       [[-0.0191, -0.0115,  0.0078,  ...,  0.0090,  0.0179,  0.0270]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0203, -0.0158, -0.0065,  ...,  0.0240,  0.0059, -0.0085]],\n",
       "              \n",
       "                       [[-0.0322, -0.0224, -0.0191,  ..., -0.0321, -0.0212, -0.0325]],\n",
       "              \n",
       "                       [[-0.0281, -0.0255, -0.0258,  ...,  0.0157,  0.0148, -0.0030]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0022,  0.0135,  0.0031,  ...,  0.0051,  0.0140, -0.0066]],\n",
       "              \n",
       "                       [[ 0.0092,  0.0010,  0.0119,  ..., -0.0034, -0.0042, -0.0014]],\n",
       "              \n",
       "                       [[-0.0110,  0.0169,  0.0148,  ...,  0.0104,  0.0224,  0.0063]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0005,  0.0030,  0.0034,  ..., -0.0125,  0.0025, -0.0010]],\n",
       "              \n",
       "                       [[ 0.0043,  0.0039,  0.0035,  ...,  0.0067,  0.0125,  0.0057]],\n",
       "              \n",
       "                       [[ 0.0045, -0.0010, -0.0013,  ..., -0.0033,  0.0002,  0.0100]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0103,  0.0076,  0.0117,  ...,  0.0034, -0.0026,  0.0080]],\n",
       "              \n",
       "                       [[-0.0129, -0.0093,  0.0002,  ..., -0.0007,  0.0023,  0.0017]],\n",
       "              \n",
       "                       [[ 0.0062,  0.0156,  0.0087,  ..., -0.0017, -0.0048, -0.0188]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0145, -0.0144, -0.0187,  ..., -0.0244, -0.0289, -0.0176]],\n",
       "              \n",
       "                       [[ 0.0048,  0.0134,  0.0059,  ..., -0.0048,  0.0122,  0.0097]],\n",
       "              \n",
       "                       [[ 0.0143,  0.0086,  0.0196,  ...,  0.0179,  0.0116,  0.0191]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0164, -0.0152, -0.0151,  ..., -0.0115, -0.0162, -0.0177]],\n",
       "              \n",
       "                       [[-0.0084, -0.0177,  0.0018,  ..., -0.0043, -0.0120, -0.0094]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0119,  0.0209,  ...,  0.0061,  0.0075,  0.0086]]]])),\n",
       "             ('model.12.bias',\n",
       "              tensor([ 9.4918e-03,  4.7369e-02,  6.9669e-02,  2.1924e-02, -7.9590e-02,\n",
       "                       1.8294e-02, -2.8654e-01,  4.2585e-02,  2.5743e-02, -2.6554e-01,\n",
       "                       7.8330e-02, -2.7370e-03, -4.5312e-02,  5.7423e-02,  2.7001e-02,\n",
       "                      -4.8094e-01,  3.3978e-02, -8.4017e-02,  1.0063e-01, -4.2792e-02,\n",
       "                      -1.5354e-01, -2.7258e-01, -1.0075e-02,  6.2062e-02, -1.0157e-01,\n",
       "                      -1.0068e-01, -1.4993e-01, -1.5090e-01,  3.5916e-01, -1.4888e-02,\n",
       "                       1.4434e-02,  1.5904e-01, -6.0888e-01, -4.5937e-02,  1.2779e-01,\n",
       "                       5.1018e-02,  4.4474e-03, -7.4865e-02,  6.0575e-02, -7.4737e-02,\n",
       "                       1.4314e-01, -1.1052e-01,  8.9289e-03, -3.5781e-01, -5.4577e-02,\n",
       "                       1.9114e-01, -4.1392e-02,  3.4658e-02, -2.0142e-01,  6.7727e-02,\n",
       "                      -1.3149e-01, -6.8833e-02,  1.5685e-01,  1.2562e-01, -4.9498e-02,\n",
       "                      -7.6153e-02,  5.1832e-02,  8.7851e-02, -2.2249e-02, -1.2315e-03,\n",
       "                       7.3447e-02, -1.1879e-02, -9.2378e-02, -7.7300e-02,  2.6691e-02,\n",
       "                       1.7169e-01,  5.1576e-02, -1.3146e-01, -1.1571e-01,  2.3123e-02,\n",
       "                       1.6279e-02, -3.1170e-02, -1.5042e-01,  2.4600e-03, -1.3782e-02,\n",
       "                      -6.5285e-02,  2.6872e-01,  1.0259e-01,  2.0454e-01,  9.1383e-02,\n",
       "                       1.1869e-01,  7.6579e-02, -4.1688e-03,  7.0501e-02, -1.4516e-01,\n",
       "                      -4.8383e-02,  2.6336e-02,  2.9525e-01, -1.2332e-02,  1.2115e-01,\n",
       "                       4.3897e-02,  2.8266e-02,  1.0693e-01,  7.4443e-02,  5.6923e-02,\n",
       "                       5.4257e-03,  1.7502e-03, -6.4463e-02,  6.1155e-02,  7.0585e-02,\n",
       "                       1.8228e-01,  8.2008e-02, -9.3894e-03, -3.0855e-02,  6.3425e-02,\n",
       "                      -1.4255e-01,  3.2710e-02, -9.4417e-02, -1.9753e-01,  1.6218e-01,\n",
       "                       6.2077e-02,  5.8903e-03, -5.9637e-02, -8.0973e-03,  1.8330e-02,\n",
       "                      -4.9802e-02, -2.1958e-01,  1.3090e-01,  3.6385e-02, -9.2095e-02,\n",
       "                       1.2673e-02, -8.7029e-03,  1.7236e-02, -1.5950e-01, -5.1232e-02,\n",
       "                       2.9679e-02, -1.6425e-01,  2.7637e-01, -2.3931e-02,  1.1438e-02,\n",
       "                       1.5438e-01,  1.4904e-01, -7.6966e-02,  5.5196e-02, -7.3030e-02,\n",
       "                       1.6966e-02,  1.6614e-01, -1.7041e-02, -1.4676e-01,  9.6153e-02,\n",
       "                       1.1497e-02, -2.2358e-02,  7.8005e-03, -3.0790e-01, -1.3474e-01,\n",
       "                       2.5800e-01, -4.3805e-03,  8.5490e-02, -1.0391e-02,  2.7168e-02,\n",
       "                       1.2761e-02,  1.8384e-01,  1.1571e-01,  1.8806e-01, -4.6156e-01,\n",
       "                      -1.7139e-01, -2.3723e-01,  1.4532e-02, -4.0671e-01,  5.9753e-02,\n",
       "                      -1.4120e-01,  1.4805e-01, -6.6854e-02,  2.5820e-02, -6.2012e-02,\n",
       "                       1.6326e-01,  1.0981e-01,  9.5008e-02,  5.6757e-02,  2.3860e-01,\n",
       "                       2.5890e-01, -7.3647e-02,  6.3639e-02, -3.6484e-02, -5.1254e-01,\n",
       "                       7.5614e-02, -1.0304e-02,  1.1591e-01,  2.2318e-01, -2.2912e-02,\n",
       "                       1.4655e-01,  7.0536e-02, -1.7608e-01, -4.7224e-02, -5.8726e-02,\n",
       "                       1.7023e-01, -2.7457e-01,  7.9015e-02, -1.5487e-01, -2.5226e-02,\n",
       "                       1.8801e-02, -5.4615e-03,  2.0183e-02,  1.1419e-02, -6.6673e-04,\n",
       "                      -3.0599e-02,  4.0429e-03,  6.7988e-02, -3.1125e-02,  1.0947e-01,\n",
       "                       1.9861e-01,  2.4390e-02, -1.9061e-02,  1.9974e-01, -2.2295e-02,\n",
       "                       1.9292e-01, -1.1461e-01,  4.5389e-03, -2.7315e-03,  2.2434e-02,\n",
       "                       4.8681e-02, -2.5159e-02,  5.6466e-02, -5.3896e-02, -5.0419e-02,\n",
       "                      -2.4568e-01,  1.0112e-01, -6.6431e-03,  1.6361e-02,  2.1230e-03,\n",
       "                      -3.2172e-02,  1.2244e-01,  5.4355e-02, -3.0117e-02,  5.1398e-03,\n",
       "                      -7.4988e-02,  3.9441e-01,  1.1526e-02,  5.0132e-02, -2.5231e-01,\n",
       "                      -5.4406e-02,  1.1377e-01, -4.4679e-02, -1.4561e-01, -2.2739e-04,\n",
       "                      -1.2195e-01, -2.7931e-02, -3.4072e-01,  6.2871e-03, -1.8367e-01,\n",
       "                      -1.1539e-01,  2.8233e-01, -2.4372e-02, -1.0071e-02, -1.4179e-02,\n",
       "                       1.2375e-01, -2.7356e-03,  5.8630e-02,  3.0441e-01, -2.1522e-02,\n",
       "                      -6.4962e-02,  8.0449e-02,  8.0960e-03, -4.1344e-03, -1.0573e-02,\n",
       "                       1.0542e-01, -2.7314e-01,  3.6047e-02,  4.0690e-05,  4.4080e-02,\n",
       "                       1.1320e-01,  1.9689e-01,  2.1183e-01,  2.4827e-02, -2.9513e-02,\n",
       "                      -7.6967e-02,  9.4851e-02, -7.7627e-04,  6.8786e-02,  1.1947e-03,\n",
       "                      -2.4080e-01, -1.4476e-01,  9.8595e-02,  1.1357e-01, -4.7791e-02,\n",
       "                      -1.0629e-02,  1.8188e-02,  7.9822e-02,  6.4349e-02,  9.4208e-03,\n",
       "                      -7.9707e-02,  3.1770e-02,  2.1999e-01, -1.5571e-01, -3.6672e-02,\n",
       "                      -1.3725e-01,  3.9431e-02, -4.3247e-02, -4.9174e-02,  2.8940e-01,\n",
       "                      -2.2233e-01, -1.6331e-01,  5.9976e-02,  3.5065e-01,  6.4438e-02,\n",
       "                      -3.0825e-01, -1.5718e-01, -1.1496e-01, -2.0506e-01,  3.1226e-02,\n",
       "                       4.1473e-01,  2.8893e-02,  1.3218e-01,  2.0542e-01, -3.1851e-02,\n",
       "                       2.3085e-02, -3.2984e-02, -2.1364e-01,  1.6885e-01,  3.2364e-02,\n",
       "                       3.6577e-01,  6.5785e-02, -5.1067e-02,  1.3048e-03, -5.3291e-03,\n",
       "                       3.7579e-02,  1.3187e-03, -2.2765e-02, -7.6256e-02, -2.3678e-02,\n",
       "                       3.6268e-01,  3.0932e-02,  9.1025e-02,  3.2679e-02,  2.4265e-02,\n",
       "                       7.2165e-02,  1.0328e-02, -3.3109e-02, -6.0972e-02, -2.2754e-01,\n",
       "                       5.6216e-02,  1.2344e-01, -1.8595e-02,  3.8484e-02, -3.4322e-02,\n",
       "                       2.1992e-01, -7.2787e-02, -9.3081e-02,  2.3028e-02, -5.1678e-03,\n",
       "                      -5.1526e-02,  3.8762e-02,  2.1388e-02, -5.2870e-02, -5.6736e-02,\n",
       "                      -4.9617e-02,  4.4659e-03, -1.0206e-01, -2.2272e-02,  1.5505e-02,\n",
       "                      -2.5628e-02,  1.6538e-01, -1.0903e-01,  3.1578e-01,  2.8578e-02,\n",
       "                       8.5227e-02,  7.0131e-02, -3.0967e-02,  9.3506e-02, -4.1108e-02,\n",
       "                       6.1438e-02,  4.9169e-03,  8.8271e-02,  1.8958e-02, -1.5794e-01,\n",
       "                       6.7280e-02, -1.6594e-01,  3.6877e-01, -8.8582e-03,  2.6252e-01,\n",
       "                       9.8981e-02,  2.2148e-03,  1.6553e-02, -2.9103e-01, -1.9340e-01,\n",
       "                      -1.5692e-02,  2.8836e-01, -6.4167e-02, -8.6294e-02,  1.8720e-01,\n",
       "                      -6.2303e-02,  1.7722e-01,  1.7767e-02,  1.1768e-01, -1.4513e-01,\n",
       "                      -2.9169e-02, -5.0997e-02, -1.6066e-01,  3.5034e-02,  1.8279e-01,\n",
       "                       5.1678e-02,  3.9572e-02, -1.2454e-01, -3.7895e-02,  1.8886e-01,\n",
       "                      -3.9405e-02,  7.8774e-02, -6.5925e-01,  1.3876e-02,  2.8787e-01,\n",
       "                       1.7426e-02, -2.3728e-02,  7.9592e-02, -1.1217e-01,  2.5083e-01,\n",
       "                       5.8961e-02,  1.2270e-02, -1.4130e-01,  4.2371e-02,  1.5572e-02,\n",
       "                       1.6796e-01, -3.5389e-01,  1.6306e-01, -1.8326e-01,  5.5799e-02,\n",
       "                       1.5445e-01, -1.4373e-01, -1.1491e-02, -3.8717e-02,  3.6010e-02,\n",
       "                      -1.7320e-01, -1.5806e-01, -9.1736e-02,  1.2384e-01,  2.2095e-02,\n",
       "                       3.5188e-01,  6.6576e-03,  2.7371e-01,  1.2151e-01,  4.9653e-02,\n",
       "                      -8.0323e-02,  6.5071e-02,  1.0101e-01,  5.5564e-02,  3.3572e-02,\n",
       "                       2.0036e-02,  1.7439e-01,  7.9113e-02,  3.8759e-01, -2.0776e-03,\n",
       "                      -8.8363e-03,  3.9077e-04,  6.1529e-02,  1.8214e-01,  6.3486e-02,\n",
       "                      -6.6170e-02,  3.3468e-02,  2.8984e-01,  6.3800e-02, -6.2311e-02,\n",
       "                      -2.5271e-02,  5.4418e-02, -6.6920e-02,  1.3063e-01, -1.1235e-01,\n",
       "                       3.4900e-02, -3.9384e-02,  6.2604e-03, -7.3498e-02, -2.7933e-02,\n",
       "                       1.2752e-01, -8.5250e-02, -1.1398e-01,  1.0330e-01,  2.2317e-01,\n",
       "                       9.3113e-02, -1.2970e-01, -6.1697e-02, -6.3646e-02,  2.7384e-02,\n",
       "                       3.2096e-02,  2.3909e-01,  2.1294e-02,  2.0776e-02,  2.8420e-02,\n",
       "                       2.3483e-01, -1.8735e-01,  3.8587e-01, -1.4706e-02,  2.3930e-02,\n",
       "                       4.7405e-03, -8.7760e-02, -3.9255e-02,  1.8603e-01, -1.9422e-02,\n",
       "                      -4.0941e-02,  1.0099e-01,  6.2865e-02, -4.4124e-02,  1.9281e-01,\n",
       "                       3.0561e-02, -1.3427e-01, -5.7001e-02, -3.1886e-02,  1.3698e-01,\n",
       "                      -2.0785e-02, -1.6838e-01,  2.1541e-03, -7.8614e-03, -2.1172e-01,\n",
       "                      -3.6233e-01,  1.0043e-01, -6.5206e-02, -2.3895e-02,  1.3753e-01,\n",
       "                       6.6694e-02,  1.1459e-01, -1.7295e-02,  3.3209e-03,  2.1806e-01,\n",
       "                       1.5267e-01,  2.5678e-02,  1.6120e-01,  7.5288e-02, -3.3736e-02,\n",
       "                      -1.6610e-03, -2.5613e-03, -4.6908e-02,  4.5450e-03,  5.5724e-01,\n",
       "                      -3.5200e-02,  9.3688e-02, -1.3313e-02,  2.7394e-02,  4.5727e-02,\n",
       "                       1.2941e-01, -2.5857e-01,  3.8710e-02, -9.7226e-03,  8.2957e-02,\n",
       "                      -6.3082e-02,  3.3139e-02, -1.2228e-01, -2.4480e-01,  6.0612e-02,\n",
       "                      -7.1498e-03, -2.5255e-02, -3.7054e-02, -1.3413e-01,  3.1429e-04,\n",
       "                      -3.1849e-02, -8.5551e-02,  1.7640e-01,  2.8616e-01,  1.1284e-01,\n",
       "                       3.3296e-02, -4.0012e-02,  2.7624e-03,  2.5989e-01, -7.2704e-02,\n",
       "                      -9.0909e-02, -2.5037e-02,  5.0697e-02,  2.8185e-02,  1.5639e-02,\n",
       "                       2.0561e-01, -1.9175e-01,  1.9686e-02,  2.0843e-02,  1.2645e-01,\n",
       "                       1.1675e-01,  5.5390e-02,  1.9388e-01,  1.3624e-02,  2.8037e-03,\n",
       "                      -3.5170e-01,  2.0905e-02,  1.4984e-01, -1.0363e-01,  5.7012e-02,\n",
       "                      -1.0952e-01,  1.2290e-02,  2.3102e-02, -3.6699e-02, -1.5420e-01,\n",
       "                      -5.3827e-02,  1.0013e-03, -3.7979e-02,  8.0081e-02, -1.1845e-01,\n",
       "                       1.0194e-01, -5.6436e-02, -6.8409e-02,  1.0812e-02, -3.1572e-03,\n",
       "                      -1.2465e-01, -1.4235e-02, -3.7593e-02, -2.2285e-01, -7.6095e-03,\n",
       "                      -3.5421e-02,  2.3889e-02,  3.5319e-02, -5.2096e-02, -7.4290e-02,\n",
       "                      -1.2588e-02, -2.9148e-02,  7.7387e-02,  1.4265e-01,  3.6566e-02,\n",
       "                       1.1607e-01,  1.4534e-02,  7.1991e-03,  1.3876e-02,  3.4604e-03,\n",
       "                       3.7565e-02,  1.9561e-01, -4.0041e-01, -9.1614e-02,  3.4345e-02,\n",
       "                      -5.2092e-02, -9.8651e-02, -1.5422e-01,  6.2055e-02, -4.6113e-02,\n",
       "                      -7.5304e-02,  4.8328e-02, -8.0726e-02, -1.0452e-01, -6.2237e-03,\n",
       "                       9.2863e-02,  1.4665e-01, -5.3884e-03,  1.4100e-01, -3.7620e-02,\n",
       "                      -1.7951e-02,  7.2210e-02, -1.3551e-02, -1.0780e-01,  3.5385e-02,\n",
       "                       6.4006e-02, -2.0943e-01, -4.2971e-01, -2.8114e-02,  4.7431e-02,\n",
       "                       1.7687e-01, -9.9762e-02,  1.4434e-02, -1.4532e-02, -1.2650e-02])),\n",
       "             ('model.14.weight',\n",
       "              tensor([[[[ 5.4716e-03,  7.8128e-03,  1.7537e-02,  ...,  6.6176e-03,\n",
       "                          4.6386e-03,  4.7731e-03]],\n",
       "              \n",
       "                       [[-1.1513e-02, -1.0308e-02, -8.7821e-03,  ..., -2.8696e-03,\n",
       "                          5.7797e-04,  3.0600e-03]],\n",
       "              \n",
       "                       [[ 3.8464e-02,  3.4485e-02,  2.4736e-02,  ...,  2.5807e-02,\n",
       "                          1.3934e-02,  2.9980e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9112e-02,  1.9715e-02,  1.2902e-02,  ...,  6.2433e-03,\n",
       "                         -1.5782e-04,  7.6173e-03]],\n",
       "              \n",
       "                       [[-1.4048e-03, -3.4812e-03, -6.5248e-03,  ..., -5.2792e-03,\n",
       "                          7.0165e-05, -5.7781e-03]],\n",
       "              \n",
       "                       [[-1.6646e-02, -5.0049e-03, -1.4090e-02,  ..., -4.4796e-03,\n",
       "                         -1.7081e-02, -2.3547e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1290e-02,  4.7509e-03,  1.0369e-02,  ...,  4.1860e-03,\n",
       "                          5.2331e-03,  1.1639e-02]],\n",
       "              \n",
       "                       [[-1.3336e-02, -8.1413e-04,  5.1362e-04,  ...,  4.6256e-03,\n",
       "                          2.5054e-03,  4.4562e-03]],\n",
       "              \n",
       "                       [[ 1.7907e-03,  2.2406e-02,  2.9657e-02,  ...,  2.8796e-02,\n",
       "                          3.0760e-02,  2.7860e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.0184e-02,  2.4288e-02,  1.2289e-02,  ...,  2.9630e-03,\n",
       "                          1.9690e-02,  3.2666e-02]],\n",
       "              \n",
       "                       [[-2.8188e-05,  2.9234e-03,  6.9552e-03,  ..., -1.7166e-03,\n",
       "                          1.9967e-03, -1.7599e-03]],\n",
       "              \n",
       "                       [[-8.4334e-03, -1.2992e-02, -5.9445e-03,  ..., -1.8861e-02,\n",
       "                         -2.1209e-02, -1.9932e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.5622e-03,  2.6242e-03, -5.0638e-03,  ...,  5.7655e-03,\n",
       "                         -2.4835e-03,  4.2138e-03]],\n",
       "              \n",
       "                       [[-3.1667e-03, -3.3226e-03, -7.3577e-03,  ..., -7.6346e-03,\n",
       "                         -8.3704e-03, -2.7543e-03]],\n",
       "              \n",
       "                       [[ 1.6022e-02,  6.8580e-03, -5.1936e-03,  ..., -9.9505e-03,\n",
       "                         -1.1914e-02, -1.4549e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4764e-02,  5.4924e-03, -1.1182e-02,  ..., -6.6145e-03,\n",
       "                          1.3733e-03, -5.4539e-03]],\n",
       "              \n",
       "                       [[-6.3335e-04, -3.1466e-03, -7.4468e-03,  ..., -5.2490e-03,\n",
       "                          2.6358e-03, -2.5809e-03]],\n",
       "              \n",
       "                       [[-1.8590e-02, -2.0699e-02, -9.2892e-03,  ..., -9.3916e-03,\n",
       "                         -2.9312e-03, -8.0748e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.4641e-03,  9.6253e-03,  8.1983e-03,  ...,  7.7629e-03,\n",
       "                          1.3146e-03,  4.1515e-03]],\n",
       "              \n",
       "                       [[ 1.0169e-02,  1.2015e-02,  2.7720e-03,  ..., -4.6577e-03,\n",
       "                          4.9144e-03, -2.3560e-03]],\n",
       "              \n",
       "                       [[-5.3321e-03, -9.1965e-03, -1.3662e-02,  ..., -9.7088e-03,\n",
       "                          3.6227e-03,  8.0028e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.7450e-02,  1.2417e-02, -1.1383e-03,  ..., -1.4894e-02,\n",
       "                         -2.3906e-02, -2.5610e-02]],\n",
       "              \n",
       "                       [[ 1.5850e-02,  1.0239e-02, -4.3746e-04,  ...,  9.1313e-03,\n",
       "                          1.7524e-02,  1.6297e-02]],\n",
       "              \n",
       "                       [[ 8.3725e-07,  3.8299e-03, -1.0412e-02,  ..., -6.4827e-03,\n",
       "                         -1.0335e-02, -1.0624e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.9715e-03, -1.6544e-02, -1.1669e-02,  ..., -4.9787e-03,\n",
       "                         -9.4223e-03, -7.8812e-04]],\n",
       "              \n",
       "                       [[ 4.8222e-03,  4.9514e-03,  8.5511e-03,  ...,  1.6263e-02,\n",
       "                          6.2106e-03,  2.5721e-03]],\n",
       "              \n",
       "                       [[-1.4130e-02, -1.6560e-02, -2.2247e-02,  ..., -2.6061e-02,\n",
       "                         -2.3271e-02, -2.3661e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.5163e-03, -1.3274e-02, -5.2280e-03,  ..., -1.6279e-02,\n",
       "                         -6.4939e-03, -1.7876e-02]],\n",
       "              \n",
       "                       [[-2.8663e-03, -4.9881e-03, -2.1477e-03,  ..., -4.9752e-03,\n",
       "                         -1.3921e-02, -1.0461e-02]],\n",
       "              \n",
       "                       [[-8.6301e-03, -1.0306e-02, -9.2151e-03,  ..., -7.2869e-03,\n",
       "                          2.5229e-03,  1.1447e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.8543e-03, -4.5363e-03, -5.7442e-03,  ..., -3.5375e-03,\n",
       "                         -4.6515e-03, -5.9920e-03]],\n",
       "              \n",
       "                       [[-1.3436e-02,  4.2799e-04,  5.1362e-03,  ..., -1.0458e-03,\n",
       "                          1.2686e-02,  8.8999e-03]],\n",
       "              \n",
       "                       [[-1.9795e-02,  3.7542e-03,  6.4114e-06,  ...,  1.8008e-02,\n",
       "                          1.4898e-02,  7.9388e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.1292e-02, -7.6434e-03, -3.9870e-03,  ..., -4.5854e-03,\n",
       "                         -9.3591e-03, -1.1982e-02]],\n",
       "              \n",
       "                       [[-2.4136e-03,  2.2758e-03,  5.6098e-03,  ...,  6.4955e-03,\n",
       "                         -2.6168e-03, -1.2989e-02]],\n",
       "              \n",
       "                       [[ 2.2275e-03, -2.4365e-03, -1.3025e-02,  ..., -9.1991e-03,\n",
       "                         -3.7864e-03, -5.2330e-03]]]])),\n",
       "             ('model.14.bias',\n",
       "              tensor([ 0.1147, -0.0651,  0.1183,  0.0578, -0.1171, -0.0443, -0.0819,  0.1554,\n",
       "                      -0.0465,  0.2269, -0.0692, -0.1052,  0.0170,  0.0930,  0.1655,  0.3362,\n",
       "                       0.0431,  0.3695,  0.2299, -0.1471,  0.0352,  0.0127,  0.1653, -0.1348,\n",
       "                       0.0301,  0.0563,  0.2552,  0.0792,  0.1461,  0.3543,  0.1152,  0.3005,\n",
       "                      -0.0762,  0.3611,  0.3399, -0.0421,  0.2600,  0.0792,  0.1345,  0.2101,\n",
       "                      -0.0040, -0.1158,  0.3548,  0.0989, -0.0132,  0.3450,  0.0012, -0.0644,\n",
       "                       0.3588,  0.3138,  0.1615,  0.0512, -0.0416,  0.0917,  0.2753,  0.0541,\n",
       "                       0.0047,  0.1940,  0.3419,  0.0920, -0.0897,  0.1648,  0.0016,  0.4142,\n",
       "                      -0.1962, -0.0417,  0.1737,  0.1580,  0.2748,  0.3379,  0.5096,  0.1049,\n",
       "                       0.0962,  0.2419,  0.2433,  0.4035,  0.1181,  0.3106,  0.1107, -0.1135,\n",
       "                       0.4159,  0.0491,  0.1559, -0.0659,  0.1707,  0.0593,  0.1442,  0.2303,\n",
       "                       0.0525,  0.0578,  0.2176,  0.0393,  0.2970,  0.3551,  0.3601,  0.1304,\n",
       "                       0.0314,  0.0870,  0.1356,  0.3266,  0.0100, -0.0165,  0.1188,  0.0339,\n",
       "                      -0.0426,  0.3685,  0.1019, -0.1634,  0.3130, -0.0973,  0.0628,  0.2773,\n",
       "                       0.0955, -0.0471,  0.2314,  0.2724,  0.1810, -0.0292, -0.0202,  0.0614,\n",
       "                       0.2050,  0.0524,  0.1695,  0.2700,  0.1569,  0.0795,  0.1254,  0.3287,\n",
       "                       0.4662, -0.1570,  0.1269,  0.1756,  0.0080,  0.3829,  0.2017,  0.0971,\n",
       "                       0.0442,  0.3363, -0.0375,  0.3981,  0.0355,  0.1677,  0.2034, -0.0743,\n",
       "                       0.3396,  0.2105, -0.0235,  0.0268,  0.1273,  0.3517,  0.0170, -0.0401,\n",
       "                       0.1051, -0.0351, -0.2460,  0.3242, -0.0098,  0.0361,  0.2918,  0.0037,\n",
       "                       0.0112,  0.4999,  0.2407,  0.2420,  0.0541,  0.0252,  0.0670, -0.1558,\n",
       "                       0.0015, -0.0175,  0.1383, -0.0960,  0.0100,  0.0384,  0.0211,  0.1140,\n",
       "                       0.0443, -0.0023,  0.0857,  0.0332,  0.0216,  0.1730,  0.2647,  0.1473,\n",
       "                       0.0362, -0.0372,  0.4652,  0.0137,  0.0942,  0.2375,  0.0353,  0.3208,\n",
       "                       0.4179, -0.0420,  0.1318,  0.1029, -0.0489, -0.1020,  0.0436, -0.0307,\n",
       "                       0.1037,  0.0476,  0.1507,  0.0125,  0.0508,  0.3676, -0.0198,  0.2276,\n",
       "                       0.4055,  0.0062,  0.0490,  0.2055, -0.1587, -0.1255, -0.0160, -0.1260,\n",
       "                       0.1133,  0.0571,  0.2138,  0.0596,  0.4356,  0.3076,  0.3902,  0.2421,\n",
       "                       0.1256,  0.1376,  0.0757,  0.2189,  0.0167,  0.0409,  0.2779, -0.0657,\n",
       "                      -0.0208,  0.3008, -0.0546, -0.0534, -0.0290, -0.0663, -0.2322,  0.0770,\n",
       "                       0.0295,  0.0749,  0.2551,  0.2025,  0.4452,  0.0502, -0.0667,  0.2627,\n",
       "                       0.1440, -0.0020,  0.1177,  0.0291,  0.2654,  0.0395, -0.0753,  0.0863,\n",
       "                       0.1295,  0.3535, -0.0332,  0.1892,  0.2155,  0.0993, -0.1305,  0.4655,\n",
       "                       0.1786, -0.2606,  0.0054,  0.3921,  0.4602,  0.1516,  0.1346,  0.0169,\n",
       "                      -0.0344,  0.0100,  0.2674,  0.1495,  0.1117,  0.2698, -0.1080,  0.0346,\n",
       "                      -0.0383, -0.0311, -0.0385,  0.1717, -0.0053,  0.2923,  0.1624,  0.0330,\n",
       "                       0.0454, -0.0697,  0.3661,  0.1549, -0.1256, -0.1212,  0.1576,  0.4284,\n",
       "                       0.0236,  0.2683,  0.0599,  0.0924,  0.0446,  0.0286,  0.3585,  0.2183,\n",
       "                       0.3063, -0.0355,  0.1636,  0.2320, -0.0364,  0.1363,  0.3234,  0.1346,\n",
       "                      -0.0287,  0.2025, -0.0450, -0.1778,  0.4284,  0.0327,  0.1088, -0.0400,\n",
       "                       0.2102,  0.2246,  0.1089,  0.2601, -0.0707,  0.2703,  0.3647,  0.1827,\n",
       "                       0.0861,  0.2718,  0.2830,  0.3481,  0.2301,  0.0482,  0.2957,  0.5048,\n",
       "                       0.0750,  0.0668,  0.1593, -0.1800,  0.0959,  0.1465, -0.2210,  0.1914,\n",
       "                       0.2602,  0.2348,  0.2230, -0.0131,  0.1074,  0.0290,  0.1880,  0.0732,\n",
       "                       0.0319,  0.0520, -0.0604,  0.1056,  0.1309,  0.1313,  0.1663,  0.1354,\n",
       "                       0.4618,  0.4030, -0.1203, -0.0513,  0.1171,  0.0534,  0.1481,  0.1098,\n",
       "                       0.0792,  0.1314,  0.3711,  0.1374,  0.0726,  0.1424,  0.2226,  0.1490,\n",
       "                       0.5004,  0.1014, -0.1413,  0.0361, -0.0078,  0.2102,  0.2907,  0.0362,\n",
       "                      -0.0175,  0.2308,  0.0694,  0.1389,  0.1029,  0.2975,  0.2232,  0.0145,\n",
       "                       0.1049,  0.4311,  0.0722,  0.2844,  0.2627, -0.0507,  0.1000,  0.1631,\n",
       "                       0.0764, -0.0486, -0.0461, -0.0981, -0.0616, -0.0063, -0.0381,  0.3077,\n",
       "                       0.0965,  0.3136,  0.3265,  0.0437, -0.0966, -0.2463,  0.4303,  0.1064,\n",
       "                       0.0095,  0.0470,  0.2242, -0.1029,  0.3385, -0.0441,  0.2282,  0.3571,\n",
       "                      -0.1379,  0.3235,  0.0574,  0.4324,  0.1744,  0.4541,  0.1691,  0.2294,\n",
       "                       0.0177,  0.1417,  0.1346, -0.0225,  0.2117,  0.1069,  0.3648, -0.3550,\n",
       "                       0.0022, -0.0125,  0.0121,  0.2185,  0.1038, -0.1281,  0.1285,  0.0136,\n",
       "                       0.2878,  0.2351,  0.3234, -0.0189, -0.1569, -0.0435,  0.4197,  0.2204,\n",
       "                       0.0027,  0.3713,  0.3488,  0.1282,  0.0034,  0.0716, -0.0954, -0.0750,\n",
       "                       0.0604,  0.1265,  0.4368,  0.2366,  0.0047,  0.1545, -0.0406,  0.4228,\n",
       "                       0.1369,  0.0087,  0.1941,  0.0497,  0.0207,  0.0898, -0.0122, -0.0702,\n",
       "                       0.2970,  0.3369,  0.4008, -0.1018,  0.2925,  0.2476, -0.0080,  0.2406,\n",
       "                       0.3522, -0.0045,  0.2827,  0.1301,  0.3159,  0.2825, -0.0016, -0.0623,\n",
       "                       0.0236,  0.1833,  0.2440,  0.1005,  0.3201,  0.0440,  0.3065, -0.1169,\n",
       "                       0.0387,  0.0425,  0.3163,  0.0947,  0.3158,  0.4285,  0.1940,  0.1796,\n",
       "                       0.0190,  0.1129, -0.0171,  0.0146,  0.3580,  0.1109,  0.2234, -0.0674,\n",
       "                       0.3774, -0.0191,  0.1474,  0.3475, -0.0920,  0.2082, -0.0056,  0.3001,\n",
       "                       0.0462,  0.0449,  0.0279,  0.0025, -0.1951,  0.4065, -0.0163, -0.0114,\n",
       "                       0.4119, -0.0385,  0.2553,  0.1983, -0.1401, -0.0067, -0.1557, -0.0858,\n",
       "                      -0.0148, -0.0452,  0.0324, -0.0622,  0.0905,  0.2399,  0.2787,  0.0888,\n",
       "                       0.0595,  0.1818,  0.0749,  0.0056,  0.1564,  0.0861,  0.0900,  0.1320,\n",
       "                       0.3906,  0.0267, -0.0427,  0.1190,  0.5426,  0.0334,  0.2595,  0.0371,\n",
       "                      -0.2962,  0.3925,  0.1947,  0.0825,  0.1313, -0.1373,  0.4708,  0.0086,\n",
       "                       0.1863,  0.1854,  0.2010,  0.0980,  0.1579,  0.1049,  0.2857,  0.1000,\n",
       "                       0.1010,  0.3730, -0.0997,  0.0908,  0.4629,  0.2528,  0.4477,  0.2417,\n",
       "                       0.1619, -0.0533, -0.1340,  0.4601, -0.0123,  0.0292,  0.0905,  0.0345,\n",
       "                      -0.1111, -0.0177,  0.0174,  0.0118,  0.2089,  0.1500,  0.3790,  0.0196,\n",
       "                       0.0497,  0.2424, -0.0863,  0.4018,  0.0180,  0.0562,  0.2265,  0.1962,\n",
       "                      -0.0295, -0.0205,  0.0850,  0.0996,  0.1701,  0.2363,  0.0226,  0.3654,\n",
       "                       0.0398, -0.0225, -0.1596,  0.1788,  0.3158, -0.3114,  0.3142,  0.0660,\n",
       "                      -0.2648, -0.0934, -0.0308,  0.3200, -0.1698,  0.3710,  0.2299,  0.3996])),\n",
       "             ('model.18.weight',\n",
       "              tensor([[-1.0594e-02, -9.6260e-03, -4.5989e-03,  ...,  7.0088e-03,\n",
       "                       -1.8057e-02, -7.4570e-03],\n",
       "                      [ 8.0310e-03, -3.3788e-04,  1.1856e-02,  ...,  4.7782e-03,\n",
       "                       -7.1361e-03, -6.0927e-03],\n",
       "                      [ 8.9205e-03, -3.4950e-04, -2.7107e-03,  ...,  3.6457e-03,\n",
       "                        4.6002e-05, -1.3725e-02],\n",
       "                      ...,\n",
       "                      [ 6.6962e-03,  1.0980e-02,  2.3070e-04,  ...,  1.2688e-02,\n",
       "                        2.0706e-03,  4.3777e-04],\n",
       "                      [-4.1341e-03,  1.5623e-02,  9.8125e-03,  ..., -1.2195e-02,\n",
       "                       -1.0064e-02, -2.5280e-03],\n",
       "                      [ 1.3963e-03,  1.0766e-03,  6.8632e-03,  ..., -1.1759e-02,\n",
       "                       -1.8071e-02, -5.4146e-03]])),\n",
       "             ('model.18.bias',\n",
       "              tensor([ 0.0101,  0.0079,  0.0044,  ..., -0.0026, -0.0018, -0.0046])),\n",
       "             ('model.20.weight',\n",
       "              tensor([[ 0.0187,  0.0173,  0.0151,  ..., -0.0294,  0.0250,  0.0148]])),\n",
       "             ('model.20.bias', tensor([0.0126]))])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_starr_state_dict, all_starr_state_dict_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbfc8630",
   "metadata": {},
   "source": [
    "### 2.2.2 Convert to keras model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a46ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np = np.random.uniform(0, 1, (1, 4, 1, 499))\n",
    "input_var = Variable(torch.FloatTensor(input_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c5039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch2keras:Converter is called.\n",
      "DEBUG:pytorch2keras:Input_names:\n",
      "DEBUG:pytorch2keras:['input_0']\n",
      "DEBUG:pytorch2keras:Output_names:\n",
      "DEBUG:pytorch2keras:['output_0']\n",
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> input_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> output_0.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight model.0.bias with shape (320,).\n",
      "DEBUG:onnx2keras:Found weight model.0.weight with shape (320, 4, 1, 8).\n",
      "DEBUG:onnx2keras:Found weight model.12.bias with shape (640,).\n",
      "DEBUG:onnx2keras:Found weight model.12.weight with shape (640, 480, 1, 8).\n",
      "DEBUG:onnx2keras:Found weight model.14.bias with shape (640,).\n",
      "DEBUG:onnx2keras:Found weight model.14.weight with shape (640, 640, 1, 8).\n",
      "DEBUG:onnx2keras:Found weight model.18.bias with shape (2003,).\n",
      "DEBUG:onnx2keras:Found weight model.18.weight with shape (2003, 7680).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_0 : Float(1, 4, 1, 499),\n",
      "      %model.0.weight : Float(320, 4, 1, 8),\n",
      "      %model.0.bias : Float(320),\n",
      "      %model.2.weight : Float(320, 320, 1, 8),\n",
      "      %model.2.bias : Float(320),\n",
      "      %model.6.weight : Float(480, 320, 1, 8),\n",
      "      %model.6.bias : Float(480),\n",
      "      %model.8.weight : Float(480, 480, 1, 8),\n",
      "      %model.8.bias : Float(480),\n",
      "      %model.12.weight : Float(640, 480, 1, 8),\n",
      "      %model.12.bias : Float(640),\n",
      "      %model.14.weight : Float(640, 640, 1, 8),\n",
      "      %model.14.bias : Float(640),\n",
      "      %model.18.weight : Float(2003, 7680),\n",
      "      %model.18.bias : Float(2003),\n",
      "      %model.20.weight : Float(1, 2003),\n",
      "      %model.20.bias : Float(1)):\n",
      "  %17 : Float(1, 320, 1, 492) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 8], pads=[0, 0, 0, 0], strides=[1, 1]](%input_0, %model.0.weight, %model.0.bias) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %18 : Float(1, 320, 1, 492) = onnx::Relu(%17) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
      "  %19 : Float(1, 320, 1, 485) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 8], pads=[0, 0, 0, 0], strides=[1, 1]](%18, %model.2.weight, %model.2.bias) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %20 : Float(1, 320, 1, 485) = onnx::Relu(%19) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:807:0\n",
      "  %21 : Float(1, 320, 1, 121) = onnx::MaxPool[kernel_shape=[1, 4], pads=[0, 0, 0, 0], strides=[1, 4]](%20) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
      "  %22 : Float(1, 480, 1, 114) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 8], pads=[0, 0, 0, 0], strides=[1, 1]](%21, %model.6.weight, %model.6.bias) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %23 : Float(1, 480, 1, 114) = onnx::Relu(%22) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
      "  %24 : Float(1, 480, 1, 107) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 8], pads=[0, 0, 0, 0], strides=[1, 1]](%23, %model.8.weight, %model.8.bias) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %25 : Float(1, 480, 1, 107) = onnx::Relu(%24) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:807:0\n",
      "  %26 : Float(1, 480, 1, 26) = onnx::MaxPool[kernel_shape=[1, 4], pads=[0, 0, 0, 0], strides=[1, 4]](%25) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
      "  %27 : Float(1, 640, 1, 19) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 8], pads=[0, 0, 0, 0], strides=[1, 1]](%26, %model.12.weight, %model.12.bias) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %28 : Float(1, 640, 1, 19) = onnx::Relu(%27) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
      "  %29 : Float(1, 640, 1, 12) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 8], pads=[0, 0, 0, 0], strides=[1, 1]](%28, %model.14.weight, %model.14.bias) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %30 : Float(1, 640, 1, 12) = onnx::Relu(%29) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:807:0\n",
      "  %31 : Tensor = onnx::Shape(%30)\n",
      "  %32 : Tensor = onnx::Constant[value={0}]()\n",
      "  %33 : Long() = onnx::Gather[axis=0](%31, %32) # /tmp/ipykernel_87872/4022561182.py:57:0\n",
      "  %34 : Long() = onnx::Constant[value={-1}]()\n",
      "  %35 : Tensor = onnx::Unsqueeze[axes=[0]](%33)\n",
      "  %36 : Tensor = onnx::Unsqueeze[axes=[0]](%34)\n",
      "  %37 : Tensor = onnx::Concat[axis=0](%35, %36)\n",
      "  %38 : Float(1, 7680) = onnx::Reshape(%30, %37) # /tmp/ipykernel_87872/4022561182.py:57:0\n",
      "  %39 : Float(1, 2003) = onnx::Gemm[alpha=1, beta=1, transB=1](%38, %model.18.weight, %model.18.bias) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:1370:0\n",
      "  %40 : Float(1, 2003) = onnx::Relu(%39) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:914:0\n",
      "  %output_0 : Float(1, 1) = onnx::Gemm[alpha=1, beta=1, transB=1](%40, %model.20.weight, %model.20.bias) # /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/torch/nn/functional.py:1370:0\n",
      "  return (%output_0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:onnx2keras:Found weight model.2.bias with shape (320,).\n",
      "DEBUG:onnx2keras:Found weight model.2.weight with shape (320, 320, 1, 8).\n",
      "DEBUG:onnx2keras:Found weight model.20.bias with shape (1,).\n",
      "DEBUG:onnx2keras:Found weight model.20.weight with shape (1, 2003).\n",
      "DEBUG:onnx2keras:Found weight model.6.bias with shape (480,).\n",
      "DEBUG:onnx2keras:Found weight model.6.weight with shape (480, 320, 1, 8).\n",
      "DEBUG:onnx2keras:Found weight model.8.bias with shape (480,).\n",
      "DEBUG:onnx2keras:Found weight model.8.weight with shape (480, 480, 1, 8).\n",
      "DEBUG:onnx2keras:Found input input_0 with shape [4, 1, 499]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 17\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 8], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name input_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name model.0.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name model.0.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "2021-12-04 19:47:41.477077: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-12-04 19:47:41.509758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194965000 Hz\n",
      "2021-12-04 19:47:41.515222: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fde6285b50 executing computations on platform Host. Devices:\n",
      "2021-12-04 19:47:41.515260: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2021-12-04 19:47:41.516781: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-04 19:47:41.517838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: TITAN V major: 7 minor: 0 memoryClockRate(GHz): 1.455\n",
      "pciBusID: 0000:02:00.0\n",
      "2021-12-04 19:47:41.517897: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-04 19:47:41.519718: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-04 19:47:41.521229: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-04 19:47:41.521603: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-04 19:47:41.523281: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-04 19:47:41.524153: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-04 19:47:41.527798: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-04 19:47:41.529369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2021-12-04 19:47:41.529525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-04 19:47:41.529551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2021-12-04 19:47:41.529556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2021-12-04 19:47:41.532274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10111 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:02:00.0, compute capability: 7.0)\n",
      "2021-12-04 19:47:41.533840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fe84d13cb0 executing computations on platform CUDA. Devices:\n",
      "2021-12-04 19:47:41.533857: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN V, Compute Capability 7.0\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"17/BiasAdd:0\", shape=(?, 320, 1, 492), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 18\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 17).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"18/Relu:0\", shape=(?, 320, 1, 492), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 19\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 8], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 18).\n",
      "DEBUG:onnx2keras:Check input 1 (name model.2.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name model.2.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"19/BiasAdd:0\", shape=(?, 320, 1, 485), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 20\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 19).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"20/Relu:0\", shape=(?, 320, 1, 485), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 21\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [1, 4], 'pads': [0, 0, 0, 0], 'strides': [1, 4], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 20).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"21/MaxPool:0\", shape=(?, 320, 1, 121), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 22\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 8], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 21).\n",
      "DEBUG:onnx2keras:Check input 1 (name model.6.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name model.6.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"22/BiasAdd:0\", shape=(?, 480, 1, 114), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 23\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 22).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"23/Relu:0\", shape=(?, 480, 1, 114), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 24\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 8], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 23).\n",
      "DEBUG:onnx2keras:Check input 1 (name model.8.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name model.8.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"24/BiasAdd:0\", shape=(?, 480, 1, 107), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 25\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 24).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"25/Relu:0\", shape=(?, 480, 1, 107), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: MaxPool\n",
      "DEBUG:onnx2keras:node_name: 26\n",
      "DEBUG:onnx2keras:node_params: {'kernel_shape': [1, 4], 'pads': [0, 0, 0, 0], 'strides': [1, 4], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 25).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "WARNING:onnx2keras:maxpool:Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"26/MaxPool:0\", shape=(?, 480, 1, 26), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 27\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 8], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 26).\n",
      "DEBUG:onnx2keras:Check input 1 (name model.12.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name model.12.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"27/BiasAdd:0\", shape=(?, 640, 1, 19), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 28\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 27).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"28/Relu:0\", shape=(?, 640, 1, 19), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Conv\n",
      "DEBUG:onnx2keras:node_name: 29\n",
      "DEBUG:onnx2keras:node_params: {'dilations': [1, 1], 'group': 1, 'kernel_shape': [1, 8], 'pads': [0, 0, 0, 0], 'strides': [1, 1], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 28).\n",
      "DEBUG:onnx2keras:Check input 1 (name model.14.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name model.14.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:conv:Conv with bias\n",
      "DEBUG:onnx2keras:conv:2D convolution\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"29/BiasAdd:0\", shape=(?, 640, 1, 12), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 30\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 29).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"30/Relu:0\", shape=(?, 640, 1, 12), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Shape\n",
      "DEBUG:onnx2keras:node_name: 31\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 30).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:shape:Actual shape:\n",
      "DEBUG:onnx2keras:shape:[Dimension(None) Dimension(640) Dimension(1) Dimension(12)]\n",
      "DEBUG:onnx2keras:Output TF Layer -> [Dimension(None) Dimension(640) Dimension(1) Dimension(12)]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 32\n",
      "DEBUG:onnx2keras:node_params: {'value': array(0), 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> 0\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gather\n",
      "DEBUG:onnx2keras:node_name: 33\n",
      "DEBUG:onnx2keras:node_params: {'axis': 0, 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 31).\n",
      "DEBUG:onnx2keras:Check input 1 (name 32).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gather:Gather from numpy array\n",
      "DEBUG:onnx2keras:Output TF Layer -> ?\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Constant\n",
      "DEBUG:onnx2keras:node_name: 34\n",
      "DEBUG:onnx2keras:node_params: {'value': array(-1), 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> -1\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Unsqueeze\n",
      "DEBUG:onnx2keras:node_name: 35\n",
      "DEBUG:onnx2keras:node_params: {'axes': [0], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 33).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:unsqueeze:Work with numpy types.\n",
      "DEBUG:onnx2keras:Output TF Layer -> [Dimension(None)]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Unsqueeze\n",
      "DEBUG:onnx2keras:node_name: 36\n",
      "DEBUG:onnx2keras:node_params: {'axes': [0], 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 34).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:unsqueeze:Work with numpy types.\n",
      "DEBUG:onnx2keras:Output TF Layer -> [-1]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Concat\n",
      "DEBUG:onnx2keras:node_name: 37\n",
      "DEBUG:onnx2keras:node_params: {'axis': 0, 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 35).\n",
      "DEBUG:onnx2keras:Check input 1 (name 36).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:concat:Concat numpy arrays.\n",
      "DEBUG:onnx2keras:Output TF Layer -> [Dimension(None) -1]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Reshape\n",
      "DEBUG:onnx2keras:node_name: 38\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 30).\n",
      "DEBUG:onnx2keras:Check input 1 (name 37).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:reshape:The second argument is numpy array.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"38/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: 39\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 38).\n",
      "DEBUG:onnx2keras:Check input 1 (name model.18.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name model.18.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 7680, output units 2003.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"39_1/BiasAdd:0\", shape=(?, 2003), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: 40\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 39).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"40/Relu:0\", shape=(?, 2003), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: output_0\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': True, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name 40).\n",
      "DEBUG:onnx2keras:Check input 1 (name model.20.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name model.20.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 2003, output units 1.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"output_0/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "k_model = pytorch_to_keras(model, input_var, verbose=True, change_ordering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee1245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_0 (InputLayer)         [(None, 1, 499, 4)]       0         \n",
      "_________________________________________________________________\n",
      "17 (Conv2D)                  (None, 1, 492, 320)       10560     \n",
      "_________________________________________________________________\n",
      "18 (Activation)              (None, 1, 492, 320)       0         \n",
      "_________________________________________________________________\n",
      "19 (Conv2D)                  (None, 1, 485, 320)       819520    \n",
      "_________________________________________________________________\n",
      "20 (Activation)              (None, 1, 485, 320)       0         \n",
      "_________________________________________________________________\n",
      "21 (MaxPooling2D)            (None, 1, 121, 320)       0         \n",
      "_________________________________________________________________\n",
      "22 (Conv2D)                  (None, 1, 114, 480)       1229280   \n",
      "_________________________________________________________________\n",
      "23 (Activation)              (None, 1, 114, 480)       0         \n",
      "_________________________________________________________________\n",
      "24 (Conv2D)                  (None, 1, 107, 480)       1843680   \n",
      "_________________________________________________________________\n",
      "25 (Activation)              (None, 1, 107, 480)       0         \n",
      "_________________________________________________________________\n",
      "26 (MaxPooling2D)            (None, 1, 26, 480)        0         \n",
      "_________________________________________________________________\n",
      "27 (Conv2D)                  (None, 1, 19, 640)        2458240   \n",
      "_________________________________________________________________\n",
      "28 (Activation)              (None, 1, 19, 640)        0         \n",
      "_________________________________________________________________\n",
      "29 (Conv2D)                  (None, 1, 12, 640)        3277440   \n",
      "_________________________________________________________________\n",
      "30 (Activation)              (None, 1, 12, 640)        0         \n",
      "_________________________________________________________________\n",
      "38 (Reshape)                 (None, None)              0         \n",
      "_________________________________________________________________\n",
      "39_reshape (Reshape)         (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "39 (Dense)                   (None, 2003)              15385043  \n",
      "_________________________________________________________________\n",
      "40 (Activation)              (None, 2003)              0         \n",
      "_________________________________________________________________\n",
      "output_0 (Dense)             (None, 1)                 2004      \n",
      "=================================================================\n",
      "Total params: 25,025,767\n",
      "Trainable params: 25,025,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "k_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model.save('./converted_models/keras_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6a01645",
   "metadata": {},
   "source": [
    "### 2.2.3 Convert to keras sequential model with conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fc5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "k_model_1d = keras.models.Sequential()\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=320, kernel_size=8, input_shape=(499,4))) #17\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #18\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=320, kernel_size=8)) #19\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #20\n",
    "k_model_1d.add(keras.layers.MaxPooling1D(pool_size=4))#21\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=480, kernel_size=8)) #22\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #23\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=480, kernel_size=8)) #24\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #25\n",
    "k_model_1d.add(keras.layers.MaxPooling1D(pool_size=4))#26\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=640, kernel_size=8)) #27\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #28\n",
    "k_model_1d.add(keras.layers.Conv1D(filters=640, kernel_size=8)) #29\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #30\n",
    "# k_model_1d.add(keras.layers.Permute((2, 1))) #31_CHW\n",
    "k_model_1d.add(keras.layers.Flatten(data_format='channels_first')) #31\n",
    "k_model_1d.add(keras.layers.Dense(units=2003)) #32\n",
    "k_model_1d.add(keras.layers.Activation(\"relu\")) #33\n",
    "k_model_1d.add(keras.layers.Dense(units=1)) #34\n",
    "# k_model_1d.add(keras.layers.Activation(\"softmax\")) #sigmoid\n",
    "k_model_1d.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9844973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/software/Anaconda3/4.4.0-foss-2017a/envs/deeplift_modisco/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 19:49:43.124046: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2021-12-04 19:49:43.165921: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194965000 Hz\n",
      "2021-12-04 19:49:43.173932: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55828bf71a60 executing computations on platform Host. Devices:\n",
      "2021-12-04 19:49:43.173994: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2021-12-04 19:49:43.175915: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-04 19:49:43.218216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: TITAN V major: 7 minor: 0 memoryClockRate(GHz): 1.455\n",
      "pciBusID: 0000:02:00.0\n",
      "2021-12-04 19:49:43.218273: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-12-04 19:49:43.220480: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10\n",
      "2021-12-04 19:49:43.222522: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-04 19:49:43.222872: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-04 19:49:43.225168: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-12-04 19:49:43.226538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-12-04 19:49:43.231532: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-12-04 19:49:43.233753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2021-12-04 19:49:46.859246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-04 19:49:46.859290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2021-12-04 19:49:46.859297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2021-12-04 19:49:46.862347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10400 MB memory) -> physical GPU (device: 0, name: TITAN V, pci bus id: 0000:02:00.0, compute capability: 7.0)\n",
      "2021-12-04 19:49:46.864190: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55831ffdf570 executing computations on platform CUDA. Devices:\n",
      "2021-12-04 19:49:46.864207: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN V, Compute Capability 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "k_model = keras.models.load_model('../models/converted_models/keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_layer_index_k_model_1d = [0, 2, 5, 7, 10, 12, 15, 17]\n",
    "trans_layer_index_k_model = [1, 3, 6, 8, 11, 13, 17, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_k_model_1d, index_k_model in zip(trans_layer_index_k_model_1d, trans_layer_index_k_model):\n",
    "    try:\n",
    "        k_model_1d.layers[index_k_model_1d].set_weights(\n",
    "            [np.squeeze(k_model.layers[index_k_model].get_weights()[0]), \n",
    "             k_model.layers[index_k_model].get_weights()[1]])\n",
    "    except ValueError:\n",
    "        k_model_1d.layers[index_k_model_1d].set_weights(\n",
    "            [k_model.layers[index_k_model].get_weights()[0], \n",
    "             k_model.layers[index_k_model].get_weights()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd493b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_model_1d.save('../models/converted_models/starr_sig_A549_499bp_rep1rep2_regression.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9 (default, Jan 26 2021, 15:33:00) \n[GCC 8.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
